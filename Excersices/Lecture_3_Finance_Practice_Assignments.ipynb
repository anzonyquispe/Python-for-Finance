{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7786de6",
   "metadata": {},
   "source": [
    "# 4. If and Loops — Finance Practice (Assignments Only)\n",
    "\n",
    "This notebook follows the **same topics and order** as the original Lecture 3 (`If and Loops`). All tasks use **real financial/economic data** from Peru and the US.\n",
    "\n",
    "**Student rule:** fill only the `TODO` blocks. Do *not* paste full solutions from elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0674befd",
   "metadata": {},
   "source": [
    "## Data sources used\n",
    "\n",
    "- **BCRPData (Peru, official)**: BCRP statistical series API.\n",
    "  - API guide: https://estadisticas.bcrp.gob.pe/estadisticas/series/ayuda/api\n",
    "  - Example daily series list includes BVL indexes and FX.\n",
    "- **Yahoo Finance (US market data)** via `yfinance` (community wrapper for Yahoo Finance).\n",
    "  - Docs: https://ranaroussi.github.io/yfinance/\n",
    "- **SEC EDGAR Data APIs (US, official)**: company facts JSON.\n",
    "  - Docs: https://www.sec.gov/search-filings/edgar-application-programming-interfaces\n",
    "\n",
    "If any download fails (internet/firewall), this notebook is designed to **keep running** with empty data, so you can still practice control flow syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f34032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0691b157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "CACHE_DIR = Path(\".cache\")\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "_ES_TO_EN_MONTH = {\n",
    "    \"Ene\": \"Jan\", \"Feb\": \"Feb\", \"Mar\": \"Mar\", \"Abr\": \"Apr\", \"May\": \"May\", \"Jun\": \"Jun\",\n",
    "    \"Jul\": \"Jul\", \"Ago\": \"Aug\", \"Set\": \"Sep\", \"Sep\": \"Sep\", \"Oct\": \"Oct\", \"Nov\": \"Nov\", \"Dic\": \"Dec\"\n",
    "}\n",
    "\n",
    "def _hash_key(*parts: str) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    for p in parts:\n",
    "        h.update(str(p).encode(\"utf-8\"))\n",
    "        h.update(b\"|\")\n",
    "    return h.hexdigest()[:24]\n",
    "\n",
    "def _normalize_period(code: str, period: str | None) -> str | None:\n",
    "    if period is None:\n",
    "        return None\n",
    "    period = str(period).strip()\n",
    "    freq = code[-2:].upper() if len(code) >= 2 else \"\"\n",
    "\n",
    "    if freq == \"PD\":  # daily\n",
    "        if re.fullmatch(r\"\\d{4}-\\d{1,2}\", period):\n",
    "            y, m = period.split(\"-\")\n",
    "            return f\"{int(y):04d}-{int(m):02d}-01\"\n",
    "        if re.fullmatch(r\"\\d{4}\", period):\n",
    "            return f\"{int(period):04d}-01-01\"\n",
    "        return period\n",
    "\n",
    "    if freq == \"PM\":  # monthly\n",
    "        m = re.fullmatch(r\"(\\d{4})-(\\d{1,2})-(\\d{1,2})\", period)\n",
    "        if m:\n",
    "            y, mo, _ = m.groups()\n",
    "            return f\"{int(y):04d}-{int(mo)}\"\n",
    "        m = re.fullmatch(r\"(\\d{4})-(\\d{1,2})\", period)\n",
    "        if m:\n",
    "            y, mo = m.groups()\n",
    "            return f\"{int(y):04d}-{int(mo)}\"\n",
    "        if re.fullmatch(r\"\\d{4}\", period):\n",
    "            return f\"{int(period):04d}-1\"\n",
    "        return period\n",
    "\n",
    "    if freq == \"MD\":  # daily index\n",
    "        return period\n",
    "\n",
    "    return period\n",
    "\n",
    "def _parse_bcrp_period_name(name: str) -> pd.Timestamp:\n",
    "    s = str(name).strip()\n",
    "\n",
    "    # ISO-ish\n",
    "    try:\n",
    "        if re.fullmatch(r\"\\d{4}(-\\d{1,2}){0,2}\", s):\n",
    "            return pd.to_datetime(s, errors=\"raise\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Monthly like \"Mar.2020\"\n",
    "    m = re.fullmatch(r\"([A-Za-zÁÉÍÓÚÑñ]{3})\\.(\\d{4})\", s)\n",
    "    if m:\n",
    "        mon_es, y = m.groups()\n",
    "        mon = _ES_TO_EN_MONTH.get(mon_es[:3], mon_es[:3])\n",
    "        return pd.to_datetime(f\"{mon}.{y}\", format=\"%b.%Y\", errors=\"coerce\")\n",
    "\n",
    "    # Daily like \"18Nov25\" or \"02Ene97\"\n",
    "    m = re.fullmatch(r\"(\\d{2})([A-Za-zÁÉÍÓÚÑñ]{3})(\\d{2})\", s)\n",
    "    if m:\n",
    "        d, mon_es, yy = m.groups()\n",
    "        mon = _ES_TO_EN_MONTH.get(mon_es[:3], mon_es[:3])\n",
    "        year = 2000 + int(yy) if int(yy) <= 69 else 1900 + int(yy)\n",
    "        return pd.to_datetime(f\"{d}{mon}{year}\", format=\"%d%b%Y\", errors=\"coerce\")\n",
    "\n",
    "    return pd.to_datetime(s, errors=\"coerce\")\n",
    "\n",
    "def bcrp_get(series_codes, start: str | None = None, end: str | None = None, lang: str = \"esp\") -> pd.DataFrame:\n",
    "    \"\"\"Fetch BCRPData series (official API) into a DataFrame.\n",
    "\n",
    "    Returns columns: [\"date\", <code1>, <code2>, ...]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import requests\n",
    "    except Exception:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    if isinstance(series_codes, (list, tuple)):\n",
    "        codes_list = [str(c).strip() for c in series_codes]\n",
    "        codes = \"-\".join(codes_list)\n",
    "        freq_code = codes_list[0]\n",
    "    else:\n",
    "        codes = str(series_codes).strip()\n",
    "        codes_list = codes.split(\"-\")\n",
    "        freq_code = codes_list[0]\n",
    "\n",
    "    start_n = _normalize_period(freq_code, start)\n",
    "    end_n = _normalize_period(freq_code, end)\n",
    "\n",
    "    key = _hash_key(\"bcrp\", codes, start_n or \"\", end_n or \"\", lang)\n",
    "    cache_path = CACHE_DIR / f\"bcrp_{key}.pkl\"\n",
    "    if cache_path.exists():\n",
    "        return pd.read_pickle(cache_path)\n",
    "\n",
    "    base_url = \"https://estadisticas.bcrp.gob.pe/estadisticas/series/api\"\n",
    "    parts = [base_url, codes, \"json\"]\n",
    "    if start_n and end_n:\n",
    "        parts += [start_n, end_n]\n",
    "    if lang:\n",
    "        parts += [lang]\n",
    "    url = \"/\".join(parts)\n",
    "\n",
    "    r = requests.get(url, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    obj = r.json()\n",
    "\n",
    "    periods = obj.get(\"periods\", [])\n",
    "    rows = []\n",
    "    for p in periods:\n",
    "        name = p.get(\"name\")\n",
    "        vals = p.get(\"values\", [])\n",
    "        if isinstance(vals, str):\n",
    "            vals = [vals]\n",
    "        if name is None or not isinstance(vals, list):\n",
    "            continue\n",
    "        vals = (vals + [None] * len(codes_list))[:len(codes_list)]\n",
    "        rows.append([name] + vals)\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\"date\"] + codes_list)\n",
    "    if df.shape[0] == 0:\n",
    "        return pd.DataFrame(columns=[\"date\"] + codes_list)\n",
    "\n",
    "    df[\"date\"] = df[\"date\"].apply(_parse_bcrp_period_name)\n",
    "    for c in codes_list:\n",
    "        df[c] = df[c].replace({\"n.d.\": np.nan, \"nd\": np.nan, \"N.D.\": np.nan})\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    df = df.dropna(subset=[\"date\"]).sort_values(\"date\").reset_index(drop=True)\n",
    "    df.to_pickle(cache_path)\n",
    "    return df\n",
    "\n",
    "def bcrp_get_cached_or_empty(series_codes, start: str, end: str) -> pd.DataFrame:\n",
    "    try:\n",
    "        return bcrp_get(series_codes, start=start, end=end)\n",
    "    except Exception:\n",
    "        if isinstance(series_codes, (list, tuple)):\n",
    "            codes_list = [str(c).strip() for c in series_codes]\n",
    "        else:\n",
    "            codes_list = [str(series_codes).strip()]\n",
    "        return pd.DataFrame(columns=[\"date\"] + codes_list)\n",
    "\n",
    "def yf_download_wide(tickers, start: str, end: str) -> pd.DataFrame:\n",
    "    \"\"\"Download Close and Volume using yfinance.\n",
    "\n",
    "    Returns a DataFrame indexed by date with columns:\n",
    "      Close_<TICKER>, Volume_<TICKER>\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import yfinance as yf\n",
    "    except Exception:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    cols = tickers if isinstance(tickers, (list, tuple)) else [tickers]\n",
    "    key = _hash_key(\"yf_wide\", \",\".join(cols), start, end)\n",
    "    cache_path = CACHE_DIR / f\"yf_wide_{key}.pkl\"\n",
    "    if cache_path.exists():\n",
    "        return pd.read_pickle(cache_path)\n",
    "\n",
    "    try:\n",
    "        data = yf.download(cols, start=start, end=end, auto_adjust=True, progress=False)\n",
    "        if data.empty:\n",
    "            return pd.DataFrame()\n",
    "        if isinstance(data.columns, pd.MultiIndex):\n",
    "            close = data[\"Close\"].copy()\n",
    "            vol = data[\"Volume\"].copy()\n",
    "        else:\n",
    "            close = data[[\"Close\"]].rename(columns={\"Close\": cols[0]})\n",
    "            vol = data[[\"Volume\"]].rename(columns={\"Volume\": cols[0]})\n",
    "        close = close.add_prefix(\"Close_\")\n",
    "        vol = vol.add_prefix(\"Volume_\")\n",
    "        out = close.join(vol, how=\"outer\")\n",
    "        out.index.name = \"date\"\n",
    "        out.to_pickle(cache_path)\n",
    "        return out\n",
    "    except Exception:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def sec_companyfacts(cik10: str, user_agent: str) -> dict:\n",
    "    \"\"\"Fetch SEC company facts (official EDGAR Data APIs).\n",
    "\n",
    "    Endpoint:\n",
    "      https://data.sec.gov/api/xbrl/companyfacts/CIK##########.json\n",
    "\n",
    "    The SEC requires a User-Agent identifying the requester.\n",
    "\n",
    "    Returns {} on failure.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import requests, json\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "    cik10 = str(cik10).zfill(10)\n",
    "    key = _hash_key(\"sec_companyfacts\", cik10)\n",
    "    cache_path = CACHE_DIR / f\"sec_companyfacts_{key}.json\"\n",
    "    if cache_path.exists():\n",
    "        try:\n",
    "            return json.loads(cache_path.read_text(encoding=\"utf-8\"))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    url = f\"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik10}.json\"\n",
    "    headers = {\"User-Agent\": user_agent, \"Accept-Encoding\": \"gzip, deflate\", \"Host\": \"data.sec.gov\"}\n",
    "\n",
    "    try:\n",
    "        r = requests.get(url, headers=headers, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        obj = r.json()\n",
    "        try:\n",
    "            cache_path.write_text(json.dumps(obj), encoding=\"utf-8\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        return obj\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "def safe_head(df: pd.DataFrame, n: int = 5) -> pd.DataFrame:\n",
    "    return df.head(n) if isinstance(df, pd.DataFrame) else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8e95b6",
   "metadata": {},
   "source": [
    "### Load datasets (used across exercises)\n",
    "\n",
    "We load:\n",
    "- Peru: **BVL General Index** (BCRP series `PD38026MD`) and **CPI Non-Tradables** (monthly, `PN01282PM`).\n",
    "- US: prices/volumes for selected tickers via `yfinance`.\n",
    "- US fundamentals: SEC company facts (optional) for Apple (CIK 0000320193).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b53a07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BVL: (729, 2) CPI NT: (59, 2) US: (1246, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(        date  BVL_index\n",
       " 0 2021-02-01   21610.03\n",
       " 1 2021-02-02   21451.89\n",
       " 2 2021-02-03   21632.78\n",
       " 3 2021-02-04   21552.20\n",
       " 4 2021-02-05   21783.37,\n",
       "         date  CPI_non_tradables\n",
       " 0 2021-01-01           0.832155\n",
       " 1 2021-02-01          -0.424668\n",
       " 2 2021-03-01           1.026397\n",
       " 3 2021-04-01          -0.361899\n",
       " 4 2021-05-01           0.158005,\n",
       " Ticker      Close_AAPL   Close_JPM  Close_MSFT  Close_NVDA   Close_SPY  \\\n",
       " date                                                                     \n",
       " 2021-01-04  125.974487  110.548325  208.882187   13.076726  345.273926   \n",
       " 2021-01-05  127.531975  111.149849  209.083710   13.367159  347.651978   \n",
       " 2021-01-06  123.239067  116.369003  203.662308   12.579123  349.730438   \n",
       " 2021-01-07  127.444382  120.190437  209.457947   13.306580  354.926575   \n",
       " 2021-01-08  128.544388  120.323151  210.734116   13.239517  356.948822   \n",
       " \n",
       " Ticker      Volume_AAPL  Volume_JPM  Volume_MSFT  Volume_NVDA  Volume_SPY  \n",
       " date                                                                       \n",
       " 2021-01-04    143301900    16819900     37130100    560640000   110210800  \n",
       " 2021-01-05     97664900    13731200     23823000    322760000    66426200  \n",
       " 2021-01-06    155088000    24909100     35930700    580424000   107997700  \n",
       " 2021-01-07    109578200    21940400     27694500    461480000    68766800  \n",
       " 2021-01-08    105158200    12035100     22956200    292528000    71677200  )"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START = \"2021-01-01\"\n",
    "END = \"2025-12-18\"\n",
    "\n",
    "# Peru — BCRPData (official)\n",
    "bvl = bcrp_get_cached_or_empty(\"PD38026MD\", start=START, end=END).rename(columns={\"PD38026MD\":\"BVL_index\"})\n",
    "cpi_nt = bcrp_get_cached_or_empty(\"PN01282PM\", start=START, end=END).rename(columns={\"PN01282PM\":\"CPI_non_tradables\"})\n",
    "\n",
    "# US — Yahoo Finance (real market data)\n",
    "tickers = [\"SPY\", \"AAPL\", \"MSFT\", \"JPM\", \"NVDA\"]\n",
    "us = yf_download_wide(tickers, start=START, end=END)\n",
    "\n",
    "print(\"BVL:\", bvl.shape, \"CPI NT:\", cpi_nt.shape, \"US:\", us.shape)\n",
    "safe_head(bvl), safe_head(cpi_nt), safe_head(us)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15619d1c",
   "metadata": {},
   "source": [
    "# 4.1. <a id='def'> If condition </a>\n",
    "\n",
    "In this section you will practice `if / elif / else` using real data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e7c0dc",
   "metadata": {},
   "source": [
    "## 4.1.1.  <a id='4.1.1.'> The structure of the code </a>\n",
    "\n",
    "**Exercise 4.1.1 — Classify a day (single `if`)**\n",
    "\n",
    "Using the **BVL index**:\n",
    "1. Compute daily returns: `ret = pct_change()`.\n",
    "2. Take the most recent non-missing return.\n",
    "3. Write a single `if` statement that prints a message only when the last return is **positive**.\n",
    "\n",
    "Keep it minimal: one `if`, one `print`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d348d456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BVL last return is positive: 0.01196384727960198\n",
      "Last return value (may be NaN if data missing): 0.01196384727960198\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "# Hint: bvl has columns [\"date\",\"BVL_index\"]\n",
    "last_ret = np.nan\n",
    "\n",
    "if isinstance(bvl, pd.DataFrame) and (not bvl.empty) and (\"BVL_index\" in bvl.columns):\n",
    "    ret = bvl.set_index(\"date\")[\"BVL_index\"].pct_change()\n",
    "    if ret.dropna().shape[0] > 0:\n",
    "        last_ret = float(ret.dropna().iloc[-1])\n",
    "\n",
    "# Single IF (prints only when positive)\n",
    "if pd.notna(last_ret) and last_ret > 0:\n",
    "    print(\"BVL last return is positive:\", last_ret)\n",
    "\n",
    "# Optional self-check (does not enforce correctness)\n",
    "print(\"Last return value (may be NaN if data missing):\", last_ret)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae000aba",
   "metadata": {},
   "source": [
    "### 4.1.2.   <a id='4.1.2.'> If condition with more than 1 expression </a>\n",
    "\n",
    "**Exercise 4.1.2 — Two conditions with `and` / `or`**\n",
    "\n",
    "Using US data (`us`):\n",
    "1. Compute daily returns for `SPY` from `Close_SPY`.\n",
    "2. Define a threshold, e.g. `thr = 0.01` (1%).\n",
    "3. Create two booleans for the last available day:\n",
    "   - `big_move`: `abs(return) > thr`\n",
    "   - `high_volume`: `Volume_SPY` above its median\n",
    "4. Use `if / elif / else` to print one of three messages:\n",
    "   - big move AND high volume\n",
    "   - big move BUT not high volume\n",
    "   - not a big move\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de06b29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPY: big move AND high volume\n",
      "{'big_move': True, 'high_volume': True, 'last_spy_ret': -0.011003536401451242, 'last_spy_vol': 110625200.0}\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "thr = 0.01\n",
    "big_move = False\n",
    "high_volume = False\n",
    "\n",
    "last_spy_ret = np.nan\n",
    "last_spy_vol = np.nan\n",
    "\n",
    "if isinstance(us, pd.DataFrame) and (not us.empty) and (\"Close_SPY\" in us.columns):\n",
    "    spy_ret = us[\"Close_SPY\"].pct_change()\n",
    "    if spy_ret.dropna().shape[0] > 0:\n",
    "        last_spy_ret = float(spy_ret.dropna().iloc[-1])\n",
    "        big_move = abs(last_spy_ret) > thr\n",
    "\n",
    "    if \"Volume_SPY\" in us.columns and us[\"Volume_SPY\"].dropna().shape[0] > 0:\n",
    "        last_spy_vol = float(us[\"Volume_SPY\"].dropna().iloc[-1])\n",
    "        vol_median = float(us[\"Volume_SPY\"].median(skipna=True))\n",
    "        high_volume = last_spy_vol > vol_median\n",
    "\n",
    "if big_move and high_volume:\n",
    "    print(\"SPY: big move AND high volume\")\n",
    "elif big_move and (not high_volume):\n",
    "    print(\"SPY: big move BUT not high volume\")\n",
    "else:\n",
    "    print(\"SPY: not a big move\")\n",
    "\n",
    "# Optional self-check\n",
    "print({\"big_move\": big_move, \"high_volume\": high_volume, \"last_spy_ret\": last_spy_ret, \"last_spy_vol\": last_spy_vol})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261d8fd9",
   "metadata": {},
   "source": [
    "### 4.1.3.   <a id='4.1.3.'> Logical Operators </a>\n",
    "\n",
    "**Exercise 4.1.3 — Filter with logical operators**\n",
    "\n",
    "Using CPI non-tradables (`cpi_nt`):\n",
    "1. Compute monthly inflation as `% change` of the CPI index.\n",
    "2. Create a filtered DataFrame keeping months where:\n",
    "   - inflation is positive **AND** above its own median.\n",
    "3. Create another filter where:\n",
    "   - inflation is negative **OR** missing.\n",
    "\n",
    "Store the results in `infl_above_median` and `infl_negative_or_missing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2b4dcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infl_above_median: (17, 3)\n",
      "infl_negative_or_missing: (42, 3)\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "infl_above_median = pd.DataFrame()\n",
    "infl_negative_or_missing = pd.DataFrame()\n",
    "\n",
    "if isinstance(cpi_nt, pd.DataFrame) and (not cpi_nt.empty) and (\"CPI_non_tradables\" in cpi_nt.columns):\n",
    "    tmp = cpi_nt.copy()\n",
    "    tmp = tmp.sort_values(\"date\").reset_index(drop=True)\n",
    "    tmp[\"inflation\"] = tmp[\"CPI_non_tradables\"].pct_change() * 100  # % monthly inflation\n",
    "    med = tmp[\"inflation\"].median(skipna=True)\n",
    "\n",
    "    infl_above_median = tmp[(tmp[\"inflation\"] > 0) & (tmp[\"inflation\"] > med)][[\"date\", \"CPI_non_tradables\", \"inflation\"]].reset_index(drop=True)\n",
    "    infl_negative_or_missing = tmp[(tmp[\"inflation\"] < 0) | (tmp[\"inflation\"].isna())][[\"date\", \"CPI_non_tradables\", \"inflation\"]].reset_index(drop=True)\n",
    "\n",
    "# Optional self-check\n",
    "print(\"infl_above_median:\", getattr(infl_above_median, \"shape\", None))\n",
    "print(\"infl_negative_or_missing:\", getattr(infl_negative_or_missing, \"shape\", None))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074b6391",
   "metadata": {},
   "source": [
    "### 4.1.4.   <a id='4.1.4.'> Python Identity Operators </a>\n",
    "\n",
    "**Exercise 4.1.4 — `==` vs `is` with missing values**\n",
    "\n",
    "Create a Python list of *observations* that mixes numbers and missing values:\n",
    "```python\n",
    "obs = [3.5, None, 3.6, np.nan, 3.55]\n",
    "```\n",
    "Tasks:\n",
    "1. Use `== None` to build a mask for `None`.\n",
    "2. Use `is None` inside a loop to count `None`.\n",
    "3. Show that `np.nan == np.nan` is `False`.\n",
    "4. Use `np.isnan` to count NaNs safely.\n",
    "\n",
    "This is useful when cleaning financial time series with missing days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da4641ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_none: [False, True, False, False, False]\n",
      "none_count: 1\n",
      "np.nan == np.nan: False\n",
      "nan_count: 1\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "obs = [3.5, None, 3.6, np.nan, 3.55]\n",
    "\n",
    "# 1) == None mask\n",
    "mask_none = [(x == None) for x in obs]  # noqa: E711\n",
    "\n",
    "# 2) is None count in a loop\n",
    "none_count = 0\n",
    "for x in obs:\n",
    "    if x is None:\n",
    "        none_count += 1\n",
    "\n",
    "# 3) NaN equality check\n",
    "nan_eq_nan = (np.nan == np.nan)\n",
    "\n",
    "# 4) Count NaNs safely with np.isnan\n",
    "nan_count = 0\n",
    "for x in obs:\n",
    "    if x is None:\n",
    "        continue\n",
    "    try:\n",
    "        if isinstance(x, float) and np.isnan(x):\n",
    "            nan_count += 1\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Optional self-check\n",
    "print(\"mask_none:\", mask_none)\n",
    "print(\"none_count:\", none_count)\n",
    "print(\"np.nan == np.nan:\", nan_eq_nan)\n",
    "print(\"nan_count:\", nan_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69700db0",
   "metadata": {},
   "source": [
    "### 4.1.5.   <a id='4.1.5.'> Final IF condition structure </a>\n",
    "\n",
    "**Exercise 4.1.5 — Write a small decision function**\n",
    "\n",
    "Write a function `risk_label(x, low, high)`:\n",
    "- returns `'LOW'` if `x < low`\n",
    "- returns `'MEDIUM'` if `low <= x < high`\n",
    "- returns `'HIGH'` if `x >= high`\n",
    "\n",
    "Then apply it to the **last SPY daily return**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f63f9cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_spy_ret: -0.011003536401451242 label: HIGH\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "def risk_label(x: float, low: float, high: float) -> str:\n",
    "    if x < low:\n",
    "        return \"LOW\"\n",
    "    elif low <= x < high:\n",
    "        return \"MEDIUM\"\n",
    "    else:\n",
    "        return \"HIGH\"\n",
    "\n",
    "last_spy_ret = np.nan\n",
    "label = \"NA\"\n",
    "\n",
    "if isinstance(us, pd.DataFrame) and (not us.empty) and (\"Close_SPY\" in us.columns):\n",
    "    spy_ret = us[\"Close_SPY\"].pct_change()\n",
    "    if spy_ret.dropna().shape[0] > 0:\n",
    "        last_spy_ret = float(spy_ret.dropna().iloc[-1])\n",
    "        # Use absolute return magnitude as a simple \"risk\" proxy\n",
    "        label = risk_label(abs(last_spy_ret), low=0.002, high=0.01)\n",
    "\n",
    "# Optional self-check\n",
    "print(\"last_spy_ret:\", last_spy_ret, \"label:\", label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5e869d",
   "metadata": {},
   "source": [
    "### 4.1.6.   <a id='4.1.6.'> Python Nested if Statement </a>\n",
    "\n",
    "**Exercise 4.1.6 — Nested if for a simple trading rule (logic only)**\n",
    "\n",
    "Using BVL daily returns:\n",
    "1. Compute `ret` and its rolling volatility proxy: rolling std over 20 days.\n",
    "2. Build a **nested if** rule:\n",
    "   - If `ret > 0`:\n",
    "       - If `volatility` is high → print `'UP but volatile'`\n",
    "       - else → print `'UP and calm'`\n",
    "   - Else:\n",
    "       - If `ret < 0` print `'DOWN'`\n",
    "       - else print `'FLAT'`\n",
    "\n",
    "Do not optimize anything; this is purely control-flow practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc06510b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UP but volatile\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "ret = pd.Series(dtype=float)\n",
    "vol20 = pd.Series(dtype=float)\n",
    "\n",
    "if isinstance(bvl, pd.DataFrame) and (not bvl.empty) and (\"BVL_index\" in bvl.columns):\n",
    "    s = bvl.set_index(\"date\")[\"BVL_index\"].sort_index()\n",
    "    ret = s.pct_change()\n",
    "    vol20 = ret.rolling(20).std()\n",
    "\n",
    "last_r = ret.dropna().iloc[-1] if ret.dropna().shape[0] > 0 else np.nan\n",
    "last_v = vol20.dropna().iloc[-1] if vol20.dropna().shape[0] > 0 else np.nan\n",
    "vol_high = False\n",
    "if vol20.dropna().shape[0] > 0 and pd.notna(last_v):\n",
    "    vol_high = last_v > vol20.median(skipna=True)\n",
    "\n",
    "if pd.isna(last_r):\n",
    "    print(\"No BVL return available.\")\n",
    "else:\n",
    "    if last_r > 0:\n",
    "        if vol_high:\n",
    "            print(\"UP but volatile\")\n",
    "        else:\n",
    "            print(\"UP and calm\")\n",
    "    else:\n",
    "        if last_r < 0:\n",
    "            print(\"DOWN\")\n",
    "        else:\n",
    "            print(\"FLAT\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4687d3da",
   "metadata": {},
   "source": [
    "## 4.2.   <a id='4.2.'> For Loops </a>\n",
    "\n",
    "You will practice loops over arrays, lists, dictionaries, ranges, and DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92311dd",
   "metadata": {},
   "source": [
    "### 4.2.1. <a id='4.2.1.'> In numpy </a>\n",
    "\n",
    "**Exercise 4.2.1 — Cumulative return with a loop (no vectorization)**\n",
    "\n",
    "Using SPY daily returns (from `Close_SPY`):\n",
    "1. Take the last 60 returns as a NumPy array.\n",
    "2. Using a `for` loop, compute cumulative growth starting at 1.0:\n",
    "   - update: `value *= (1 + r)`\n",
    "3. Store the cumulative values in a list `path`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a186c711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(path): 60\n",
      "final_value: 1.0123490329911564\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "path = []\n",
    "final_value = np.nan\n",
    "\n",
    "if isinstance(us, pd.DataFrame) and (not us.empty) and (\"Close_SPY\" in us.columns):\n",
    "    spy_ret = us[\"Close_SPY\"].pct_change().dropna()\n",
    "    arr = spy_ret.to_numpy()\n",
    "    if arr.size > 0:\n",
    "        arr = arr[-min(60, arr.size):]\n",
    "        value = 1.0\n",
    "        for r in arr:\n",
    "            value *= (1 + float(r))\n",
    "            path.append(value)\n",
    "        final_value = float(value)\n",
    "\n",
    "# Optional self-check\n",
    "print(\"len(path):\", len(path))\n",
    "print(\"final_value:\", final_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c8cdf2",
   "metadata": {},
   "source": [
    "### 4.2.2 <a id='4.2.2.'> In List </a>\n",
    "\n",
    "**Exercise 4.2.2 — Loop over tickers and compute last close**\n",
    "\n",
    "Using the `tickers` list and the `us` DataFrame:\n",
    "1. Loop over tickers.\n",
    "2. For each ticker, pick its last non-missing `Close_<T>`.\n",
    "3. Store results in a list of tuples: `(ticker, last_close)`.\n",
    "4. If a ticker column is missing, use `continue`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed7dd827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_close_list (first 3): [('SPY', 671.4000244140625), ('AAPL', 271.8399963378906), ('MSFT', 476.1199951171875)]\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "last_close_list = []\n",
    "\n",
    "if isinstance(us, pd.DataFrame) and (not us.empty):\n",
    "    for t in tickers:\n",
    "        col = f\"Close_{t}\"\n",
    "        if col not in us.columns:\n",
    "            continue\n",
    "        series = us[col].dropna()\n",
    "        if series.shape[0] == 0:\n",
    "            continue\n",
    "        last_close = float(series.iloc[-1])\n",
    "        last_close_list.append((t, last_close))\n",
    "\n",
    "# Optional self-check\n",
    "print(\"last_close_list (first 3):\", last_close_list[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904f7f25",
   "metadata": {},
   "source": [
    "### 4.2.3  <a id='4.2.3.'>In Dictionary </a>\n",
    "\n",
    "**Exercise 4.2.3 — Build a dictionary of risk flags**\n",
    "\n",
    "1. Create a dict `risk_by_ticker = {}`.\n",
    "2. Loop over `last_close_list` (from 4.2.2).\n",
    "3. Assign `'HIGH_PRICE'` if last_close is above its own cross-ticker median, else `'LOW_PRICE'`.\n",
    "4. Store: `risk_by_ticker[ticker] = label`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2e15057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SPY': 'HIGH_PRICE', 'AAPL': 'LOW_PRICE', 'MSFT': 'HIGH_PRICE', 'JPM': 'LOW_PRICE', 'NVDA': 'LOW_PRICE'}\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "risk_by_ticker = {}\n",
    "\n",
    "if isinstance(last_close_list, list) and len(last_close_list) > 0:\n",
    "    vals = [v for (_, v) in last_close_list if pd.notna(v)]\n",
    "    med = float(np.median(vals)) if len(vals) > 0 else np.nan\n",
    "    for t, v in last_close_list:\n",
    "        if pd.isna(v) or pd.isna(med):\n",
    "            label = \"UNKNOWN\"\n",
    "        else:\n",
    "            label = \"HIGH_PRICE\" if v > med else \"LOW_PRICE\"\n",
    "        risk_by_ticker[t] = label\n",
    "\n",
    "# Optional self-check\n",
    "print(risk_by_ticker)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb57b5b1",
   "metadata": {},
   "source": [
    "### 4.2.4 <a id = '4.2.4.'>  For loop using range </a>\n",
    "\n",
    "**Exercise 4.2.4 — Simple monthly budgeting with `range`**\n",
    "\n",
    "Goal: create a monthly savings path (control flow only).\n",
    "\n",
    "1. Choose `months = 12` and `monthly_saving = 200`.\n",
    "2. Use `for i in range(months)` to build a list with cumulative savings.\n",
    "3. Add an `if` inside the loop: every 3 months add a bonus of 50.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6826389f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "savings_path: [200, 400, 650, 850, 1050, 1300, 1500, 1700, 1950, 2150, 2350, 2600]\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "months = 12\n",
    "monthly_saving = 200\n",
    "savings_path = []\n",
    "\n",
    "total = 0\n",
    "for i in range(months):\n",
    "    total += monthly_saving\n",
    "    if (i + 1) % 3 == 0:\n",
    "        total += 50\n",
    "    savings_path.append(total)\n",
    "\n",
    "# Optional self-check\n",
    "print(\"savings_path:\", savings_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6047bb08",
   "metadata": {},
   "source": [
    "### 4.2.5 <a id='4.2.5.'>  Nested For Loop </a>\n",
    "\n",
    "**Exercise 4.2.5 — Pairwise comparison (nested loop)**\n",
    "\n",
    "Using the tickers list:\n",
    "1. Build all **unique pairs** `(i, j)` with `i < j`.\n",
    "2. For each pair, compare their last close and store the ticker with the higher value.\n",
    "3. Save outputs in a list `winners`.\n",
    "\n",
    "This is intentionally simple to focus on nested loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12a5013c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winners (first 5): ['SPY', 'SPY', 'SPY', 'SPY', 'MSFT']\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "winners = []\n",
    "\n",
    "# Build a lookup of last close for quick access\n",
    "last_close = {t: v for (t, v) in last_close_list} if isinstance(last_close_list, list) else {}\n",
    "\n",
    "for i in range(len(tickers)):\n",
    "    for j in range(i + 1, len(tickers)):\n",
    "        ti, tj = tickers[i], tickers[j]\n",
    "        vi, vj = last_close.get(ti, np.nan), last_close.get(tj, np.nan)\n",
    "\n",
    "        if pd.isna(vi) and pd.isna(vj):\n",
    "            continue\n",
    "        if pd.isna(vi):\n",
    "            winners.append(tj)\n",
    "        elif pd.isna(vj):\n",
    "            winners.append(ti)\n",
    "        else:\n",
    "            winners.append(ti if vi >= vj else tj)\n",
    "\n",
    "# Optional self-check\n",
    "print(\"winners (first 5):\", winners[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2461242",
   "metadata": {},
   "source": [
    "### 4.2.6. <a id = '4.2.6.'> Iterations over Pandas</a>\n",
    "\n",
    "#### Exercise — Rename Columns (finance version)\n",
    "\n",
    "Using `us`:\n",
    "1. Copy `us` to `us2`.\n",
    "2. Rename columns so that:\n",
    "   - `Close_SPY` → `close_spy`\n",
    "   - `Volume_SPY` → `volume_spy`\n",
    "   - similarly for other tickers\n",
    "3. Do this **with a loop**, not by writing each rename manually.\n",
    "\n",
    "Store the final DataFrame in `us2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af591fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original cols (first 6): ['Close_AAPL', 'Close_JPM', 'Close_MSFT', 'Close_NVDA', 'Close_SPY', 'Volume_AAPL']\n",
      "New cols (first 6): ['close_aapl', 'close_jpm', 'close_msft', 'close_nvda', 'close_spy', 'volume_aapl']\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "us2 = us.copy()\n",
    "\n",
    "rename_map = {}\n",
    "for col in us2.columns:\n",
    "    if \"_\" in col:\n",
    "        prefix, ticker = col.split(\"_\", 1)\n",
    "        rename_map[col] = f\"{prefix.lower()}_{ticker.lower()}\"\n",
    "    else:\n",
    "        rename_map[col] = col.lower()\n",
    "\n",
    "us2 = us2.rename(columns=rename_map)\n",
    "\n",
    "# Optional self-check\n",
    "print(\"Original cols (first 6):\", list(us.columns)[:6])\n",
    "print(\"New cols (first 6):\", list(us2.columns)[:6])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2710c1d8",
   "metadata": {},
   "source": [
    "## 4.3. <a id = '4.3.'> Pass, Continue, Break, Try</a>\n",
    "\n",
    "These statements help control loop execution and handle errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7098b5b8",
   "metadata": {},
   "source": [
    "### 4.3.1 <a id = '4.3.1.'> Pass</a>\n",
    "\n",
    "**Exercise 4.3.1 — Placeholder rule**\n",
    "\n",
    "Write a loop over tickers that *would* apply a rule, but for now uses `pass` when the ticker is not `'SPY'`. When the ticker is `'SPY'`, print its last close.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d051d634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPY last close: 671.4000244140625\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "# Use last_close_list from 4.2.2 if available\n",
    "\n",
    "# Create a lookup for convenience\n",
    "lookup = {t: v for (t, v) in last_close_list} if isinstance(last_close_list, list) else {}\n",
    "\n",
    "for t in tickers:\n",
    "    if t != \"SPY\":\n",
    "        pass\n",
    "    else:\n",
    "        v = lookup.get(\"SPY\", np.nan)\n",
    "        print(\"SPY last close:\", v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d37248",
   "metadata": {},
   "source": [
    "### 4.3.2. <a id = '4.3.2.'>Continue</a>\n",
    "\n",
    "**Exercise 4.3.2 — Skip short histories**\n",
    "\n",
    "1. Loop over tickers.\n",
    "2. For each ticker, count non-missing price observations.\n",
    "3. If fewer than 500 observations, `continue`.\n",
    "4. Otherwise, store the ticker in `enough_data`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cea4813f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enough_data: ['SPY', 'AAPL', 'MSFT', 'JPM', 'NVDA']\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "enough_data = []\n",
    "\n",
    "if isinstance(us, pd.DataFrame) and (not us.empty):\n",
    "    for t in tickers:\n",
    "        col = f\"Close_{t}\"\n",
    "        if col not in us.columns:\n",
    "            continue\n",
    "        n = int(us[col].dropna().shape[0])\n",
    "        if n < 500:\n",
    "            continue\n",
    "        enough_data.append(t)\n",
    "\n",
    "# Optional self-check\n",
    "print(\"enough_data:\", enough_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d1bf7f",
   "metadata": {},
   "source": [
    "### 4.3.3. <a id = '4.3.3.'>Break</a>\n",
    "\n",
    "**Exercise 4.3.3 — Stop when a drawdown threshold is hit**\n",
    "\n",
    "Using SPY returns:\n",
    "1. Walk forward day-by-day.\n",
    "2. Track a running `peak` of the cumulative value.\n",
    "3. Compute drawdown = `value / peak - 1`.\n",
    "4. If drawdown falls below `-0.10` (−10%), `break`.\n",
    "5. Record the date where you stop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a752e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_date: 2022-02-22 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "stop_date = None\n",
    "\n",
    "if isinstance(us, pd.DataFrame) and (not us.empty) and (\"Close_SPY\" in us.columns):\n",
    "    spy_ret = us[\"Close_SPY\"].pct_change().dropna()\n",
    "    if spy_ret.shape[0] > 0:\n",
    "        value = 1.0\n",
    "        peak = 1.0\n",
    "        for dt, r in spy_ret.items():\n",
    "            value *= (1 + float(r))\n",
    "            peak = max(peak, value)\n",
    "            dd = value / peak - 1.0\n",
    "            if dd < -0.10:\n",
    "                stop_date = dt\n",
    "                break\n",
    "\n",
    "print(\"stop_date:\", stop_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2444eb16",
   "metadata": {},
   "source": [
    "### 4.3.4. <a id = '4.3.4.'> Try </a>\n",
    "\n",
    "**Exercise 4.3.4 — Try/Except with a real API (SEC)**\n",
    "\n",
    "The SEC requires a **User-Agent**. You can put your email in it.\n",
    "\n",
    "Tasks:\n",
    "1. Set `SEC_USER_AGENT`.\n",
    "2. Fetch Apple company facts (`CIK 0000320193`).\n",
    "3. In a `try` block, navigate the nested dict to find the section `facts`.\n",
    "4. If something is missing, handle with `except` and set `facts = {}`.\n",
    "\n",
    "Do not extract any final metric here—just practice safe access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80ba92aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facts keys (if available): ['dei', 'us-gaap']\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "SEC_USER_AGENT = \"Python Finance Course (student@example.com)\"  # change to your own email if you run this locally\n",
    "\n",
    "apple = sec_companyfacts(\"0000320193\", user_agent=SEC_USER_AGENT)\n",
    "\n",
    "facts = {}\n",
    "try:\n",
    "    if isinstance(apple, dict):\n",
    "        facts = apple.get(\"facts\", {})\n",
    "    if not isinstance(facts, dict):\n",
    "        facts = {}\n",
    "except Exception:\n",
    "    facts = {}\n",
    "\n",
    "print(\"facts keys (if available):\", list(facts.keys())[:5] if isinstance(facts, dict) else None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4c2710",
   "metadata": {},
   "source": [
    "## 4.4. <a id='4.4.'> While Loop </a>\n",
    "\n",
    "Practice `while` loops with a simple finance simulation using real-return samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0ef191",
   "metadata": {},
   "source": [
    "### 4.4.1. <a id='4.4.1.'> Structure </a>\n",
    "\n",
    "**Exercise 4.4.1 — Reach a target portfolio value**\n",
    "\n",
    "Using SPY daily returns:\n",
    "1. Create a list/array of historical daily returns.\n",
    "2. Start with `value = 1.0`.\n",
    "3. While `value < 1.2` (target +20%), repeatedly:\n",
    "   - draw one return at random (fixed seed)\n",
    "   - update value\n",
    "   - increment `steps`\n",
    "4. Add a safety stop: if `steps > 2000`, break.\n",
    "\n",
    "Store the final `steps` and `value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7741d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps: 669\n",
      "value: 1.2059536907831272\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "steps = 0\n",
    "value = 1.0\n",
    "\n",
    "if isinstance(us, pd.DataFrame) and (not us.empty) and (\"Close_SPY\" in us.columns):\n",
    "    spy_ret = us[\"Close_SPY\"].pct_change().dropna().to_numpy()\n",
    "    if spy_ret.size > 0:\n",
    "        rng = np.random.default_rng(123)\n",
    "        while value < 1.2:\n",
    "            r = float(rng.choice(spy_ret))\n",
    "            value *= (1 + r)\n",
    "            steps += 1\n",
    "            if steps > 2000:\n",
    "                break\n",
    "\n",
    "print(\"steps:\", steps)\n",
    "print(\"value:\", value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da18181",
   "metadata": {},
   "source": [
    "## 4.5. <a id = '4.5.'> References </a>\n",
    "\n",
    "- BCRPData API: https://estadisticas.bcrp.gob.pe/estadisticas/series/ayuda/api\n",
    "- yfinance docs: https://ranaroussi.github.io/yfinance/\n",
    "- SEC EDGAR Data APIs: https://www.sec.gov/search-filings/edgar-application-programming-interfaces\n",
    "- Python control flow: https://docs.python.org/3/tutorial/controlflow.html\n",
    "- Pandas pct_change: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pct_change.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ra_task",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
