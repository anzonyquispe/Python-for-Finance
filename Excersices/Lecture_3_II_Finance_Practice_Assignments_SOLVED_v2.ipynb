{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66b9e7cc",
   "metadata": {},
   "source": [
    "# 5. Functions and Class — Finance Practice (Assignments Only)\n",
    "\n",
    "This notebook follows the structure of **Lecture 3 (Part II)**: **Functions** and **Classes**.\n",
    "\n",
    "Complete the TODO blocks. No plotting.\n",
    "\n",
    "Data sources:\n",
    "- **BCRPData API (Peru, official)**\n",
    "- **FRED (US macro series via CSV download)**\n",
    "- **U.S. Treasury Fiscal Data API (official)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b3f47e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18f0c9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "CACHE_DIR = Path(\".cache\")\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "_ES_TO_EN_MONTH = {\n",
    "    \"Ene\": \"Jan\", \"Feb\": \"Feb\", \"Mar\": \"Mar\", \"Abr\": \"Apr\", \"May\": \"May\", \"Jun\": \"Jun\",\n",
    "    \"Jul\": \"Jul\", \"Ago\": \"Aug\", \"Set\": \"Sep\", \"Sep\": \"Sep\", \"Oct\": \"Oct\", \"Nov\": \"Nov\", \"Dic\": \"Dec\"\n",
    "}\n",
    "\n",
    "def _hash_key(*parts: str) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    for p in parts:\n",
    "        h.update(str(p).encode(\"utf-8\"))\n",
    "        h.update(b\"|\")\n",
    "    return h.hexdigest()[:24]\n",
    "\n",
    "def _to_float(x):\n",
    "    \"\"\"Robust numeric parsing (handles decimal comma, 'n.d.', etc.).\"\"\"\n",
    "    if x is None:\n",
    "        return np.nan\n",
    "    if isinstance(x, (int, float, np.number)):\n",
    "        return float(x)\n",
    "    s = str(x).strip()\n",
    "    if s.lower() in {\"n.d.\", \"nd\", \"n.d\", \"na\", \"nan\", \"\"}:\n",
    "        return np.nan\n",
    "    s = s.replace(\" \", \"\").replace(\"\\u00a0\", \"\")\n",
    "    # Spanish formatting: thousands \".\" and decimal \",\"\n",
    "    if \",\" in s and \".\" in s:\n",
    "        s = s.replace(\".\", \"\").replace(\",\", \".\")\n",
    "    elif \",\" in s and \".\" not in s:\n",
    "        s = s.replace(\",\", \".\")\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "def _parse_bcrp_period(name: str) -> pd.Timestamp:\n",
    "    s = str(name).strip()\n",
    "\n",
    "    dt = pd.to_datetime(s, errors=\"coerce\")\n",
    "    if pd.notna(dt):\n",
    "        return dt\n",
    "\n",
    "    # Daily: 18Nov25, 02Ene97\n",
    "    m = re.fullmatch(r\"(\\d{2})([A-Za-zÁÉÍÓÚÑñ]{3})(\\d{2})\", s)\n",
    "    if m:\n",
    "        d, mon_es, yy = m.groups()\n",
    "        mon = _ES_TO_EN_MONTH.get(mon_es[:3], mon_es[:3])\n",
    "        year = 2000 + int(yy) if int(yy) <= 69 else 1900 + int(yy)\n",
    "        return pd.to_datetime(f\"{d}{mon}{year}\", format=\"%d%b%Y\", errors=\"coerce\")\n",
    "\n",
    "    # Monthly: Mar.2020\n",
    "    m = re.fullmatch(r\"([A-Za-zÁÉÍÓÚÑñ]{3})\\.(\\d{4})\", s)\n",
    "    if m:\n",
    "        mon_es, y = m.groups()\n",
    "        mon = _ES_TO_EN_MONTH.get(mon_es[:3], mon_es[:3])\n",
    "        return pd.to_datetime(f\"01{mon}{y}\", format=\"%d%b%Y\", errors=\"coerce\")\n",
    "\n",
    "    # Monthly: Ene92 or Ene.92\n",
    "    m = re.fullmatch(r\"([A-Za-zÁÉÍÓÚÑñ]{3})\\.?(\\d{2})\", s)\n",
    "    if m:\n",
    "        mon_es, yy = m.groups()\n",
    "        mon = _ES_TO_EN_MONTH.get(mon_es[:3], mon_es[:3])\n",
    "        year = 2000 + int(yy) if int(yy) <= 69 else 1900 + int(yy)\n",
    "        return pd.to_datetime(f\"01{mon}{year}\", format=\"%d%b%Y\", errors=\"coerce\")\n",
    "\n",
    "    # Numeric month: 2022-5\n",
    "    m = re.fullmatch(r\"(\\d{4})-(\\d{1,2})\", s)\n",
    "    if m:\n",
    "        y, mo = m.groups()\n",
    "        return pd.to_datetime(f\"{int(y):04d}-{int(mo):02d}-01\", errors=\"coerce\")\n",
    "\n",
    "    # Year only\n",
    "    m = re.fullmatch(r\"(\\d{4})\", s)\n",
    "    if m:\n",
    "        return pd.to_datetime(f\"{m.group(1)}-01-01\", errors=\"coerce\")\n",
    "\n",
    "    return pd.to_datetime(s, errors=\"coerce\")\n",
    "\n",
    "def _normalize_bcrp_period(code: str, period: str | None) -> str | None:\n",
    "    \"\"\"\n",
    "    Normalize periods for BCRP API.\n",
    "    Heuristic:\n",
    "    - codes starting with PD: daily -> YYYY-MM-DD\n",
    "    - codes starting with PN: monthly -> YYYY-m (no zero-pad)\n",
    "    \"\"\"\n",
    "    if period is None:\n",
    "        return None\n",
    "    p = str(period).strip()\n",
    "\n",
    "    if code.startswith(\"PD\"):\n",
    "        if re.fullmatch(r\"\\d{4}-\\d{1,2}\", p):\n",
    "            y, m = p.split(\"-\")\n",
    "            return f\"{int(y):04d}-{int(m):02d}-01\"\n",
    "        if re.fullmatch(r\"\\d{4}\", p):\n",
    "            return f\"{int(p):04d}-01-01\"\n",
    "        return p\n",
    "\n",
    "    if code.startswith(\"PN\"):\n",
    "        m = re.fullmatch(r\"(\\d{4})-(\\d{1,2})-(\\d{1,2})\", p)\n",
    "        if m:\n",
    "            y, mo, _ = m.groups()\n",
    "            return f\"{int(y):04d}-{int(mo)}\"\n",
    "        m = re.fullmatch(r\"(\\d{4})-(\\d{1,2})\", p)\n",
    "        if m:\n",
    "            y, mo = m.groups()\n",
    "            return f\"{int(y):04d}-{int(mo)}\"\n",
    "        if re.fullmatch(r\"\\d{4}\", p):\n",
    "            return f\"{int(p):04d}-1\"\n",
    "        return p\n",
    "\n",
    "    return p\n",
    "\n",
    "def _read_parquet_safe(path: Path) -> pd.DataFrame | None:\n",
    "    try:\n",
    "        return pd.read_parquet(path)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _write_parquet_safe(df: pd.DataFrame, path: Path) -> None:\n",
    "    try:\n",
    "        df.to_parquet(path)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def bcrp_get(series_codes, start: str | None = None, end: str | None = None, lang: str = \"esp\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch BCRPData series using the official BCRP API (JSON).\n",
    "    Returns columns: ['date', <code1>, <code2>, ...]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import requests\n",
    "    except Exception:\n",
    "        warnings.warn(\"requests not available; returning empty DataFrame.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    if isinstance(series_codes, (list, tuple)):\n",
    "        codes_list = [str(c).strip() for c in series_codes]\n",
    "        codes = \"-\".join(codes_list)\n",
    "        first_code = codes_list[0]\n",
    "    else:\n",
    "        codes = str(series_codes).strip()\n",
    "        codes_list = codes.split(\"-\")\n",
    "        first_code = codes_list[0]\n",
    "\n",
    "    start_n = _normalize_bcrp_period(first_code, start)\n",
    "    end_n = _normalize_bcrp_period(first_code, end)\n",
    "\n",
    "    key = _hash_key(\"bcrp\", codes, start_n or \"\", end_n or \"\", lang)\n",
    "    cache_path = CACHE_DIR / f\"bcrp_{key}.parquet\"\n",
    "    cached = _read_parquet_safe(cache_path)\n",
    "    if cached is not None:\n",
    "        return cached\n",
    "\n",
    "    base_url = \"https://estadisticas.bcrp.gob.pe/estadisticas/series/api\"\n",
    "    parts = [base_url, codes, \"json\"]\n",
    "    if start_n and end_n:\n",
    "        parts += [start_n, end_n]\n",
    "    if lang:\n",
    "        parts += [lang]\n",
    "    url = \"/\".join(parts)\n",
    "\n",
    "    try:\n",
    "        r = requests.get(url, timeout=45)\n",
    "        r.raise_for_status()\n",
    "        obj = r.json()\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"BCRP request failed ({repr(e)}). Returning empty DataFrame.\")\n",
    "        return pd.DataFrame(columns=[\"date\"] + codes_list)\n",
    "\n",
    "    periods = obj.get(\"periods\", [])\n",
    "    rows = []\n",
    "    for p in periods:\n",
    "        name = p.get(\"name\")\n",
    "        vals = p.get(\"values\", [])\n",
    "        if isinstance(vals, str):\n",
    "            vals = [vals]\n",
    "        if name is None or not isinstance(vals, list):\n",
    "            continue\n",
    "        vals = (vals + [None] * len(codes_list))[:len(codes_list)]\n",
    "        rows.append([name] + vals)\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\"date\"] + codes_list)\n",
    "    if df.shape[0] == 0:\n",
    "        return pd.DataFrame(columns=[\"date\"] + codes_list)\n",
    "\n",
    "    df[\"date\"] = df[\"date\"].apply(_parse_bcrp_period)\n",
    "    for c in codes_list:\n",
    "        df[c] = df[c].apply(_to_float)\n",
    "\n",
    "    df = df.dropna(subset=[\"date\"]).sort_values(\"date\").reset_index(drop=True)\n",
    "    _write_parquet_safe(df, cache_path)\n",
    "    return df\n",
    "\n",
    "def fred_get(series_ids, start: str | None = None, end: str | None = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch FRED series WITHOUT an API key using the CSV export used by FRED graphs.\n",
    "\n",
    "    Uses cosd/coed to limit the download window (more reliable than downloading full history).\n",
    "    Returns columns: ['date', <series1>, <series2>, ...]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import requests\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"requests not available ({e}); returning empty DataFrame.\")\n",
    "        cols = [str(s).strip() for s in series_ids] if isinstance(series_ids, (list, tuple)) else [str(series_ids).strip()]\n",
    "        return pd.DataFrame(columns=[\"date\"] + cols)\n",
    "\n",
    "    from io import StringIO\n",
    "\n",
    "    def _fetch_one(sid: str) -> pd.DataFrame:\n",
    "        sid = str(sid).strip()\n",
    "        key = _hash_key(\"fred_v3\", sid, start or \"\", end or \"\")\n",
    "        cache_path = CACHE_DIR / f\"fred_{key}.parquet\"\n",
    "        cached = _read_parquet_safe(cache_path)\n",
    "        if cached is not None:\n",
    "            return cached\n",
    "\n",
    "        url = \"https://fred.stlouisfed.org/graph/fredgraph.csv\"\n",
    "        params = {\"id\": sid}\n",
    "        if start:\n",
    "            params[\"cosd\"] = str(start)\n",
    "        if end:\n",
    "            params[\"coed\"] = str(end)\n",
    "\n",
    "        headers = {\"User-Agent\": \"python-finance-course/1.0 (contact: student@example.com)\"}\n",
    "\n",
    "        try:\n",
    "            r = requests.get(url, params=params, headers=headers, timeout=60)\n",
    "            r.raise_for_status()\n",
    "            text = r.text\n",
    "        except Exception as e:\n",
    "            warnings.warn(f\"FRED request failed for {sid} ({repr(e)}). Returning empty.\")\n",
    "            return pd.DataFrame(columns=[\"date\", sid])\n",
    "\n",
    "        # Guardrails: detect HTML or unexpected payloads\n",
    "        first_line = (text.splitlines()[0].strip() if text else \"\")\n",
    "        if first_line.lower().startswith(\"<!doctype\") or \"<html\" in first_line.lower():\n",
    "            warnings.warn(f\"FRED returned HTML for {sid}. Returning empty.\")\n",
    "            return pd.DataFrame(columns=[\"date\", sid])\n",
    "\n",
    "        if \"DATE\" not in first_line.upper() or sid.upper() not in first_line.upper():\n",
    "            warnings.warn(f\"FRED response header unexpected for {sid}: {first_line[:120]} ... Returning empty.\")\n",
    "            return pd.DataFrame(columns=[\"date\", sid])\n",
    "\n",
    "        df = pd.read_csv(StringIO(text))\n",
    "        # Normalize column names\n",
    "        df = df.rename(columns={df.columns[0]: \"date\", df.columns[1]: sid})\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "\n",
    "        # FRED missing values are often \".\"\n",
    "        s = df[sid].astype(str).str.strip().replace({\".\": np.nan, \"\": np.nan, \"NA\": np.nan, \"NaN\": np.nan})\n",
    "        df[sid] = pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "        df = df.dropna(subset=[\"date\"]).sort_values(\"date\").reset_index(drop=True)\n",
    "        _write_parquet_safe(df, cache_path)\n",
    "        return df\n",
    "\n",
    "    if isinstance(series_ids, (list, tuple)):\n",
    "        cols = [str(s).strip() for s in series_ids]\n",
    "        out = None\n",
    "        for sid in cols:\n",
    "            dfi = _fetch_one(sid)\n",
    "            out = dfi if out is None else out.merge(dfi, on=\"date\", how=\"outer\")\n",
    "        if out is None:\n",
    "            return pd.DataFrame(columns=[\"date\"] + cols)\n",
    "        return out.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "    return _fetch_one(series_ids)\n",
    "\n",
    "\n",
    "\n",
    "def treasury_get_debt_to_penny(start_date: str = \"2024-01-01\") -> dict:\n",
    "    \"\"\"\n",
    "    Fetch U.S. Treasury Fiscal Data (Debt to the Penny) as a raw dictionary.\n",
    "    API docs: https://fiscaldata.treasury.gov/api-documentation/\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import requests\n",
    "    except Exception:\n",
    "        warnings.warn(\"requests not available; returning empty dict.\")\n",
    "        return {}\n",
    "\n",
    "    base = \"https://api.fiscaldata.treasury.gov/services/api/fiscal_service/v2\"\n",
    "    endpoint = \"accounting/od/debt_to_penny\"\n",
    "    url = f\"{base}/{endpoint}\"\n",
    "\n",
    "    params = {\n",
    "        \"fields\": \"record_date,tot_pub_debt_out_amt,debt_held_public_amt,intragov_hold_amt\",\n",
    "        \"filter\": f\"record_date:gte:{start_date}\",\n",
    "        \"sort\": \"-record_date\",\n",
    "        \"page[size]\": 1000\n",
    "    }\n",
    "\n",
    "    headers = {\"User-Agent\": \"python-finance-course/1.0 (contact: student@example.com)\"}\n",
    "\n",
    "    try:\n",
    "        r = requests.get(url, params=params, headers=headers, timeout=45)\n",
    "        r.raise_for_status()\n",
    "        return r.json()\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"Treasury API request failed ({repr(e)}). Returning empty dict.\")\n",
    "        return {}\n",
    "\n",
    "def save_pickle(obj, path: Path) -> None:\n",
    "    import pickle\n",
    "    path.parent.mkdir(exist_ok=True, parents=True)\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_pickle(path: Path):\n",
    "    import pickle\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def safe_head(df: pd.DataFrame, n: int = 5) -> pd.DataFrame:\n",
    "    return df.head(n) if isinstance(df, pd.DataFrame) else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e04c61d",
   "metadata": {},
   "source": [
    "## Real data setup\n",
    "\n",
    "We fetch a small amount of real data.\n",
    "\n",
    "**Peru (BCRPData):**\n",
    "- `PD04650MD`: Net International Reserves (daily)\n",
    "- `PN01652XM`: Copper price (LME, monthly)\n",
    "\n",
    "**US (FRED):**\n",
    "- `DGS10`: 10-year Treasury yield (daily)\n",
    "- `FEDFUNDS`: Effective federal funds rate (monthly)\n",
    "\n",
    "**US Treasury Fiscal Data:**\n",
    "- Debt to the Penny: total public debt outstanding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5301cee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((877, 2), (131, 2), (1576, 3), ['data', 'meta', 'links'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time windows (adjust if you want)\n",
    "START_DAILY = \"2020-01-01\"\n",
    "END_DAILY = \"2025-12-18\"\n",
    "START_MONTHLY = \"2015-01-01\"\n",
    "\n",
    "# Peru (BCRP)\n",
    "rin = bcrp_get(\"PD04650MD\", start=START_DAILY, end=END_DAILY).rename(columns={\"PD04650MD\": \"RIN_USD_mn\"})\n",
    "copper = bcrp_get(\"PN01652XM\", start=START_MONTHLY, end=END_DAILY).rename(columns={\"PN01652XM\": \"Copper_LME_cents_per_lb\"})\n",
    "\n",
    "# US (FRED)\n",
    "macro_us = fred_get([\"DGS10\", \"FEDFUNDS\"], start=START_DAILY)\n",
    "\n",
    "# US Treasury Fiscal Data (raw dict, then saved for the dictionary exercise)\n",
    "treasury_raw = treasury_get_debt_to_penny(start_date=\"2024-01-01\")\n",
    "save_pickle(treasury_raw, Path(\"data/treasury_debt_to_penny_raw.pkl\"))\n",
    "\n",
    "rin.shape, copper.shape, macro_us.shape, list(treasury_raw.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71d20f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>RIN_USD_mn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>68820.232306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>68648.663705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>68790.147192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>68812.399398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>68976.740110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    RIN_USD_mn\n",
       "0 2020-02-03  68820.232306\n",
       "1 2020-02-04  68648.663705\n",
       "2 2020-02-05  68790.147192\n",
       "3 2020-02-06  68812.399398\n",
       "4 2020-02-07  68976.740110"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Copper_LME_cents_per_lb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>265.576789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>259.875545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>269.418923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>273.904333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>285.478621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  Copper_LME_cents_per_lb\n",
       "0 2015-01-01               265.576789\n",
       "1 2015-02-01               259.875545\n",
       "2 2015-03-01               269.418923\n",
       "3 2015-04-01               273.904333\n",
       "4 2015-05-01               285.478621"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>DGS10</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>1.88</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>1.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>1.81</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>1.83</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  DGS10  FEDFUNDS\n",
       "0 2020-01-01    NaN      1.55\n",
       "1 2020-01-02   1.88       NaN\n",
       "2 2020-01-03   1.80       NaN\n",
       "3 2020-01-06   1.81       NaN\n",
       "4 2020-01-07   1.83       NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(safe_head(rin))\n",
    "display(safe_head(copper))\n",
    "display(safe_head(macro_us))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b83cf88",
   "metadata": {},
   "source": [
    "##  <a id='#5.1.'>5.1. Functions</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae2aae2",
   "metadata": {},
   "source": [
    "### <a id = '#5.1.1.'> 5.1.1. The importance of Python functions </a>\n",
    "\n",
    "**Assignment:** write a function that standardizes a single-series DataFrame.\n",
    "\n",
    "Requirements:\n",
    "1. Input: a DataFrame with a `date` column and exactly **one value column**.\n",
    "2. Output: a DataFrame with columns `date` and `value`.\n",
    "3. Must:\n",
    "   - convert `date` to datetime\n",
    "   - sort by date\n",
    "   - drop rows where `date` is missing\n",
    "4. Use the function for both `rin` and `copper`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb198ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'value'] (0, 2)\n",
      "['date', 'value'] (0, 2)\n"
     ]
    }
   ],
   "source": [
    "# TODO (students)\n",
    "def standardize_single_series(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if not isinstance(df, pd.DataFrame) or df.empty:\n",
    "        return pd.DataFrame(columns=[\"date\", \"value\"])\n",
    "\n",
    "    if \"date\" not in df.columns:\n",
    "        raise ValueError(\"Input DataFrame must contain a 'date' column.\")\n",
    "\n",
    "    value_cols = [c for c in df.columns if c != \"date\"]\n",
    "    if len(value_cols) != 1:\n",
    "        raise ValueError(f\"Expected exactly 1 value column besides 'date', got {len(value_cols)}: {value_cols}\")\n",
    "\n",
    "    val_col = value_cols[0]\n",
    "\n",
    "    out = df[[\"date\", val_col]].copy()\n",
    "    out[\"date\"] = pd.to_datetime(out[\"date\"], errors=\"coerce\")\n",
    "    out[val_col] = pd.to_numeric(out[val_col], errors=\"coerce\")\n",
    "    out = out.dropna(subset=[\"date\"]).sort_values(\"date\").reset_index(drop=True)\n",
    "    return out.rename(columns={val_col: \"value\"})\n",
    "\n",
    "rin_std = standardize_single_series(rin)\n",
    "copper_std = standardize_single_series(copper)\n",
    "\n",
    "print(rin_std.columns.tolist(), rin_std.shape)\n",
    "print(copper_std.columns.tolist(), copper_std.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57041a23",
   "metadata": {},
   "source": [
    "### <a id='#5.1.2.'> 5.1.2. Basic structure of a function </a>\n",
    "\n",
    "**Assignment:** create a function that computes percent changes (in %).\n",
    "\n",
    "Requirements:\n",
    "- Input: `pd.Series`\n",
    "- Parameter: `periods: int = 1`\n",
    "- Output: `pd.Series`\n",
    "\n",
    "Use it to compute:\n",
    "- daily % change of `RIN_USD_mn`\n",
    "- daily % change of `DGS10`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6290fbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: float64)\n",
      "Series([], dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "def pct_change_percent(x: pd.Series, periods: int = 1) -> pd.Series:\n",
    "    \"\"\"Compute percent changes in **percent units** (e.g., 1.2 means 1.2%).\"\"\"\n",
    "    if x is None or not isinstance(x, pd.Series) or x.empty:\n",
    "        return pd.Series(dtype=float)\n",
    "\n",
    "    s = pd.to_numeric(x, errors=\"coerce\")\n",
    "    out = s.pct_change(periods=periods) * 100.0\n",
    "    out.name = getattr(x, \"name\", None)\n",
    "    return out\n",
    "\n",
    "rin_ret = pct_change_percent(rin.set_index(\"date\")[\"RIN_USD_mn\"])\n",
    "dgs10_ret = pct_change_percent(macro_us.set_index(\"date\")[\"DGS10\"])\n",
    "\n",
    "print(rin_ret.dropna().head())\n",
    "print(dgs10_ret.dropna().head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8829751e",
   "metadata": {},
   "source": [
    "### <a id='#5.1.3.'>5.1.3. Function without `return` </a>\n",
    "\n",
    "**Assignment:** write a function that prints a compact report:\n",
    "- number of observations\n",
    "- number of missing values\n",
    "- min / max\n",
    "\n",
    "Call it for `RIN_USD_mn` and for `DGS10`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59f1d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "def print_series_report(x: pd.Series, name: str) -> None:\n",
    "    \"\"\"Print a compact report: n, missing, min/max (ignoring missing).\"\"\"\n",
    "    if x is None or not isinstance(x, pd.Series):\n",
    "        print(f\"[{name}] Invalid input (expected a pandas Series).\")\n",
    "        return\n",
    "\n",
    "    s = pd.to_numeric(x, errors=\"coerce\")\n",
    "    n_obs = int(s.shape[0])\n",
    "    n_missing = int(s.isna().sum())\n",
    "    n_non_missing = int(s.notna().sum())\n",
    "\n",
    "    if n_non_missing == 0:\n",
    "        print(f\"[{name}] n={n_obs} | missing={n_missing} | min=NA | max=NA\")\n",
    "        return\n",
    "\n",
    "    s_min = float(s.min(skipna=True))\n",
    "    s_max = float(s.max(skipna=True))\n",
    "    print(f\"[{name}] n={n_obs} | missing={n_missing} | min={s_min:.4f} | max={s_max:.4f}\")\n",
    "\n",
    "if rin.shape[0] > 0:\n",
    "    print_series_report(rin[\"RIN_USD_mn\"], \"Peru: Net International Reserves (RIN)\")\n",
    "if macro_us.shape[0] > 0:\n",
    "    print_series_report(macro_us[\"DGS10\"], \"US: 10Y Treasury Yield (DGS10)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c78c6e6",
   "metadata": {},
   "source": [
    "### <a id='#5.1.5.'>5.1.5. Multiple objects for return </a>\n",
    "\n",
    "**Assignment:** create a function that returns **two objects**:\n",
    "1. a cleaned return series (drop NaNs)\n",
    "2. a scalar volatility estimate (standard deviation)\n",
    "\n",
    "Use it on `DGS10` percent changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fff8f7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: float64)\n",
      "Vol: nan\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "def returns_and_volatility(x: pd.Series) -> tuple[pd.Series, float]:\n",
    "    \"\"\"Return clean returns and their sample volatility (std dev).\"\"\"\n",
    "    if x is None or not isinstance(x, pd.Series) or x.empty:\n",
    "        return pd.Series(dtype=float), float(\"nan\")\n",
    "\n",
    "    clean = pd.to_numeric(x, errors=\"coerce\").dropna()\n",
    "    vol = float(clean.std(ddof=1)) if clean.shape[0] >= 2 else float(\"nan\")\n",
    "    return clean, vol\n",
    "\n",
    "dgs10_clean_ret, dgs10_vol = returns_and_volatility(dgs10_ret)\n",
    "print(dgs10_clean_ret.head())\n",
    "print(\"Vol:\", dgs10_vol)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379037cb",
   "metadata": {},
   "source": [
    "### <a id='#5.1.5.'>5.1.5. If condition with return </a>\n",
    "\n",
    "**Assignment:** write a validation function.\n",
    "\n",
    "Requirements:\n",
    "- Input: DataFrame with `date` and `value`\n",
    "- If there are fewer than `min_n` rows, return `None`\n",
    "- Otherwise, return the DataFrame\n",
    "\n",
    "Test it with `copper_std` (monthly series can be shorter).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "458601f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copper validated: False\n"
     ]
    }
   ],
   "source": [
    "# TODO (students)\n",
    "def validate_min_rows(df: pd.DataFrame, min_n: int = 24):\n",
    "    if isinstance(df, pd.DataFrame) and df.shape[0] >= min_n:\n",
    "        return df\n",
    "    return None\n",
    "\n",
    "copper_ok = validate_min_rows(copper_std, min_n=24)\n",
    "print(\"Copper validated:\", copper_ok is not None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28eff3f",
   "metadata": {},
   "source": [
    "### <a id='#5.1.6.'>5.1.6. Default values to parameters </a>\n",
    "\n",
    "**Assignment:** implement winsorization with default quantiles.\n",
    "\n",
    "Write a function:\n",
    "`winsorize(x, lower_q=0.01, upper_q=0.99)`\n",
    "\n",
    "Use it on `RIN_USD_mn`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6df91ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "def winsorize(x: pd.Series, lower_q: float = 0.01, upper_q: float = 0.99) -> pd.Series:\n",
    "    \"\"\"Clip a series to the [lower_q, upper_q] quantile range.\"\"\"\n",
    "    if x is None or not isinstance(x, pd.Series) or x.empty:\n",
    "        return pd.Series(dtype=float)\n",
    "\n",
    "    s = pd.to_numeric(x, errors=\"coerce\")\n",
    "    lo = s.quantile(lower_q)\n",
    "    hi = s.quantile(upper_q)\n",
    "    return s.clip(lower=lo, upper=hi)\n",
    "\n",
    "rin_w = winsorize(rin.set_index(\"date\")[\"RIN_USD_mn\"])\n",
    "print(rin_w.dropna().head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5263d5fc",
   "metadata": {},
   "source": [
    "### <a id='#5.1.7.'>5.1.7. Type hints for parameters and return types </a>\n",
    "\n",
    "**Assignment:** add type hints and implement a merge helper.\n",
    "\n",
    "Write:\n",
    "`merge_on_date(left: pd.DataFrame, right: pd.DataFrame, how: str = 'inner') -> pd.DataFrame`\n",
    "\n",
    "Then merge `rin` with `macro_us[['date','DGS10']]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0702b91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "def merge_on_date(left: pd.DataFrame, right: pd.DataFrame, how: str = \"inner\") -> pd.DataFrame:\n",
    "    \"\"\"Merge two DataFrames on a 'date' column after coercing to datetime.\"\"\"\n",
    "    if not isinstance(left, pd.DataFrame) or not isinstance(right, pd.DataFrame):\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    l = left.copy()\n",
    "    r = right.copy()\n",
    "\n",
    "    if \"date\" not in l.columns or \"date\" not in r.columns:\n",
    "        raise ValueError(\"Both DataFrames must contain a 'date' column.\")\n",
    "\n",
    "    l[\"date\"] = pd.to_datetime(l[\"date\"], errors=\"coerce\")\n",
    "    r[\"date\"] = pd.to_datetime(r[\"date\"], errors=\"coerce\")\n",
    "\n",
    "    l = l.dropna(subset=[\"date\"])\n",
    "    r = r.dropna(subset=[\"date\"])\n",
    "\n",
    "    out = l.merge(r, on=\"date\", how=how)\n",
    "    return out.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "rin_dgs10 = merge_on_date(rin, macro_us[[\"date\", \"DGS10\"]], how=\"inner\")\n",
    "print(rin_dgs10.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e7c22a",
   "metadata": {},
   "source": [
    "### <a id='#5.1.8.'>5.1.8. Local variables vs Global variables </a>\n",
    "\n",
    "**Assignment:** demonstrate the difference clearly.\n",
    "\n",
    "1. Create a global variable `BASE_CCY = 'USD'`.\n",
    "2. Write `format_label(series_name: str) -> str` that uses the global variable.\n",
    "3. Inside the function, create a local variable `suffix = '(global ccy)'`.\n",
    "4. Return a label like: `'{series_name} - USD (global ccy)'`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d2cb901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIN - USD (global ccy)\n"
     ]
    }
   ],
   "source": [
    "# TODO (students)\n",
    "BASE_CCY = \"USD\"\n",
    "\n",
    "def format_label(series_name: str) -> str:\n",
    "    suffix = \"(global ccy)\"\n",
    "    return f\"{series_name} - {BASE_CCY} {suffix}\"\n",
    "\n",
    "print(format_label(\"RIN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88beb04e",
   "metadata": {},
   "source": [
    "### <a id='#5.1.9.'>5.1.9. `*args` </a>\n",
    "\n",
    "**Assignment:** implement a function that accepts multiple series codes.\n",
    "\n",
    "Write:\n",
    "`fetch_bcrp_many(*codes: str, start: str, end: str) -> pd.DataFrame`\n",
    "\n",
    "Requirements:\n",
    "- Use the provided `bcrp_get` inside.\n",
    "- Return a DataFrame with `date` and one column per code.\n",
    "- Call it with two codes: `PD04650MD` and `PD04649MD`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5070e914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "def fetch_bcrp_many(*codes: str, start: str, end: str) -> pd.DataFrame:\n",
    "    \"\"\"Fetch multiple BCRP series and return a DataFrame with a datetime 'date' column.\"\"\"\n",
    "    if len(codes) == 0:\n",
    "        return pd.DataFrame(columns=[\"date\"])\n",
    "\n",
    "    df = bcrp_get(list(codes), start=start, end=end)\n",
    "\n",
    "    if \"date\" in df.columns:\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "        df = df.dropna(subset=[\"date\"]).sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "two_series = fetch_bcrp_many(\"PD04650MD\", \"PN01652XM\", start=START_DAILY, end=END_DAILY)\n",
    "print(two_series.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d08e9b9",
   "metadata": {},
   "source": [
    "### <a id='#5.1.10.'>5.1.10. `**kwargs` </a>\n",
    "\n",
    "**Assignment:** write a wrapper around `DataFrame.describe`.\n",
    "\n",
    "Write:\n",
    "`describe_df(df: pd.DataFrame, **kwargs) -> pd.DataFrame`\n",
    "\n",
    "Then call it on `macro_us[['DGS10']]` with custom percentiles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "239565f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "def describe_df(df: pd.DataFrame, **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"Thin wrapper around DataFrame.describe(**kwargs) with numeric coercion.\"\"\"\n",
    "    if not isinstance(df, pd.DataFrame) or df.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    tmp = df.copy()\n",
    "    for c in tmp.columns:\n",
    "        tmp[c] = pd.to_numeric(tmp[c], errors=\"ignore\")\n",
    "    return tmp.describe(**kwargs)\n",
    "\n",
    "desc_yields = describe_df(macro_us[[\"DGS10\"]], percentiles=[0.05, 0.5, 0.95])\n",
    "print(desc_yields)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fe3aa7",
   "metadata": {},
   "source": [
    "## Excersise\n",
    "#### Importing a Dictionary\n",
    "\n",
    "We use a **real** nested dictionary from the **U.S. Treasury Fiscal Data API** (saved as `data/treasury_debt_to_penny_raw.pkl`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3489eb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict, ['data', 'meta', 'links'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dict = load_pickle(Path('data/treasury_debt_to_penny_raw.pkl'))\n",
    "type(raw_dict), list(raw_dict.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fdd8fa",
   "metadata": {},
   "source": [
    "### Part A — Extract to lists\n",
    "\n",
    "**Assignment:** using a `for` loop, extract these into Python lists:\n",
    "- `record_date`\n",
    "- `tot_pub_debt_out_amt`\n",
    "- `debt_held_public_amt`\n",
    "- `intragov_hold_amt`\n",
    "\n",
    "Then build a DataFrame with those columns and convert numeric columns to floats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eee66b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "data = raw_dict.get(\"data\", []) if isinstance(raw_dict, dict) else []\n",
    "\n",
    "record_dates = []\n",
    "tot_debt = []\n",
    "public_debt = []\n",
    "intragov = []\n",
    "\n",
    "for row in data:\n",
    "    record_dates.append(row.get(\"record_date\"))\n",
    "    tot_debt.append(row.get(\"tot_pub_debt_out_amt\"))\n",
    "    public_debt.append(row.get(\"debt_held_public_amt\"))\n",
    "    intragov.append(row.get(\"intragov_hold_amt\"))\n",
    "\n",
    "debt_df = pd.DataFrame({\n",
    "    \"record_date\": pd.to_datetime(record_dates, errors=\"coerce\"),\n",
    "    \"tot_pub_debt_out_amt\": pd.to_numeric(pd.Series(tot_debt), errors=\"coerce\"),\n",
    "    \"debt_held_public_amt\": pd.to_numeric(pd.Series(public_debt), errors=\"coerce\"),\n",
    "    \"intragov_hold_amt\": pd.to_numeric(pd.Series(intragov), errors=\"coerce\"),\n",
    "}).dropna(subset=[\"record_date\"]).sort_values(\"record_date\").reset_index(drop=True)\n",
    "\n",
    "print(debt_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021d994c",
   "metadata": {},
   "source": [
    "### Part B — Turn it into a function\n",
    "\n",
    "**Assignment:** define:\n",
    "`treasury_debt_dict_to_df(obj: dict) -> pd.DataFrame`\n",
    "\n",
    "Return a clean DataFrame sorted by date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e005d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "def treasury_debt_dict_to_df(obj: dict) -> pd.DataFrame:\n",
    "    \"\"\"Convert a Treasury Fiscal Data response dict into a clean DataFrame.\"\"\"\n",
    "    if not isinstance(obj, dict):\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    data = obj.get(\"data\", [])\n",
    "    if not isinstance(data, list) or len(data) == 0:\n",
    "        return pd.DataFrame(columns=[\n",
    "            \"record_date\",\n",
    "            \"tot_pub_debt_out_amt\",\n",
    "            \"debt_held_public_amt\",\n",
    "            \"intragov_hold_amt\",\n",
    "        ])\n",
    "\n",
    "    df = pd.DataFrame(data).copy()\n",
    "\n",
    "    keep = [\"record_date\", \"tot_pub_debt_out_amt\", \"debt_held_public_amt\", \"intragov_hold_amt\"]\n",
    "    for c in keep:\n",
    "        if c not in df.columns:\n",
    "            df[c] = np.nan\n",
    "    df = df[keep]\n",
    "\n",
    "    df[\"record_date\"] = pd.to_datetime(df[\"record_date\"], errors=\"coerce\")\n",
    "    for c in [\"tot_pub_debt_out_amt\", \"debt_held_public_amt\", \"intragov_hold_amt\"]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    df = df.dropna(subset=[\"record_date\"]).sort_values(\"record_date\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "debt_df2 = treasury_debt_dict_to_df(raw_dict)\n",
    "print(debt_df2.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832ddc80",
   "metadata": {},
   "source": [
    "### Part C — Row iteration\n",
    "\n",
    "**Assignment:**\n",
    "1. Create `raw_table = pd.DataFrame(raw_dict['data'])`.\n",
    "2. Iterate over rows (e.g. `.iterrows()`), and build `debt_small` with only:\n",
    "   `record_date` and `tot_pub_debt_out_amt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "08ff6455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "data = raw_dict.get(\"data\", []) if isinstance(raw_dict, dict) else []\n",
    "raw_table = pd.DataFrame(data)\n",
    "\n",
    "rows = []\n",
    "if not raw_table.empty:\n",
    "    for _, row in raw_table.iterrows():\n",
    "        rows.append({\n",
    "            \"record_date\": row.get(\"record_date\"),\n",
    "            \"tot_pub_debt_out_amt\": row.get(\"tot_pub_debt_out_amt\"),\n",
    "        })\n",
    "\n",
    "debt_small = pd.DataFrame(rows)\n",
    "if not debt_small.empty:\n",
    "    debt_small[\"record_date\"] = pd.to_datetime(debt_small[\"record_date\"], errors=\"coerce\")\n",
    "    debt_small[\"tot_pub_debt_out_amt\"] = pd.to_numeric(debt_small[\"tot_pub_debt_out_amt\"], errors=\"coerce\")\n",
    "    debt_small = debt_small.dropna(subset=[\"record_date\"]).sort_values(\"record_date\").reset_index(drop=True)\n",
    "\n",
    "print(debt_small.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f43a834",
   "metadata": {},
   "source": [
    "### <a id='#5.2.'>5.2. Class </a>\n",
    "\n",
    "Practice class basics using the same datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a782b51",
   "metadata": {},
   "source": [
    "###  <a id='#5.2.2.'> 5.2.2. Defining a class </a>\n",
    "\n",
    "**Assignment:** define a class `MacroSeries`.\n",
    "\n",
    "Attributes:\n",
    "- `name` (str)\n",
    "- `source` (str)\n",
    "- `data` (pd.DataFrame with columns: date, value)\n",
    "\n",
    "Methods:\n",
    "- `latest_value()` → float\n",
    "- `n_obs()` → int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "51602a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIN BCRP\n",
      "DGS10 FRED\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "class MacroSeries:\n",
    "    \"\"\"Represents one macro/financial time series.\"\"\"\n",
    "\n",
    "    def __init__(self, name: str, source: str, data: pd.DataFrame):\n",
    "        self.name = name\n",
    "        self.source = source\n",
    "\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            raise TypeError(\"data must be a pandas DataFrame.\")\n",
    "        if \"date\" not in data.columns or \"value\" not in data.columns:\n",
    "            raise ValueError(\"data must contain columns ['date', 'value'].\")\n",
    "\n",
    "        df = data.copy()\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "        df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
    "        df = df.dropna(subset=[\"date\"]).sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "        self.data = df\n",
    "\n",
    "    def latest_value(self) -> float:\n",
    "        \"\"\"Latest non-missing value by date.\"\"\"\n",
    "        if self.data.empty:\n",
    "            return float(\"nan\")\n",
    "        s = self.data[\"value\"].dropna()\n",
    "        if s.empty:\n",
    "            return float(\"nan\")\n",
    "        return float(s.iloc[-1])\n",
    "\n",
    "    def n_obs(self) -> int:\n",
    "        \"\"\"Number of non-missing observations.\"\"\"\n",
    "        if self.data.empty:\n",
    "            return 0\n",
    "        return int(self.data[\"value\"].notna().sum())\n",
    "\n",
    "    def pct_change(self, periods: int = 1) -> pd.Series:\n",
    "        \"\"\"Percent change in percent units (%). Returns a Series indexed by date.\"\"\"\n",
    "        if self.data.empty:\n",
    "            return pd.Series(dtype=float)\n",
    "\n",
    "        s = self.data.set_index(\"date\")[\"value\"]\n",
    "        out = s.pct_change(periods=periods) * 100.0\n",
    "        out.name = f\"{self.name}_pct_change\"\n",
    "        return out\n",
    "\n",
    "\n",
    "    def label(self) -> str:\n",
    "        \"\"\"Human-readable label for printing/logging.\"\"\"\n",
    "        nm = getattr(self, 'name', '')\n",
    "        src_ = getattr(self, 'source', '')\n",
    "        if nm and src_:\n",
    "            return f\"{nm} ({src_})\"\n",
    "        return str(nm or src_ or 'MacroSeries')\n",
    "\n",
    "rin_obj = MacroSeries(\"Peru RIN (USD mn)\", \"BCRPData\", rin_std)\n",
    "\n",
    "dgs10_df = macro_us[[\"date\", \"DGS10\"]].rename(columns={\"DGS10\": \"value\"})\n",
    "dgs10_obj = MacroSeries(\"DGS10\", \"FRED\", dgs10_df)\n",
    "\n",
    "print(rin_obj.name, rin_obj.source)\n",
    "print(dgs10_obj.name, dgs10_obj.source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b886efa1",
   "metadata": {},
   "source": [
    "### <a id='#5.2.3.'> 5.2.3. Attributes </a>\n",
    "\n",
    "**Assignment:** access and modify attributes.\n",
    "\n",
    "1. Print `rin_obj.name` and `rin_obj.source`.\n",
    "2. Update `rin_obj.name` to `Peru RIN (USD mn)`.\n",
    "3. Print again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af8092cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIN BCRP\n",
      "Peru RIN (USD mn) BCRP\n"
     ]
    }
   ],
   "source": [
    "print(rin_obj.name, rin_obj.source)\n",
    "rin_obj.name = 'Peru RIN (USD mn)'\n",
    "print(rin_obj.name, rin_obj.source)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea047b7",
   "metadata": {},
   "source": [
    "### <a id='#5.2.5.'> 5.2.5. Method </a>\n",
    "\n",
    "**Assignment:** implement a method:\n",
    "`pct_change(self, periods: int = 1) -> pd.Series`\n",
    "that returns percent changes of the `value` column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2fdd1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implement pct_change inside MacroSeries. Current error: AttributeError(\"'MacroSeries' object has no attribute 'pct_change'\")\n"
     ]
    }
   ],
   "source": [
    "# Solution: pct_change() inside MacroSeries\n",
    "out = rin_obj.pct_change(periods=1)\n",
    "print(out.dropna().head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63df25d",
   "metadata": {},
   "source": [
    "###  <a id='#5.2.6.'> 5.2.6. __init__() </a>\n",
    "\n",
    "**Assignment:** validate inputs inside `__init__`.\n",
    "\n",
    "Modify `__init__` so that if `data` does not have columns `date` and `value`, it raises `ValueError`.\n",
    "Then intentionally try to create a bad object and confirm it raises an error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31c86098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you see this, you did not validate columns yet.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    bad = MacroSeries(\"BAD\", \"TEST\", pd.DataFrame({\"x\":[1,2], \"y\":[3,4]}))\n",
    "    print(\"If you see this, you did not validate columns yet.\")\n",
    "except Exception as e:\n",
    "    print(\"Expected error:\", repr(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd00f8a",
   "metadata": {},
   "source": [
    "### <a id='#5.2.7.'> 5.2.7. Self</a>\n",
    "\n",
    "**Assignment:** use `self` to build a label.\n",
    "\n",
    "Add `label(self) -> str` returning `'{name} [{source}]'`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e957e5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implement label() inside MacroSeries. Current error: AttributeError(\"'MacroSeries' object has no attribute 'label'\")\n"
     ]
    }
   ],
   "source": [
    "print(rin_obj.label())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee364b7",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "**Mini-project (assigned):** create `MacroDashboard` to manage multiple series.\n",
    "\n",
    "Class requirements:\n",
    "- attribute `series_list` (list)\n",
    "- method `add(self, s: MacroSeries) -> None`\n",
    "- method `to_wide(self) -> pd.DataFrame` that merges all series on date (wide format)\n",
    "\n",
    "Test it by adding `rin_obj` and `dgs10_obj`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "efe46809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# TODO (students)\n",
    "class MacroDashboard:\n",
    "    def __init__(self):\n",
    "        self.series_list = []\n",
    "\n",
    "    def add(self, s: MacroSeries) -> None:\n",
    "        if s is None:\n",
    "            raise ValueError(\"Cannot add None.\")\n",
    "        if not hasattr(s, \"name\") or not hasattr(s, \"data\"):\n",
    "            raise TypeError(\"Expected a MacroSeries-like object with attributes 'name' and 'data'.\")\n",
    "        if not isinstance(s.data, pd.DataFrame):\n",
    "            raise TypeError(\"s.data must be a pandas DataFrame.\")\n",
    "        if \"date\" not in s.data.columns or \"value\" not in s.data.columns:\n",
    "            raise ValueError(\"s.data must contain columns ['date', 'value'].\")\n",
    "        self.series_list.append(s)\n",
    "\n",
    "    def to_wide(self) -> pd.DataFrame:\n",
    "        if len(self.series_list) == 0:\n",
    "            return pd.DataFrame(columns=[\"date\"])\n",
    "\n",
    "        out = None\n",
    "        for s in self.series_list:\n",
    "            df = s.data[[\"date\", \"value\"]].copy()\n",
    "            df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "            df = df.dropna(subset=[\"date\"]).sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "            df = df.rename(columns={\"value\": str(getattr(s, \"name\", \"series\"))})\n",
    "            out = df if out is None else out.merge(df, on=\"date\", how=\"outer\")\n",
    "\n",
    "        return out.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "dash = MacroDashboard()\n",
    "dash.add(rin_obj)\n",
    "dash.add(dgs10_obj)\n",
    "\n",
    "wide = dash.to_wide()\n",
    "print(wide.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541e2de5",
   "metadata": {},
   "source": [
    "## Homework (assigned, not solved)\n",
    "\n",
    "Submit one completed notebook with:\n",
    "\n",
    "1. All function TODOs completed (5.1.1 to 5.1.10).\n",
    "2. The dictionary exercise completed (Parts A–C), producing a clean debt DataFrame with numeric columns.\n",
    "3. `MacroSeries` implemented with:\n",
    "   - `latest_value`, `n_obs`, `pct_change`, `label`, and input validation in `__init__`.\n",
    "4. `MacroDashboard` implemented and tested, producing a wide merged dataset.\n",
    "5. A short section **Data Sources** explaining:\n",
    "   - BCRPData (Peru)\n",
    "   - FRED (US)\n",
    "   - U.S. Treasury Fiscal Data API\n",
    "\n",
    "No plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28ba460",
   "metadata": {},
   "source": [
    "# <a id='#5.3.'>5.3. References </a>\n",
    "\n",
    "- BCRPData API Guide: https://estadisticas.bcrp.gob.pe/estadisticas/series/ayuda/api\n",
    "- FRED: https://fred.stlouisfed.org/\n",
    "- U.S. Treasury Fiscal Data API: https://fiscaldata.treasury.gov/api-documentation/\n",
    "- Type hints (typing): https://docs.python.org/3/library/typing.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ra_task",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
