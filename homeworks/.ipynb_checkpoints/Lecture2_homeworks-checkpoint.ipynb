{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcf0f73c",
   "metadata": {},
   "source": [
    "## Lecture 2 — Pandas (Series/DataFrames) + Real Data (BCRP + Yahoo) \n",
    "### Goal\n",
    "Build a small **data pipeline** using the same sources as the lecture notebook:\n",
    "\n",
    "- **BCRP daily FX**: PD04637PD (buy) and PD04638PD (sell)  \n",
    "- **Yahoo Finance (yfinance)**: SPY, QQQ, TLT, GLD, EEM  \n",
    "- **BCRP monthly policy rate**: PD12301MD  \n",
    "\n",
    "**Final outputs**\n",
    "1. One **clean daily dataset** (both **long** and **wide** formats)  \n",
    "2. One **monthly dataset** with **policy rate + monthly SPY** (merged)  \n",
    "3. **Five quick consistency checks** (validations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9474e8",
   "metadata": {},
   "source": [
    "1. Define `START` and `END` as in the notebook and explain why that date range is reasonable.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268cbead",
   "metadata": {},
   "source": [
    "2. Download BCRP series PD04637PD and PD04638PD (JSON) and build a DataFrame with: `date`, `fx_buy`, `fx_sell`.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2de2d5a",
   "metadata": {},
   "source": [
    "3. Convert `date` to `datetime`, sort by date, and verify the index/column is monotonic.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4619712",
   "metadata": {},
   "source": [
    "4. Download Yahoo prices for SPY, QQQ, TLT, GLD, EEM and build a **long** DataFrame: `date`, `ticker`, `close`.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a121c7b0",
   "metadata": {},
   "source": [
    "5. Create a dictionary `{ticker: last_close}` using `groupby(...).last().to_dict()` and convert it to a Series sorted descending.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9152fce",
   "metadata": {},
   "source": [
    "6. *(Series)* Show three indexing methods for that Series: by label, by position, and by slice.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d17dde3",
   "metadata": {},
   "source": [
    "7. Convert the long price DataFrame into **wide** format (columns = tickers) and verify expected dimensions.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b028a51",
   "metadata": {},
   "source": [
    "8. Apply a filter to keep (i) a subset of tickers (e.g., SPY, TLT, GLD) and (ii) a subset of dates (e.g., 2024+).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301168ef",
   "metadata": {},
   "source": [
    "9. Compute NA counts per column and discuss whether imputing or trimming the panel makes more sense.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a534aefd",
   "metadata": {},
   "source": [
    "10. Impute missing `close` values by ticker (forward fill) and explain the risk of doing so.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d12546",
   "metadata": {},
   "source": [
    "11. Create a `ret` (simple return) column by ticker using `pct_change` (after sorting by `ticker` and `date`).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c2ac88",
   "metadata": {},
   "source": [
    "12. Detect and remove duplicates by key `(date, ticker)` if any exist. Explain how you detected them.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66da3921",
   "metadata": {},
   "source": [
    "13. Using `groupby(ticker)`, compute: mean return, volatility, and % of positive-return days.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b812fc",
   "metadata": {},
   "source": [
    "14. Group by month (derived from `date`) and compute `mean(close)` for SPY.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1960776d",
   "metadata": {},
   "source": [
    "15. Reshape: put returns into **wide** format (`date x ticker`), then convert back to long using `melt`.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b36071",
   "metadata": {},
   "source": [
    "16. Download BCRP monthly policy rate PD12301MD and build a DataFrame: `date`, `policy_rate`.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3431536e",
   "metadata": {},
   "source": [
    "17. Convert SPY to monthly frequency (e.g., monthly average of `close`) as in the notebook.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbda580",
   "metadata": {},
   "source": [
    "18. Perform an **inner merge** between monthly `policy_rate` and monthly `SPY_close_avg`. Report the number of rows.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d94886",
   "metadata": {},
   "source": [
    "19. Export the monthly merged dataset to CSV (as in the notebook) and confirm you did **not** export the index.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fa56a0",
   "metadata": {},
   "source": [
    "20. Write **5 validation checks** (assert-style), such as: “no duplicate dates”, “date is datetime”, “policy_rate is numeric”, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d603b94",
   "metadata": {},
   "source": [
    "# Exercise 1:\n",
    "\n",
    "### The file ```AMZN_options.csv``` contains options data for amazon. For those of you not familiar with option data, an option is a financial derivatives that pays at expiration time $T$ and strike $K>0$:\n",
    "\n",
    "$$C(K,T)=(S_T-K)_+ \\text{  if a call option}$$\n",
    "$$P(K,T)=(K-S_T)_+ \\text{  if a put option}$$\n",
    "\n",
    "It is well known, that Put-Call parity implies the following relation:\n",
    "\n",
    "$$C(K,T)-P(K,T)=S(T)-K\\cdot DF(T)$$\n",
    "where $S(T)$ is the underlying price and $DF(T)$ is the discount factor.\n",
    "### a) Compute a new column labelled ```mid_price``` which corresponds to:\n",
    "$$\\text{mid price}=\\frac{\\text{bid}+\\text{ask}}{2}$$\n",
    "### b) For each available ```expiration_date``` perform a linear regression using the ```mid_price``` only for options ```whose trade_volume>25``` (note that both calls and puts need to satisfy this condition):\n",
    "$$C(K,T)-P(K,T)=a+b K$$ where $a$ corresponds to $S(T)$ and $b$ corresponds to $DF(T)$.\n",
    "\n",
    "### you can use ```numpy.polyfit(x, y, deg=1)``` to fit a linear regression and obtain the coefficients\n",
    "### c) Plot $S(T)$ and  $DF(T)$ as a function of $T$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35340e0a",
   "metadata": {},
   "source": [
    "### Note: you will need to transform dates into time, $T$ in years to to us eyou will need to use the ```datetime``` library. Here goes an example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2866cc",
   "metadata": {},
   "source": [
    "# a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b642660",
   "metadata": {},
   "source": [
    "# b) first we find the different expirations available in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da14cb0a",
   "metadata": {},
   "source": [
    "## We will now group_by our dataframe by expiration_date, option_type and strike which gives one record per multi-index combination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c37167",
   "metadata": {},
   "source": [
    "# The following function performs the linear regression\n",
    "## Note that we need at least 2 points to perform the regression, try/except is helpful here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfe44f4",
   "metadata": {},
   "source": [
    "### Finally we plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eadba22",
   "metadata": {},
   "source": [
    "### As you (first hand) see, data can be a challenging business. We see some unexpected behaviour right? Why is this happening? let's check our samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294cd906",
   "metadata": {},
   "source": [
    "### Something seems to happen in \"2021-01-15\" right?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e023de",
   "metadata": {},
   "source": [
    "### Here we go, so we found that mid_price has a zero value. How can we fix this? Well we can surely check that mid_price is greater than zero!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e42a1d",
   "metadata": {},
   "source": [
    "### Bottomline here: you will face this kind of \"issue\" when dealing with data. Be prepared to debug and adapt your code to detect these anomalies. You can of course leave the task without the cleaning part, but as a good future quant you should question these anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eb9ad2",
   "metadata": {},
   "source": [
    "# Exercise 2:\n",
    "\n",
    "### a) Using the forward prices $F(T)$ and Discount Factors $DF(T)$ obtained previously, calculate the implied volatility of each option using the  ```mid_price```. (Note that you will need to use the implied volatility calculation that you did in the Session 2 assignment)\n",
    "\n",
    "Recall that in the Black-Scholes model, the value of a European Call option on $(S_t)_{t\\geq 0}$ is given at inception by,\n",
    "    $$C^{\\mathrm{BS}}(S_0, K, T;\\sigma) = S(T)\\left(\\mathcal{N}(d_{+}) - DF(T)K\\mathcal{N}(d_{-})\\right)$$\n",
    "    $$d_{\\pm} = \\frac{\\log\\left(\\frac{F(T)}{K}\\right)}{\\sigma\\sqrt{T}} \\pm\\frac{\\sigma\\sqrt{T}}{2}$$\n",
    "    \n",
    " Where $F(T)=\\frac{S(T)}{DF(T)}$\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dff766",
   "metadata": {},
   "source": [
    "### Remark1 : Try to optimize your code to execute efficiently\n",
    "### Remark2 : Note that some mid prices might lead to arbitrage and the solution for implied volatility might not exist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e100e1eb",
   "metadata": {},
   "source": [
    "### a) let us first deal with the fact that we were not able to compute $DF$ and $S$ for all expirations. To fix this we will need to apply some kind of interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821756fa",
   "metadata": {},
   "source": [
    "## For simplicity we will apply linear interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840463ce",
   "metadata": {},
   "source": [
    "# Let us now fill our original option_chain dataframe with $DF$ and $S$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce36081",
   "metadata": {},
   "source": [
    "### We will create a smaller dataframe with the columns we need to perform Black-Scholes to Implied Volatility trasform"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ra_task",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
