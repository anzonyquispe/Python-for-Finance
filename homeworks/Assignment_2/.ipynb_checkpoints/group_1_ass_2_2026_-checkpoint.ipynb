{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "execution_count": 207,
   "id": "e64ef3fa-10fc-462c-9db0-29ea2a4e3dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Tuple\n",
    "tuple1 = (\"Orange\", [10, 20, 30], (5, 15, 25))\n",
    "tuple2 = ([7, 8], [9, 1], [10, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "execution_count": 208,
   "id": "0e17e926-99f2-4cae-bc2e-c15c044309ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "#1.1 Tuple: The first item of the second item of tuple1 \n",
    "print(tuple1[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "execution_count": 209,
   "id": "95afa6f0-c1a2-4d11-9bd5-743bb72999a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 15, 25)\n",
      "(5, 15, 25)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.2 Tuple:The last item of the tuple1\n",
    "print(tuple1[2])==print(tuple1[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "execution_count": 210,
   "id": "450eecfe-3f41-49c5-8c0b-e6959c240b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No es posible\n"
     ]
    }
   ],
   "source": [
    "#1.3 Tuple: I wanted to change the value \"orange\" for \"pink grapefruit\" but It's impossible, because It's a tuple\n",
    "try:\n",
    "    tuple1[tuple1.index(\"Orange\")] = \"pink grapefruit\"\n",
    "except TypeError:\n",
    "    print(\"No es posible\")\n",
    "#Tuples are immutable, so their values cannot be changed after creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "execution_count": 211,
   "id": "067e1b93-6ef5-4248-96c3-30f4ba6d5598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.4 Tuple: This is the number of item by tuple1\n",
    "len(tuple1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "execution_count": 212,
   "id": "0c22cd9a-75ec-47c6-b45e-7c4c4fb9c4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "#1.5 Tuple: I use the funtion \"map\" for a sum the all of item by the tuple2\n",
    "A = tuple(map(sum, tuple2))\n",
    "print(sum(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "execution_count": 213,
   "id": "45a9941c-c122-4fa3-892f-997ea4ea5e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([3.5, 4.0], [4.5, 0.5], [5.0, 3.5])\n"
     ]
    }
   ],
   "source": [
    "#1.6 Generate a new tuple object named as tuple3 with the half values of tuple2. This tuple should be similar as tuple2, tuple of lists\n",
    "\n",
    "tuple3 = tuple([list(map(lambda y: y / 2, x)) for x in tuple2])  #map makes the same operation on each element, y es cada elemento de tuple\n",
    "print(tuple3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "execution_count": 214,
   "id": "5933e6a5-fee5-4a82-84d7-2957c24a720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List: Data\n",
    "import numpy as np\n",
    "f_list = [np.nan , np.nan, \"Austria\", \"Germany\", np.nan, \"Pakistan\", \"np.nan\", np.nan ]\n",
    "text1 = ['My', 'teacher', 'assistant', 'is', 'so', 'boring.']\n",
    "p2_list = [ 2 , 3, 4, 5 ]\n",
    "values1 = [ 86, 86, 85, 85, 85, 83, 23, 0, 84, 1 ] \n",
    "# These two lists a\n",
    "last_and_name = [ \"CORNEJO SANCHEZ, CHRISTIAN SANTOS\", \"ORELLANA QUISPE, CRISTIAN NASSER\", \"MORALES CHOQUEHUANCA, ANGELICA KARINA\", \"GUIMARAY RIBEYRO, JOSE ROBERTO\", \"CAMACHO GAVIDIA, ABEL FERNANDO\", \"TINTAYA ORIHUELA, MEIR ALVARO\", \"CHAVEZ MARTINEZ, JOSELIN ALEXANDRA\", \"FIGUEROA MURO, LEONEL ARTURO\", \"GOMEZ CRIBILLERO, JOSE FELIPE\", \"PALOMINO SEGUÍN, AFRANIA\", \"LUZON CUEVA, BIANCA MARIETTE\", \"SUAÑA ZEGARRA, ADRIAN ANDRE\", \"SOTO POMACHAGUA, DORKAS YOMIRA JHERMY\", \"FIORENTINO MARTINEZ, LADY ALY\", \"LAMA MAVILA, HECTOR ANDRE\", \"MEZA HINOJO, GUSTAVO\", \"LOZADA MURILLO, PERSEO MARCELO\", \"ZAMBRANO JIMENEZ, MIGUEL ALONZO\", \"JACOBS LUQUE, NICOLAS\", \"VIDAL VIDAL, ROCIO GABRIELA\", \"TORRES ANICAMA, JANE CAMILA\", \"LOPEZ ESTRADA, MARIA ELISA\", \"BOYCO ORAMS, ALEJANDRO\", \"DIAZ BERROSPI, KARLINE ROSMELI\", \"RIEGA ESCALANTE, STEPHY ROSARIO\", \"LEVANO TORRES, VALERIA CECILIA\", \"ESQUIVES BRAVO, SEBASTIAN RENATO\", \"PEREZ GONZALES, JUAN CARLOS\", \"OTERO MAGUIÑA, MARIANA\", \"CLAVO CAMPOS, ANDREA BRIZETH\", \"AGUILAR GARCIA, ERICK JOSUE\", \"CALDAS VELASQUEZ, JOSUE DANIEL\", \"SALAS NUÑEZ BORJA, FABIO MANUEL\", \"PIZARRO VILLANES, FERNANDA NICOLLE\", \"QUILLATUPA MORALES, ANGELA ADELINA\", \"HUANCAYA IDONE, CESAR DANTE\", \"CALVO PORTOCARRERO, GABRIELA ISABEL\", \"IBAÑEZ ABANTO, ANGEL MAURICIO\", \"MELÉNDEZ APONTE, JUAN DIEGO\", \"CRISTIAN SERRANO, ARONE\", \"HINOJOSA CAHUANA, PERCY ALBERTH\", \"ANGLAS GARCÍA, KEVIN ARTURO\", \"ALDAVE ACOSTA, CESAR ERNESTO\", \"NÚÑEZ HUAMÁN, CÉSAR AGUSTO\", \"OBREGON HUAMAN, DIANA EDITH\", \"SOTO PACHERRES, RODRIGO FRANCO\", \"INGARUCA RIVERA, GRETTEL ALEXANDRA\", \"ROJAS HUAMAN, ROSA ANGELA\", \"NEYRA SALAS, DANTE OMAR\", \"HUERTA ESPINOZA, YAJAIRA ALEXANDRA\", \"HUANCA MARTINEZ, JORGE ALBERTO\", \"FLORES CADILLO, ALEXIS\" ]\n",
    "emails = [\"cscornejo@pucp.edu.pe\", \"orellana.cn@pucp.edu.pe\", \"karina.morales@pucp.edu.pe\", \"a20083223@pucp.pe\", \"abel.camacho@pucp.pe\", \"mtintaya@pucp.edu.pe\", \"joselin.chavez@pucp.edu.pe\", \"a20105737@pucp.pe\", \"jfgomezc@pucp.pe\", \"afrania.palomino@pucp.pe\", \"luzon.bianca@pucp.pe\", \"adrian.suanaz@pucp.pe\", \"soto.y@pucp.edu.pe\", \"a20132766@pucp.pe\", \"andre.lama@pucp.edu.pe\", \"gustavo.meza@pucp.edu.pe\", \"pmlozada@pucp.edu.pe\", \"m.zambranoj@pucp.edu.pe\", \"nicolas.jacobs@pucp.edu.pe\", \"gvidal@pucp.edu.pe\", \"jane.torres@pucp.edu.pe\", \"m.lopez@pucp.edu.pe\", \"alejandro.boyco@pucp.edu.pe\", \"a20167070@pucp.edu.pe\", \"riega.stephy@pucp.edu.pe\", \"vlevanot@pucp.edu.pe\", \"sesquives@pucp.edu.pe\", \"perez.juanc@pucp.edu.pe\", \"mariana.otero@pucp.edu.pe\", \"aclavo@pucp.edu.pe\", \"a20182474@pucp.edu.pe\", \"josue.caldas@pucp.edu.pe\", \"fabio.salas@pucp.edu.pe\", \"fernanda.pizarro@pucp.edu.pe\", \"aquillatupa@pucp.pe\", \"\", \"\", \"\", \"\", \"\", \"f0873079@pucp.edu.pe\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"flores.alexis@pucp.edu.pe\", ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "execution_count": 215,
   "id": "e92b918f-f20c-4a16-8ec9-0147bf345061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The indices 0, 1, 4, 7 have np.nan values.\n"
     ]
    }
   ],
   "source": [
    "# 1.2.1 Show the indices of the np.nan values in the f_list list\n",
    "\n",
    "nan_indices = []  # ✅ Correct way to initialize an empty list\n",
    "\n",
    "# Loop through the list using enumerate to get index (i) and value (v)\n",
    "for i, v in enumerate(f_list):\n",
    "\n",
    "    # Verify if the value is np.nan\n",
    "    if isinstance(v, float) and np.isnan(v):\n",
    "        nan_indices.append(i)  # Store the index\n",
    "\n",
    "# Print OUTSIDE the for-loop\n",
    "print(f\"The indices {', '.join(map(str, nan_indices))} have np.nan values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "execution_count": 216,
   "id": "60ce4a5c-8be4-4389-8d81-87d196e3402e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "#1.2.2 Replicate 4 times the values of the list p2_list. We expect an ouput like this: [ 2 , 3, 4, 5, 2 , 3, 4, 5, 2 , 3, 4, 5, 2 , 3, 4, 5]\n",
    "replicated_list = p2_list * 4\n",
    "\n",
    "print(replicated_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "execution_count": 217,
   "id": "3367f129-1ee6-4d98-8086-a91679ed0f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "#1.2.3 Print the length of f_list\n",
    "print(len(f_list)) #len es largo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "execution_count": 218,
   "id": "20622bd5-c7ae-47e5-b055-04f301eab296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My teacher assistant is so boring.\n"
     ]
    }
   ],
   "source": [
    "#1.2.4 \n",
    "print(\" \".join(text1)) #join() function to combine the words \" \" espacio entre items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "execution_count": 219,
   "id": "a31a0024-b054-4348-a1ca-6858e75dbcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# String\n",
    "str1 = 'I am                            too                                                        old'\n",
    "emails = [\"cscornejo@pucp.edu.pe\", \"orellana.cn@pucp.edu.pe\", \"karina.morales@pucp.edu.pe\", \"a20083223@pucp.pe\", \"abel.camacho@pucp.pe\", \"mtintaya@pucp.edu.pe\", \"joselin.chavez@pucp.edu.pe\", \"a20105737@pucp.pe\", \"jfgomezc@pucp.pe\", \"afrania.palomino@pucp.pe\", \"luzon.bianca@pucp.pe\", \"adrian.suanaz@pucp.pe\", \"soto.y@pucp.edu.pe\", \"a20132766@pucp.pe\", \"andre.lama@pucp.edu.pe\", \"gustavo.meza@pucp.edu.pe\", \"pmlozada@pucp.edu.pe\", \"m.zambranoj@pucp.edu.pe\", \"nicolas.jacobs@pucp.edu.pe\", \"gvidal@pucp.edu.pe\", \"jane.torres@pucp.edu.pe\", \"m.lopez@pucp.edu.pe\", \"alejandro.boyco@pucp.edu.pe\", \"a20167070@pucp.edu.pe\", \"riega.stephy@pucp.edu.pe\", \"vlevanot@pucp.edu.pe\", \"sesquives@pucp.edu.pe\", \"perez.juanc@pucp.edu.pe\", \"mariana.otero@pucp.edu.pe\", \"aclavo@pucp.edu.pe\", \"a20182474@pucp.edu.pe\", \"josue.caldas@pucp.edu.pe\", \"fabio.salas@pucp.edu.pe\", \"fernanda.pizarro@pucp.edu.pe\", \"aquillatupa@pucp.pe\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_count": 220,
   "id": "43ddbace-1c06-4477-af57-963d3f6ae3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My TA is so boring, but is very funny.\n"
     ]
    }
   ],
   "source": [
    "# 1.2.5.  In this part we edited text1 using the \"join\" function and the \"extend\" method,  and we also modified some words in text1.\n",
    "text1[1:3] = ['TA']\n",
    "text1[4] = 'boring,'\n",
    "text1.extend(['but', 'is', 'very', 'funny.'])\n",
    "print(' '.join(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "93d38703-8b2a-4ff8-abe3-aab467dac2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max value of values1 is 86 and is located in the 0 index. \n",
      "The min value of values1 is 0 and is located in the 7 index. \n"
     ]
    }
   ],
   "source": [
    "#1.2.6. First of all we find the maximum and minimum value of values1, we also find the index of the values and finally we use the f-string to set up the final message\n",
    "max_value = max(values1)\n",
    "min_value = min(values1)\n",
    "max_index = values1.index(max_value)\n",
    "min_index = values1.index(min_value)\n",
    "\n",
    "print(f\"The max value of values1 is {max_value} and is located in the {max_index} index. \")\n",
    "print(f\"The min value of values1 is {min_value} and is located in the {min_index} index. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a8d530a6-3dab-4e75-9a5d-6a2ed9a3d0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names: ['CHRISTIAN SANTOS', 'CRISTIAN NASSER', 'ANGELICA KARINA', 'JOSE ROBERTO', 'ABEL FERNANDO', 'MEIR ALVARO', 'JOSELIN ALEXANDRA', 'LEONEL ARTURO', 'JOSE FELIPE', 'AFRANIA', 'BIANCA MARIETTE', 'ADRIAN ANDRE', 'DORKAS YOMIRA JHERMY', 'LADY ALY', 'HECTOR ANDRE', 'GUSTAVO', 'PERSEO MARCELO', 'MIGUEL ALONZO', 'NICOLAS', 'ROCIO GABRIELA', 'JANE CAMILA', 'MARIA ELISA', 'ALEJANDRO', 'KARLINE ROSMELI', 'STEPHY ROSARIO', 'VALERIA CECILIA', 'SEBASTIAN RENATO', 'JUAN CARLOS', 'MARIANA', 'ANDREA BRIZETH', 'ERICK JOSUE', 'JOSUE DANIEL', 'FABIO MANUEL', 'FERNANDA NICOLLE', 'ANGELA ADELINA', 'CESAR DANTE', 'GABRIELA ISABEL', 'ANGEL MAURICIO', 'JUAN DIEGO', 'ARONE', 'PERCY ALBERTH', 'KEVIN ARTURO', 'CESAR ERNESTO', 'CÉSAR AGUSTO', 'DIANA EDITH', 'RODRIGO FRANCO', 'GRETTEL ALEXANDRA', 'ROSA ANGELA', 'DANTE OMAR', 'YAJAIRA ALEXANDRA', 'JORGE ALBERTO', 'ALEXIS']\n",
      "Last Names: ['CORNEJO SANCHEZ', 'ORELLANA QUISPE', 'MORALES CHOQUEHUANCA', 'GUIMARAY RIBEYRO', 'CAMACHO GAVIDIA', 'TINTAYA ORIHUELA', 'CHAVEZ MARTINEZ', 'FIGUEROA MURO', 'GOMEZ CRIBILLERO', 'PALOMINO SEGUÍN', 'LUZON CUEVA', 'SUAÑA ZEGARRA', 'SOTO POMACHAGUA', 'FIORENTINO MARTINEZ', 'LAMA MAVILA', 'MEZA HINOJO', 'LOZADA MURILLO', 'ZAMBRANO JIMENEZ', 'JACOBS LUQUE', 'VIDAL VIDAL', 'TORRES ANICAMA', 'LOPEZ ESTRADA', 'BOYCO ORAMS', 'DIAZ BERROSPI', 'RIEGA ESCALANTE', 'LEVANO TORRES', 'ESQUIVES BRAVO', 'PEREZ GONZALES', 'OTERO MAGUIÑA', 'CLAVO CAMPOS', 'AGUILAR GARCIA', 'CALDAS VELASQUEZ', 'SALAS NUÑEZ BORJA', 'PIZARRO VILLANES', 'QUILLATUPA MORALES', 'HUANCAYA IDONE', 'CALVO PORTOCARRERO', 'IBAÑEZ ABANTO', 'MELÉNDEZ APONTE', 'CRISTIAN SERRANO', 'HINOJOSA CAHUANA', 'ANGLAS GARCÍA', 'ALDAVE ACOSTA', 'NÚÑEZ HUAMÁN', 'OBREGON HUAMAN', 'SOTO PACHERRES', 'INGARUCA RIVERA', 'ROJAS HUAMAN', 'NEYRA SALAS', 'HUERTA ESPINOZA', 'HUANCA MARTINEZ', 'FLORES CADILLO']\n"
     ]
    }
   ],
   "source": [
    "#1.2.7. We generated these two lists using \"last_and_name\". We want to highlight the use of \"map\" and \"split\", as they help us extract the first and last names from a long text list containing them.\n",
    "names = list(map(lambda x: x.split(', ')[1], last_and_name)) #In this case you can see that we choose the second part of \"last_and_name\"\n",
    "last_names = list(map(lambda x: x.split(', ')[0], last_and_name)) ##In this case you can see that we choose the first part of \"last_and_name\"\n",
    "\n",
    "print(\"Names:\", names)\n",
    "print(\"Last Names:\", last_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "707c37e4-40f2-4c99-a0e2-852139f4fe33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Last Names: []\n"
     ]
    }
   ],
   "source": [
    "#1.2.8. First, we create a sequence of tuples where each tuple is (last name, email address). Then, we filter the email addresses containing an empty string using a lambda function, and finally, we map the filtered pairs to extract only the last name and convert it into a list.\n",
    "# Asegúrate de que las variables 'last_names' y 'emails' estén definidas ejecutando la celda 1.2.7 (a1af4c7e) primero.\n",
    "last_names = list(map(lambda x: x.split(', ')[0], last_and_name)) # Aseguramos que 'last_names' esté definida\n",
    "pair_last_name_email = zip(last_names, emails)\n",
    "filtered_pairs = filter(lambda pair: pair[1] == \"\", pair_last_name_email)\n",
    "last_names_without_email = list(map(lambda pair: pair[0], filtered_pairs))\n",
    "\n",
    "print(\"All Last Names:\", last_names_without_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5a48123d-2613-4023-86ff-5dcb84c7cd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = 'I am                            too                                                        old'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "d371bb2e-a470-4f92-98ce-e43af7f433b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = [\"cscornejo@pucp.edu.pe\", \"orellana.cn@pucp.edu.pe\", \"karina.morales@pucp.edu.pe\", \"a20083223@pucp.pe\", \"abel.camacho@pucp.pe\", \"mtintaya@pucp.edu.pe\", \"joselin.chavez@pucp.edu.pe\", \"a20105737@pucp.pe\", \"jfgomezc@pucp.pe\", \"afrania.palomino@pucp.pe\", \"luzon.bianca@pucp.pe\", \"adrian.suanaz@pucp.pe\", \"soto.y@pucp.edu.pe\", \"a20132766@pucp.pe\", \"andre.lama@pucp.edu.pe\", \"gustavo.meza@pucp.edu.pe\", \"pmlozada@pucp.edu.pe\", \"m.zambranoj@pucp.edu.pe\", \"nicolas.jacobs@pucp.edu.pe\", \"gvidal@pucp.edu.pe\", \"jane.torres@pucp.edu.pe\", \"m.lopez@pucp.edu.pe\", \"alejandro.boyco@pucp.edu.pe\", \"a20167070@pucp.edu.pe\", \"riega.stephy@pucp.edu.pe\", \"vlevanot@pucp.edu.pe\", \"sesquives@pucp.edu.pe\", \"perez.juanc@pucp.edu.pe\", \"mariana.otero@pucp.edu.pe\", \"aclavo@pucp.edu.pe\", \"a20182474@pucp.edu.pe\", \"josue.caldas@pucp.edu.pe\", \"fabio.salas@pucp.edu.pe\", \"fernanda.pizarro@pucp.edu.pe\", \"aquillatupa@pucp.pe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "2f334bff-81e9-4c54-9704-1e5dce7858c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cadena original: I am                            too                                                        old\n",
      "Cadena limpia: I am too old\n"
     ]
    }
   ],
   "source": [
    "# 1.3.1. First, we use split() without arguments to separate the string into words, removing all empty spaces, and then with join() we join the words with a single space as a separator, thus obtaining a clean string\n",
    "words = str1.split()\n",
    "cleaned_str1 = ' '.join(words)\n",
    "\n",
    "print(\"Cadena original:\", str1)\n",
    "print(\"Cadena limpia:\", cleaned_str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd51aec-cafa-4d45-8737-9bdde55cf6e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d38703-8b2a-4ff8-abe3-aab467dac2e4",
   "id": "602e7de5-83fe-4401-b7e7-679bca70df3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d530a6-3dab-4e75-9a5d-6a2ed9a3d0a6",
   "id": "755cc2a3-07ad-4fa8-a346-40ac75169aef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707c37e4-40f2-4c99-a0e2-852139f4fe33",
   "id": "964e8d72-8f65-43f8-8129-491d08e47f48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a48123d-2613-4023-86ff-5dcb84c7cd05",
   "id": "d433252b-e067-41bf-a9a8-9569181ddec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "a6147e64-3cbd-4111-9b2d-0d86d986f1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SECOND PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "0aabe9e0-0b13-4255-bd1f-1ed777e31350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "START = \"2022-01-01\"\n",
    "END = \"2025-12-18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "a748ab84-4e9a-452e-a3fd-c8e36384637b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not import yfinance: ModuleNotFoundError No module named 'yfinance'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Empty DataFrame\n",
       " Columns: [date, ticker, close, volume]\n",
       " Index: [],\n",
       " (0, 4))"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Yahoo Finance via yfinance: US tickers (real market yh_df) ---\n",
    "tickers = [\"SPY\", \"QQQ\", \"TLT\", \"GLD\", \"EEM\"]\n",
    "# SPY : S&P 500 index\n",
    "# QQQ : Nasdaq-100 index\n",
    "# TLT : U.S. Treasury bonds with 20+ year maturity\n",
    "# GLD : Physical gold prices\n",
    "# EEM : MSCI Emerging Markets index\n",
    "\n",
    "try:\n",
    "    import yfinance as yf\n",
    "except Exception as e:\n",
    "    yf = None\n",
    "    print(\"Could not import yfinance:\", type(e).__name__, str(e))\n",
    "\n",
    "if yf is not None:\n",
    "    try:\n",
    "        yh_df = yf.download(tickers, start=START, end=END, auto_adjust=True, progress=False)\n",
    "    except Exception as e:\n",
    "        yh_df = pd.DataFrame()\n",
    "        print(\"yfinance download failed:\", type(e).__name__, str(e))\n",
    "else:\n",
    "    yh_df = pd.DataFrame()\n",
    "\n",
    "# Convert to long format: date, ticker, close, volume\n",
    "if isinstance(yh_df, pd.DataFrame) and yh_df.shape[0] > 0:\n",
    "    if isinstance(yh_df.columns, pd.MultiIndex):\n",
    "        close = yh_df[\"Close\"].copy()\n",
    "        vol = yh_df[\"Volume\"].copy()\n",
    "    else:\n",
    "        close = yh_df[[\"Close\"]].rename(columns={\"Close\": tickers[0]})\n",
    "        vol = yh_df[[\"Volume\"]].rename(columns={\"Volume\": tickers[0]})\n",
    "\n",
    "    close.index.name = \"date\"\n",
    "    vol.index.name = \"date\"\n",
    "\n",
    "    us_close_long = close.reset_index().melt(id_vars=\"date\", var_name=\"ticker\", value_name=\"close\")\n",
    "    us_vol_long = vol.reset_index().melt(id_vars=\"date\", var_name=\"ticker\", value_name=\"volume\")\n",
    "    us_mkt = us_close_long.merge(us_vol_long, on=[\"date\",\"ticker\"], how=\"inner\").dropna(subset=[\"close\"])\n",
    "else:\n",
    "    us_mkt = pd.DataFrame(columns=[\"date\",\"ticker\",\"close\",\"volume\"])\n",
    "\n",
    "us_mkt.head(), us_mkt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "2dd417ae-195e-4bde-b986-574ec3835277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_raw</th>\n",
       "      <th>PENUSD_buy</th>\n",
       "      <th>PENUSD_sell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03.Ene.22</td>\n",
       "      <td>3.98366666666667</td>\n",
       "      <td>3.98883333333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04.Ene.22</td>\n",
       "      <td>3.9595</td>\n",
       "      <td>3.964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05.Ene.22</td>\n",
       "      <td>3.952</td>\n",
       "      <td>3.95633333333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06.Ene.22</td>\n",
       "      <td>3.96716666666667</td>\n",
       "      <td>3.96966666666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07.Ene.22</td>\n",
       "      <td>3.94516666666667</td>\n",
       "      <td>3.94816666666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>12.Dic.25</td>\n",
       "      <td>3.36685714285714</td>\n",
       "      <td>3.36885714285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>15.Dic.25</td>\n",
       "      <td>3.36871428571429</td>\n",
       "      <td>3.3705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>16.Dic.25</td>\n",
       "      <td>3.36985714285714</td>\n",
       "      <td>3.37142857142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>17.Dic.25</td>\n",
       "      <td>3.36771428571429</td>\n",
       "      <td>3.36914285714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>18.Dic.25</td>\n",
       "      <td>3.36514285714286</td>\n",
       "      <td>3.36664285714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>988 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      date_raw        PENUSD_buy       PENUSD_sell\n",
       "0    03.Ene.22  3.98366666666667  3.98883333333333\n",
       "1    04.Ene.22            3.9595             3.964\n",
       "2    05.Ene.22             3.952  3.95633333333333\n",
       "3    06.Ene.22  3.96716666666667  3.96966666666667\n",
       "4    07.Ene.22  3.94516666666667  3.94816666666667\n",
       "..         ...               ...               ...\n",
       "983  12.Dic.25  3.36685714285714  3.36885714285714\n",
       "984  15.Dic.25  3.36871428571429            3.3705\n",
       "985  16.Dic.25  3.36985714285714  3.37142857142857\n",
       "986  17.Dic.25  3.36771428571429  3.36914285714286\n",
       "987  18.Dic.25  3.36514285714286  3.36664285714286\n",
       "\n",
       "[988 rows x 3 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- BCRP: daily exchange rate PEN/USD buy & sell (official API) ---\n",
    "# Codes:\n",
    "# - PD04637PD: USD/PEN (buy)\n",
    "# - PD04638PD: USD/PEN (sell)\n",
    "\n",
    "import requests\n",
    "\n",
    "bcrp_url = f\"https://estadisticas.bcrp.gob.pe/estadisticas/series/api/PD04637PD-PD04638PD/json/{START}/{END}/esp\"\n",
    "try:\n",
    "    r = requests.get(bcrp_url, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    bcrp_obj = r.json()\n",
    "except Exception as e:\n",
    "    bcrp_obj = {\"periods\": []}\n",
    "    print(\"BCRP request failed:\", type(e).__name__, str(e))\n",
    "\n",
    "periods = bcrp_obj.get(\"periods\", [])\n",
    "rows = []\n",
    "for p in periods:\n",
    "    name = p.get(\"name\")\n",
    "    vals = p.get(\"values\", [])\n",
    "    if isinstance(vals, str):\n",
    "        vals = [vals]\n",
    "    if name is None or not isinstance(vals, list) or len(vals) < 2:\n",
    "        continue\n",
    "    rows.append([name, vals[0], vals[1]])\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"date_raw\", \"PENUSD_buy\", \"PENUSD_sell\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "0fcaed77-8f2c-4ff8-b886-f9ef909d644c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: nan, Min: nan, Max: nan\n",
      "Series([], Name: SPY_close_series, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "#3.2.2\n",
    "#First step is to filter the DataFrame to obtain only the ticker \"SPY\", so we create a boolean mask where the ticker is the same as \"SPY\"\n",
    "mask_spy = us_mkt[\"ticker\"] == \"SPY\"\n",
    "\n",
    "# Next we need to apply the mask to the original DataFrame to obtain a new DF using only SPY\n",
    "spy_data = us_mkt[mask_spy]\n",
    "\n",
    "#Second step is to take a column \"close\" as a Numpy array and in this way we enter the \"close\" cloumn and use .value to get the underlying NumPy array.\n",
    "spy_close_array = spy_data[\"close\"].values\n",
    "\n",
    "#Third step is to create a series indexed by \"date\" called \"SPY_close_series\", then we also need the dates as an array to align the data\n",
    "spy_dates = spy_data[\"date\"].values\n",
    "\n",
    "# pd.Series constructor:\n",
    "# data: the array of closing values ​(NumPy array from step 2)\n",
    "# index: the corresponding dates.\n",
    "# name: the internal name of the series.\n",
    "SPY_close_series = pd.Series(data=spy_close_array, index=spy_dates, name=\"SPY_close_series\")\n",
    "\n",
    "#Fourth step is calculate average, minimum and maximum with Series methods\n",
    "spy_mean = SPY_close_series.mean()\n",
    "spy_min = SPY_close_series.min()\n",
    "spy_max = SPY_close_series.max()\n",
    "\n",
    "print(f\"Mean: {spy_mean:.2f}, Min: {spy_min:.2f}, Max: {spy_max:.2f}\")\n",
    "print(SPY_close_series.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "dac9c157-fd54-4d78-9a8b-282666049512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "#3.2.3\n",
    "# First, we order by date to ensure the \"last\" is the most recent, after, we group by ticker and select the \"close\" column, and finally we use .last() to retrieve the final data from each group\n",
    "last_prices_series = us_mkt.sort_values(\"date\").groupby(\"ticker\")[\"close\"].last()\n",
    "\n",
    "# Sort the series in descending order\n",
    "last_prices_series = last_prices_series.sort_values(ascending=False)\n",
    "\n",
    "# Second, we transformed the pandas series directly into the {ticker: last_close} format\n",
    "dict_last_close = last_prices_series.to_dict()\n",
    "\n",
    "print(dict_last_close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "1e4b9835-db39-44ff-b212-df703542ccba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'pandas.core.frame.DataFrame'>\n",
      "shape: (0, 4)\n",
      "empty: True\n",
      "cols: ['date', 'ticker', 'close', 'volume']\n",
      "Empty DataFrame\n",
      "Columns: [date, ticker, close, volume]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(\"type:\", type(us_mkt))\n",
    "print(\"shape:\", us_mkt.shape)\n",
    "print(\"empty:\", us_mkt.empty)\n",
    "\n",
    "# Si es DataFrame:\n",
    "if hasattr(us_mkt, \"columns\"):\n",
    "    print(\"cols:\", list(us_mkt.columns))\n",
    "    print(us_mkt.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "9fb05fa6-89e0-4897-85d4-b66b52437463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in close: 1\n",
      "Expected n: 1\n"
     ]
    }
   ],
   "source": [
    "# 3.3.6 Dealing with Nulls\n",
    "# Firts, I creat a copu whit .copy(), then I used rng=np.random for which random row but I use 300 for not changes other row. \n",
    "#Them, I use the funtion max number for limiting the number of rows I can choose.And In this row I can chege the data, I use np.nan for to place NAN\n",
    "#Finally, I count the rows that have NAN\n",
    "\n",
    "dates = pd.date_range(start='2023-01-01', periods=100)\n",
    "close_values = np.random.rand(100) * 100  # Random stock prices\n",
    "us_mkt = pd.DataFrame({'date': dates, 'close': close_values})\n",
    "\n",
    "if us_mkt.empty:\n",
    "    raise ValueError(\"Dataset is empty. Check your data creation.\")\n",
    "\n",
    "# Now create a copy with NaN values\n",
    "us_mkt_nan = us_mkt.copy()\n",
    "rng = np.random.default_rng(300)\n",
    "\n",
    "m = len(us_mkt_nan)\n",
    "n = max(1, int(m * 0.01))  # Calculate how many rows to modify (1% of total)\n",
    "idx = rng.choice(us_mkt_nan.index.to_numpy(), size=n, replace=False)\n",
    "us_mkt_nan.loc[idx, \"close\"] = np.nan  # Set selected rows' close values to NaN\n",
    "\n",
    "print(\"NaNs in close:\", us_mkt_nan[\"close\"].isna().sum())\n",
    "print(\"Expected n:\", n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "80c2cd07-df55-4cc4-b4bd-b70ab2aa2b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dup_df shape: (110, 2)\n",
      "Cantidad de duplicados detectados: 10\n",
      "dup_clean shape: (100, 2)\n"
     ]
    }
   ],
   "source": [
    "# 3.3.7 Duplicates\n",
    "#We use concat() to add the last 5 rows twice, so our table has repeated rows. duplicated() finds which rows are repeats, and sum() counts them. duplicates() removes the repeats and keeps only one copy.\n",
    "\n",
    "dup_df = pd.concat([us_mkt, us_mkt.tail(5), us_mkt.tail(5)], ignore_index=True)\n",
    "dup_mask = dup_df.duplicated()\n",
    "print(\"dup_df shape:\", dup_df.shape)\n",
    "print(\"Cantidad de duplicados detectados:\", dup_mask.sum())\n",
    "dup_clean = dup_df.drop_duplicates()\n",
    "print(\"dup_clean shape:\", dup_clean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b41e94d-df0f-41d4-af81-ee835b71f3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7595e604-5a44-4d1a-a8d4-e29f111aca89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "python3"
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
