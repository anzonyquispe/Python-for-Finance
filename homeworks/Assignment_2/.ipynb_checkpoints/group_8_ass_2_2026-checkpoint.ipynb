{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment\n",
    "\n",
    "It is totally prohibited to use any kind of loop. You can use stackoverflow. If you copy codes from previous answers, explain each step. No explanation is `0 points`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Tuple\n",
    "\n",
    "\n",
    "\n",
    "1. Print the first item of the second item of `tuple1` object. **Hint: Use indexing**<br><br>\n",
    "2. Print the last item of the `tuple1` object.**Hint: Use indexing**<br><br>\n",
    "3. Change the value \"orange\" for \"pink grapefruit\". Comment the output. **Hint: Is it possible?** <br><br>\n",
    "4. Print the length of `tuple1`. **Hint: Length function**<br><br>\n",
    "5. Sum all the elements of tuple2 and describe your steps and explain each of them. **Hint: Use `map` function.**<br><br>\n",
    "6. Generate a new tuple object named as `tuple3` with the half values of `tuple2`. This tuple should be similar as `tuple2`, tuple of lists.  **Hint: Use `map` funciont.**<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple1 = (\"Orange\", [10, 20, 30], (5, 15, 25))\n",
    "tuple2 = ([7, 8], [9, 1], [10, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Lists\n",
    "1. Show the indices of the `np.nan` values  in the `f_list` list. We want to see this output: `The indices 0, 1, 4, 7 have np.nan values.` **Hint: Use print function and [f-strings](https://realpython.com/python-f-strings/) to insert the indices values.**<br><br>\n",
    "\n",
    "2. Replicate 4 times the values of the list `p2_list`. We expect an ouput like this: `[ 2 , 3, 4, 5, 2 , 3, 4, 5, 2 , 3, 4, 5, 2 , 3, 4, 5]`.  **Hint: Use multiplication function in `lists`and see the output.**<br><br>\n",
    "3. Print the length of `f_list`. **Hint: Length function**<br><br>\n",
    "4. Print `My teacher assistant is so boring.` using `text1` list. **Hint: Use the [`join` function](https://stackoverflow.com/questions/493819/why-is-it-string-joinlist-instead-of-list-joinstring)**<br><br>\n",
    "5. Print `My TA is so boring, but is very funny.` using `text1` list.**Hint: Use the `join` function, and `extend` method.**<br><br>\n",
    "6. Print <br>\n",
    "`The max value of values1 is 86 and is located in the 0 index. ` <br>\n",
    "`The min value of values1 is 0 and is located in the 7 index. ` <br> **Hint: Use the `f-string`, `min`, and `max` functions.**\n",
    "<br>\n",
    "7. Get two lists: `names` and `last_names` using `last_and_name` list. **Hint: Use `map` and `split`.**\n",
    "<br>\n",
    "8. Give only the last names of students who do not have email. Use the `emails` and `last_names` listt. **Hint: Use `map` and `split`.**\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_list = [np.nan , np.nan, \"Austria\", \"Germany\", np.nan, \"Pakistan\", \"np.nan\", np.nan ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = ['My', 'teacher', 'assistant', 'is', 'so', 'boring.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2_list = [ 2 , 3, 4, 5 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "values1 = [ 86, 86, 85, 85, 85, 83, 23, 0, 84, 1 ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These two lists a\n",
    "last_and_name = [ \"CORNEJO SANCHEZ, CHRISTIAN SANTOS\", \"ORELLANA QUISPE, CRISTIAN NASSER\", \"MORALES CHOQUEHUANCA, ANGELICA KARINA\", \"GUIMARAY RIBEYRO, JOSE ROBERTO\", \"CAMACHO GAVIDIA, ABEL FERNANDO\", \"TINTAYA ORIHUELA, MEIR ALVARO\", \"CHAVEZ MARTINEZ, JOSELIN ALEXANDRA\", \"FIGUEROA MURO, LEONEL ARTURO\", \"GOMEZ CRIBILLERO, JOSE FELIPE\", \"PALOMINO SEGUÍN, AFRANIA\", \"LUZON CUEVA, BIANCA MARIETTE\", \"SUAÑA ZEGARRA, ADRIAN ANDRE\", \"SOTO POMACHAGUA, DORKAS YOMIRA JHERMY\", \"FIORENTINO MARTINEZ, LADY ALY\", \"LAMA MAVILA, HECTOR ANDRE\", \"MEZA HINOJO, GUSTAVO\", \"LOZADA MURILLO, PERSEO MARCELO\", \"ZAMBRANO JIMENEZ, MIGUEL ALONZO\", \"JACOBS LUQUE, NICOLAS\", \"VIDAL VIDAL, ROCIO GABRIELA\", \"TORRES ANICAMA, JANE CAMILA\", \"LOPEZ ESTRADA, MARIA ELISA\", \"BOYCO ORAMS, ALEJANDRO\", \"DIAZ BERROSPI, KARLINE ROSMELI\", \"RIEGA ESCALANTE, STEPHY ROSARIO\", \"LEVANO TORRES, VALERIA CECILIA\", \"ESQUIVES BRAVO, SEBASTIAN RENATO\", \"PEREZ GONZALES, JUAN CARLOS\", \"OTERO MAGUIÑA, MARIANA\", \"CLAVO CAMPOS, ANDREA BRIZETH\", \"AGUILAR GARCIA, ERICK JOSUE\", \"CALDAS VELASQUEZ, JOSUE DANIEL\", \"SALAS NUÑEZ BORJA, FABIO MANUEL\", \"PIZARRO VILLANES, FERNANDA NICOLLE\", \"QUILLATUPA MORALES, ANGELA ADELINA\", \"HUANCAYA IDONE, CESAR DANTE\", \"CALVO PORTOCARRERO, GABRIELA ISABEL\", \"IBAÑEZ ABANTO, ANGEL MAURICIO\", \"MELÉNDEZ APONTE, JUAN DIEGO\", \"CRISTIAN SERRANO, ARONE\", \"HINOJOSA CAHUANA, PERCY ALBERTH\", \"ANGLAS GARCÍA, KEVIN ARTURO\", \"ALDAVE ACOSTA, CESAR ERNESTO\", \"NÚÑEZ HUAMÁN, CÉSAR AGUSTO\", \"OBREGON HUAMAN, DIANA EDITH\", \"SOTO PACHERRES, RODRIGO FRANCO\", \"INGARUCA RIVERA, GRETTEL ALEXANDRA\", \"ROJAS HUAMAN, ROSA ANGELA\", \"NEYRA SALAS, DANTE OMAR\", \"HUERTA ESPINOZA, YAJAIRA ALEXANDRA\", \"HUANCA MARTINEZ, JORGE ALBERTO\", \"FLORES CADILLO, ALEXIS\" ]\n",
    "emails = [\"cscornejo@pucp.edu.pe\", \"orellana.cn@pucp.edu.pe\", \"karina.morales@pucp.edu.pe\", \"a20083223@pucp.pe\", \"abel.camacho@pucp.pe\", \"mtintaya@pucp.edu.pe\", \"joselin.chavez@pucp.edu.pe\", \"a20105737@pucp.pe\", \"jfgomezc@pucp.pe\", \"afrania.palomino@pucp.pe\", \"luzon.bianca@pucp.pe\", \"adrian.suanaz@pucp.pe\", \"soto.y@pucp.edu.pe\", \"a20132766@pucp.pe\", \"andre.lama@pucp.edu.pe\", \"gustavo.meza@pucp.edu.pe\", \"pmlozada@pucp.edu.pe\", \"m.zambranoj@pucp.edu.pe\", \"nicolas.jacobs@pucp.edu.pe\", \"gvidal@pucp.edu.pe\", \"jane.torres@pucp.edu.pe\", \"m.lopez@pucp.edu.pe\", \"alejandro.boyco@pucp.edu.pe\", \"a20167070@pucp.edu.pe\", \"riega.stephy@pucp.edu.pe\", \"vlevanot@pucp.edu.pe\", \"sesquives@pucp.edu.pe\", \"perez.juanc@pucp.edu.pe\", \"mariana.otero@pucp.edu.pe\", \"aclavo@pucp.edu.pe\", \"a20182474@pucp.edu.pe\", \"josue.caldas@pucp.edu.pe\", \"fabio.salas@pucp.edu.pe\", \"fernanda.pizarro@pucp.edu.pe\", \"aquillatupa@pucp.pe\", \"\", \"\", \"\", \"\", \"\", \"f0873079@pucp.edu.pe\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"flores.alexis@pucp.edu.pe\", ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The indices 0, 1, 4, 7 have np.nan values.\n"
     ]
    }
   ],
   "source": [
    "# 1) It asks to determine the index of the elements that are np.nan in the f_list list and print them.\n",
    "\n",
    "# There is no native tool to index lists with np.nan, but we can use numpy and pandas to do it.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# We convert the list into a numpy array\n",
    "f_array = np.array(f_list, dtype=object)\n",
    "\n",
    "# We use np.isnan to get a boolean array indicating where the np.nan values are\n",
    "nan_indices = pd.isna(f_array)\n",
    "\n",
    "# We obtain the indices where the value is True (that is, where there is np.nan)\n",
    "indices = np.where(nan_indices)[0]\n",
    "\n",
    "# We put the result into a string to print it\n",
    "indices = indices.tolist()\n",
    "indices = ', '.join(map(str, indices))\n",
    "\n",
    "# We print the indices\n",
    "print(f\"The indices {indices} have np.nan values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "# 2) It asks to replicate the p2_list list four times using the list multiplication function.\n",
    "\n",
    "# We replicate the list p2_list four times\n",
    "p2_list_replicated = p2_list * 4\n",
    "\n",
    "# We print the replicated list\n",
    "print(p2_list_replicated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of f_list is 8.\n"
     ]
    }
   ],
   "source": [
    "# 3) It asks to determine the length of the f_list list using the len() function.\n",
    "\n",
    "# We calculate the length of f_list\n",
    "length_f_list = len(f_list)\n",
    "\n",
    "# We print the length of f_list\n",
    "print(f\"The length of f_list is {length_f_list}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My teacher assistant is so boring.\n"
     ]
    }
   ],
   "source": [
    "# 4) It asks to print the string \"My teacher assistant is so boring.\" as a single text string using the join() function.\n",
    "\n",
    "# We join the elements of text1 into a single string with spaces in between\n",
    "full_text = ' '.join(text1)\n",
    "\n",
    "# We print the complete text\n",
    "print(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My TA assistant is so boring, but is very funny.\n"
     ]
    }
   ],
   "source": [
    "# 5) It asks to print the string \"My TA is so boring, but is very funny.\" using text1, the join function, and the extend method.\n",
    "\n",
    "# We create a copy of text1 to avoid modifying the original\n",
    "text1_extended = text1.copy()\n",
    "\n",
    "# We edit the necessary words\n",
    "text1_extended[1] = \"TA\"\n",
    "text1_extended[5] = \"boring,\"\n",
    "\n",
    "# We extend the list with the new words\n",
    "text1_extended.extend([\"but\", \"is\", \"very\", \"funny.\"])\n",
    "\n",
    "# We join the list into a single string\n",
    "full_text_extended = \" \".join(text1_extended)\n",
    "\n",
    "# We print the complete text\n",
    "print(full_text_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max value of values1 is 86 and is located in the 0 index.\n",
      "The min value of values1 is 0 and is located in the 7 index.\n"
     ]
    }
   ],
   "source": [
    "# 6) It asks to determine the min and max of the values1 list using the min() and max() functions.\n",
    "\n",
    "# We calculate the minimum and maximum values of values1\n",
    "min_value = min(values1)\n",
    "max_value = max(values1)\n",
    "\n",
    "# We print the minimum and maximum values\n",
    "print(f\"The max value of values1 is {max_value} and is located in the {values1.index(max_value)} index.\")\n",
    "print(f\"The min value of values1 is {min_value} and is located in the {values1.index(min_value)} index.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names: ('CHRISTIAN SANTOS', 'CRISTIAN NASSER', 'ANGELICA KARINA', 'JOSE ROBERTO', 'ABEL FERNANDO', 'MEIR ALVARO', 'JOSELIN ALEXANDRA', 'LEONEL ARTURO', 'JOSE FELIPE', 'AFRANIA', 'BIANCA MARIETTE', 'ADRIAN ANDRE', 'DORKAS YOMIRA JHERMY', 'LADY ALY', 'HECTOR ANDRE', 'GUSTAVO', 'PERSEO MARCELO', 'MIGUEL ALONZO', 'NICOLAS', 'ROCIO GABRIELA', 'JANE CAMILA', 'MARIA ELISA', 'ALEJANDRO', 'KARLINE ROSMELI', 'STEPHY ROSARIO', 'VALERIA CECILIA', 'SEBASTIAN RENATO', 'JUAN CARLOS', 'MARIANA', 'ANDREA BRIZETH', 'ERICK JOSUE', 'JOSUE DANIEL', 'FABIO MANUEL', 'FERNANDA NICOLLE', 'ANGELA ADELINA', 'CESAR DANTE', 'GABRIELA ISABEL', 'ANGEL MAURICIO', 'JUAN DIEGO', 'ARONE', 'PERCY ALBERTH', 'KEVIN ARTURO', 'CESAR ERNESTO', 'CÉSAR AGUSTO', 'DIANA EDITH', 'RODRIGO FRANCO', 'GRETTEL ALEXANDRA', 'ROSA ANGELA', 'DANTE OMAR', 'YAJAIRA ALEXANDRA', 'JORGE ALBERTO', 'ALEXIS')\n",
      "Last Names: ('CORNEJO SANCHEZ', 'ORELLANA QUISPE', 'MORALES CHOQUEHUANCA', 'GUIMARAY RIBEYRO', 'CAMACHO GAVIDIA', 'TINTAYA ORIHUELA', 'CHAVEZ MARTINEZ', 'FIGUEROA MURO', 'GOMEZ CRIBILLERO', 'PALOMINO SEGUÍN', 'LUZON CUEVA', 'SUAÑA ZEGARRA', 'SOTO POMACHAGUA', 'FIORENTINO MARTINEZ', 'LAMA MAVILA', 'MEZA HINOJO', 'LOZADA MURILLO', 'ZAMBRANO JIMENEZ', 'JACOBS LUQUE', 'VIDAL VIDAL', 'TORRES ANICAMA', 'LOPEZ ESTRADA', 'BOYCO ORAMS', 'DIAZ BERROSPI', 'RIEGA ESCALANTE', 'LEVANO TORRES', 'ESQUIVES BRAVO', 'PEREZ GONZALES', 'OTERO MAGUIÑA', 'CLAVO CAMPOS', 'AGUILAR GARCIA', 'CALDAS VELASQUEZ', 'SALAS NUÑEZ BORJA', 'PIZARRO VILLANES', 'QUILLATUPA MORALES', 'HUANCAYA IDONE', 'CALVO PORTOCARRERO', 'IBAÑEZ ABANTO', 'MELÉNDEZ APONTE', 'CRISTIAN SERRANO', 'HINOJOSA CAHUANA', 'ANGLAS GARCÍA', 'ALDAVE ACOSTA', 'NÚÑEZ HUAMÁN', 'OBREGON HUAMAN', 'SOTO PACHERRES', 'INGARUCA RIVERA', 'ROJAS HUAMAN', 'NEYRA SALAS', 'HUERTA ESPINOZA', 'HUANCA MARTINEZ', 'FLORES CADILLO')\n"
     ]
    }
   ],
   "source": [
    "# 7) It asks to separate the last_and_name list into two lists: names and last_names using map() and split(). \n",
    "\n",
    "# We use map and split to separate last names and names\n",
    "separated = list(map(lambda x: x.split(\", \"), last_and_name))\n",
    "# Explanation: The lambda function takes each element x from the last_and_name list and\n",
    "# splits it into a list of two elements using \", \" as the separator.\n",
    "\n",
    "# We separate the new list into two lists\n",
    "last_names, names = zip(*separated)\n",
    "\n",
    "# We print the results\n",
    "print(\"Names:\", names)\n",
    "print(\"Last Names:\", last_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last names of students without email: ['HUANCAYA IDONE', 'CALVO PORTOCARRERO', 'IBAÑEZ ABANTO', 'MELÉNDEZ APONTE', 'CRISTIAN SERRANO', 'ANGLAS GARCÍA', 'ALDAVE ACOSTA', 'NÚÑEZ HUAMÁN', 'OBREGON HUAMAN', 'SOTO PACHERRES', 'INGARUCA RIVERA', 'ROJAS HUAMAN', 'NEYRA SALAS', 'HUERTA ESPINOZA', 'HUANCA MARTINEZ']\n"
     ]
    }
   ],
   "source": [
    "# 8) It asks to print the last names of students who do not have an email registered in the emails list using map() and split().\n",
    "\n",
    "# We obtain the boolean values for empty emails\n",
    "empty_email_flags = list(map(lambda x: x == \"\", emails))\n",
    "\n",
    "# We filter the last names corresponding to empty emails\n",
    "filtered_last_names = [last_names[i] for i in range(len(emails)) if empty_email_flags[i]]\n",
    "# Explanation: For each index in the range of the length of emails, if the value in empty_email_flags\n",
    "# is True (empty email), we add the corresponding last name to filtered_last_names.\n",
    "\n",
    "# We print the filtered last names\n",
    "print(\"Last names of students without email:\", filtered_last_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Strings\n",
    "\n",
    "\n",
    "1. Drop the duplicated blank spaces in `str1`. Do not use the regular expresions. Do not use the code shown in class. Explain your steps.**Hint: Use `split` method and `join` function.**\n",
    "\n",
    "2. Get the number of letters in the string .**Hint: Use `len`function.**\n",
    "\n",
    "3. Get the number of blank spaces (all of them) in the string .**Hint: Use `len`function.**\n",
    "\n",
    "4. Get the position of `@` in each string in the emails list. **Hint: Use `map`function and `find` method.**\n",
    "\n",
    "5. Identifies if exists `.edu.`  in each string in the `emails` list. Get a list of Booleans. **Hint: Use `map`function and `find` method.**\n",
    "\n",
    "6. Get all the strings before the first dot `.`in each string in the `emails` list. Identifies how many of them has `@`. **Hint: Use `map`function and `find` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = 'I am                            too                                                        old'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = [\"cscornejo@pucp.edu.pe\", \"orellana.cn@pucp.edu.pe\", \"karina.morales@pucp.edu.pe\", \"a20083223@pucp.pe\", \"abel.camacho@pucp.pe\", \"mtintaya@pucp.edu.pe\", \"joselin.chavez@pucp.edu.pe\", \"a20105737@pucp.pe\", \"jfgomezc@pucp.pe\", \"afrania.palomino@pucp.pe\", \"luzon.bianca@pucp.pe\", \"adrian.suanaz@pucp.pe\", \"soto.y@pucp.edu.pe\", \"a20132766@pucp.pe\", \"andre.lama@pucp.edu.pe\", \"gustavo.meza@pucp.edu.pe\", \"pmlozada@pucp.edu.pe\", \"m.zambranoj@pucp.edu.pe\", \"nicolas.jacobs@pucp.edu.pe\", \"gvidal@pucp.edu.pe\", \"jane.torres@pucp.edu.pe\", \"m.lopez@pucp.edu.pe\", \"alejandro.boyco@pucp.edu.pe\", \"a20167070@pucp.edu.pe\", \"riega.stephy@pucp.edu.pe\", \"vlevanot@pucp.edu.pe\", \"sesquives@pucp.edu.pe\", \"perez.juanc@pucp.edu.pe\", \"mariana.otero@pucp.edu.pe\", \"aclavo@pucp.edu.pe\", \"a20182474@pucp.edu.pe\", \"josue.caldas@pucp.edu.pe\", \"fabio.salas@pucp.edu.pe\", \"fernanda.pizarro@pucp.edu.pe\", \"aquillatupa@pucp.pe\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am too old\n"
     ]
    }
   ],
   "source": [
    "# 1) It asks to remove unnecessary blank spaces in the str1 string using the split() and join() functions.\n",
    "\n",
    "# We use split to divide the string into words, removing unnecessary blank spaces\n",
    "words = str1.split()\n",
    "# Explanation: The split() function without arguments divides the string into words\n",
    "# using any amount of whitespace as a separator.\n",
    "\n",
    "# We use join to combine the words with a single space between them\n",
    "cleaned_str1 = ' '.join(words)\n",
    "\n",
    "# We print the cleaned string\n",
    "print(cleaned_str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of letters in str1 is 9.\n"
     ]
    }
   ],
   "source": [
    "# 2) It asks to calculate the number of letters in str1 using the len() function.\n",
    "\n",
    "# From the cleaned string, we count the number of letters excluding spaces\n",
    "num_letters = len(cleaned_str1.replace(\" \", \"\"))\n",
    "\n",
    "# We print the number of letters\n",
    "print(f\"The number of letters in str1 is {num_letters}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of spaces in str1 is 85.\n"
     ]
    }
   ],
   "source": [
    "# 3) It asks to calculate the number of spaces in the original str1 using the len() function.\n",
    "\n",
    "# We count the number of characters in the original str1 string\n",
    "len_str1 = len(str1)\n",
    "\n",
    "# We subtract the number of letters calculated previously\n",
    "num_spaces = len_str1 - num_letters\n",
    "\n",
    "# We print the number of spaces\n",
    "print(f\"The number of spaces in str1 is {num_spaces}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 11, 14, 9, 12, 8, 14, 9, 8, 16, 12, 13, 6, 9, 10, 12, 8, 11, 14, 6, 11, 7, 15, 9, 12, 8, 9, 11, 13, 6, 9, 12, 11, 16, 11]\n"
     ]
    }
   ],
   "source": [
    "# 4) It asks to identify the index of \"@\" in each element of the emails list and return the result using the map() and find() functions.\n",
    "\n",
    "# We use map and find to obtain the index of \"@\" in each email.\n",
    "list_of_at_index = list(map(lambda x: x.find(\"@\"), emails))\n",
    "# Explanation: The lambda function takes each email x and uses find() to search for the \"@\" character.\n",
    "\n",
    "# We print the result\n",
    "print(list_of_at_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, False, False, True, True, False, False, False, False, False, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False]\n"
     ]
    }
   ],
   "source": [
    "# 5) It asks to identify whether the string \".edu.\" exists in each element of the emails list and return a boolean using the map() and find() functions.\n",
    "\n",
    "# We use map and find to check the presence of \".edu.\" in each email.\n",
    "list_of_edu = list(map(lambda x: x.find(\".edu.\") != -1, emails))\n",
    "# Explanation: The lambda function takes each email x and uses find() to search for the substring \".edu.\".\n",
    "# If it is found, find() returns an index >= 0, so we compare it with -1 to get a boolean.\n",
    "\n",
    "# We print the result\n",
    "print(list_of_edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cscornejo@pucp', 'orellana', 'karina', 'a20083223@pucp', 'abel', 'mtintaya@pucp', 'joselin', 'a20105737@pucp', 'jfgomezc@pucp', 'afrania', 'luzon', 'adrian', 'soto', 'a20132766@pucp', 'andre', 'gustavo', 'pmlozada@pucp', 'm', 'nicolas', 'gvidal@pucp', 'jane', 'm', 'alejandro', 'a20167070@pucp', 'riega', 'vlevanot@pucp', 'sesquives@pucp', 'perez', 'mariana', 'aclavo@pucp', 'a20182474@pucp', 'josue', 'fabio', 'fernanda', 'aquillatupa@pucp']\n",
      "The number of elements with '@' is 35.\n"
     ]
    }
   ],
   "source": [
    "# 6) It asks to print the string before the \".\" character and count the number of elements that have \"@\" in them using the map() and find() functions.\n",
    "\n",
    "# We use map and find to get the string before the first \".\" in each email.\n",
    "list_before_dot = list(map(lambda x: x[:x.find(\".\")], emails))\n",
    "# Explanation: The lambda function takes each email x and uses find() to search for the \".\" character.\n",
    "# With the obtained index, we extract the substring from the beginning up to that index.\n",
    "\n",
    "# We count the number of elements that have \"@\" in them\n",
    "list_with_at = list(map(lambda x: x.find(\"@\") != -1, emails))\n",
    "# Explanation: The lambda function takes each email x and uses find() to search for the \"@\" character.\n",
    "# If it is found, find() returns an index >= 0, so we compare it with -1 to get a boolean.\n",
    "\n",
    "# We sum the boolean values to get the count of elements with \"@\"\n",
    "count_with_at = sum(list_with_at)\n",
    "\n",
    "# We print the results\n",
    "print(list_before_dot)\n",
    "print(f\"The number of elements with '@' is {count_with_at}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Assignment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance<1.0\n",
      "  Downloading yfinance-0.2.66-py2.py3-none-any.whl (123 kB)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\usuario\\anaconda3\\lib\\site-packages (4.1.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from yfinance<1.0) (1.21.5)\n",
      "Requirement already satisfied: websockets>=13.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from yfinance<1.0) (15.0.1)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from yfinance<1.0) (3.19.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from yfinance<1.0) (4.11.1)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from yfinance<1.0) (0.0.12)\n",
      "Requirement already satisfied: curl_cffi>=0.7 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from yfinance<1.0) (0.13.0)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from yfinance<1.0) (4.4.0)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from yfinance<1.0) (2.32.5)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from yfinance<1.0) (2025.2)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from yfinance<1.0) (3.19.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from yfinance<1.0) (2.4.7)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from yfinance<1.0) (1.4.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance<1.0) (2.3.1)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from curl_cffi>=0.7->yfinance<1.0) (2026.1.4)\n",
      "Requirement already satisfied: cffi>=1.12.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from curl_cffi>=0.7->yfinance<1.0) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance<1.0) (2.21)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance<1.0) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.3.0->yfinance<1.0) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance<1.0) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance<1.0) (1.26.9)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance<1.0) (2.0.4)\n",
      "Installing collected packages: yfinance\n",
      "  Attempting uninstall: yfinance\n",
      "    Found existing installation: yfinance 1.0\n",
      "    Uninstalling yfinance-1.0:\n",
      "      Successfully uninstalled yfinance-1.0\n",
      "Successfully installed yfinance-0.2.66\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"yfinance<1.0\" typing_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "START = \"2022-01-01\"\n",
    "END = \"2025-12-18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USUARIO\\anaconda3\\lib\\site-packages\\yfinance\\multi.py:281: DeprecationWarning: 'raise_errors' deprecated, do: yf.config.debug.hide_exceptions = False\n",
      "  data = Ticker(ticker).history(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(        date ticker      close    volume\n",
       " 0 2022-01-03    EEM  44.624969  27572700\n",
       " 1 2022-01-04    EEM  44.470772  24579500\n",
       " 2 2022-01-05    EEM  43.745163  46425100\n",
       " 3 2022-01-06    EEM  43.944706  34288700\n",
       " 4 2022-01-07    EEM  44.343788  32640900,\n",
       " (4970, 4))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Yahoo Finance via yfinance: US tickers (real market yh_df) ---\n",
    "tickers = [\"SPY\", \"QQQ\", \"TLT\", \"GLD\", \"EEM\"]\n",
    "# SPY : S&P 500 index\n",
    "# QQQ : Nasdaq-100 index\n",
    "# TLT : U.S. Treasury bonds with 20+ year maturity\n",
    "# GLD : Physical gold prices\n",
    "# EEM : MSCI Emerging Markets index\n",
    "\n",
    "try:\n",
    "    import yfinance as yf\n",
    "except Exception as e:\n",
    "    yf = None\n",
    "    print(\"Could not import yfinance:\", type(e).__name__, str(e))\n",
    "\n",
    "if yf is not None:\n",
    "    try:\n",
    "        yh_df = yf.download(tickers, start=START, end=END, auto_adjust=True, progress=False)\n",
    "    except Exception as e:\n",
    "        yh_df = pd.DataFrame()\n",
    "        print(\"yfinance download failed:\", type(e).__name__, str(e))\n",
    "else:\n",
    "    yh_df = pd.DataFrame()\n",
    "\n",
    "# Convert to long format: date, ticker, close, volume\n",
    "if isinstance(yh_df, pd.DataFrame) and yh_df.shape[0] > 0:\n",
    "    if isinstance(yh_df.columns, pd.MultiIndex):\n",
    "        close = yh_df[\"Close\"].copy()\n",
    "        vol = yh_df[\"Volume\"].copy()\n",
    "    else:\n",
    "        close = yh_df[[\"Close\"]].rename(columns={\"Close\": tickers[0]})\n",
    "        vol = yh_df[[\"Volume\"]].rename(columns={\"Volume\": tickers[0]})\n",
    "\n",
    "    close.index.name = \"date\"\n",
    "    vol.index.name = \"date\"\n",
    "\n",
    "    us_close_long = close.reset_index().melt(id_vars=\"date\", var_name=\"ticker\", value_name=\"close\")\n",
    "    us_vol_long = vol.reset_index().melt(id_vars=\"date\", var_name=\"ticker\", value_name=\"volume\")\n",
    "    us_mkt = us_close_long.merge(us_vol_long, on=[\"date\",\"ticker\"], how=\"inner\").dropna(subset=[\"close\"])\n",
    "else:\n",
    "    us_mkt = pd.DataFrame(columns=[\"date\",\"ticker\",\"close\",\"volume\"])\n",
    "\n",
    "us_mkt.head(), us_mkt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_raw</th>\n",
       "      <th>PENUSD_buy</th>\n",
       "      <th>PENUSD_sell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03.Ene.22</td>\n",
       "      <td>3.98366666666667</td>\n",
       "      <td>3.98883333333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04.Ene.22</td>\n",
       "      <td>3.9595</td>\n",
       "      <td>3.964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05.Ene.22</td>\n",
       "      <td>3.952</td>\n",
       "      <td>3.95633333333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06.Ene.22</td>\n",
       "      <td>3.96716666666667</td>\n",
       "      <td>3.96966666666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07.Ene.22</td>\n",
       "      <td>3.94516666666667</td>\n",
       "      <td>3.94816666666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>12.Dic.25</td>\n",
       "      <td>3.36685714285714</td>\n",
       "      <td>3.36885714285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>15.Dic.25</td>\n",
       "      <td>3.36871428571429</td>\n",
       "      <td>3.3705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>16.Dic.25</td>\n",
       "      <td>3.36985714285714</td>\n",
       "      <td>3.37142857142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>17.Dic.25</td>\n",
       "      <td>3.36771428571429</td>\n",
       "      <td>3.36914285714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>18.Dic.25</td>\n",
       "      <td>3.36514285714286</td>\n",
       "      <td>3.36664285714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>988 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      date_raw        PENUSD_buy       PENUSD_sell\n",
       "0    03.Ene.22  3.98366666666667  3.98883333333333\n",
       "1    04.Ene.22            3.9595             3.964\n",
       "2    05.Ene.22             3.952  3.95633333333333\n",
       "3    06.Ene.22  3.96716666666667  3.96966666666667\n",
       "4    07.Ene.22  3.94516666666667  3.94816666666667\n",
       "..         ...               ...               ...\n",
       "983  12.Dic.25  3.36685714285714  3.36885714285714\n",
       "984  15.Dic.25  3.36871428571429            3.3705\n",
       "985  16.Dic.25  3.36985714285714  3.37142857142857\n",
       "986  17.Dic.25  3.36771428571429  3.36914285714286\n",
       "987  18.Dic.25  3.36514285714286  3.36664285714286\n",
       "\n",
       "[988 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- BCRP: daily exchange rate PEN/USD buy & sell (official API) ---\n",
    "# Codes:\n",
    "# - PD04637PD: USD/PEN (buy)\n",
    "# - PD04638PD: USD/PEN (sell)\n",
    "\n",
    "import requests\n",
    "\n",
    "bcrp_url = f\"https://estadisticas.bcrp.gob.pe/estadisticas/series/api/PD04637PD-PD04638PD/json/{START}/{END}/esp\"\n",
    "try:\n",
    "    r = requests.get(bcrp_url, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    bcrp_obj = r.json()\n",
    "except Exception as e:\n",
    "    bcrp_obj = {\"periods\": []}\n",
    "    print(\"BCRP request failed:\", type(e).__name__, str(e))\n",
    "\n",
    "periods = bcrp_obj.get(\"periods\", [])\n",
    "rows = []\n",
    "for p in periods:\n",
    "    name = p.get(\"name\")\n",
    "    vals = p.get(\"values\", [])\n",
    "    if isinstance(vals, str):\n",
    "        vals = [vals]\n",
    "    if name is None or not isinstance(vals, list) or len(vals) < 2:\n",
    "        continue\n",
    "    rows.append([name, vals[0], vals[1]])\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"date_raw\", \"PENUSD_buy\", \"PENUSD_sell\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.2 From NumPy array to Series \n",
    "\n",
    "Using `us_mkt`:\n",
    "\n",
    "1. Filter to `ticker == \"SPY\"`.\n",
    "2. Take `close` as a NumPy array.\n",
    "3. Create a Series indexed by `date` named `SPY_close_series`.\n",
    "4. Compute the mean/min/max with Series methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.3 From Dictionary to Series \n",
    "\n",
    "Using `us_mkt`:\n",
    "\n",
    "1. Compute the **last available close** for each ticker in `tickers`.\n",
    "2. Store it in a dict `{ticker: last_close}`.\n",
    "3. Convert to a Series and sort descending."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.4 Series vs NumPy \n",
    "\n",
    "Goal: show why pandas alignment matters.\n",
    "\n",
    "1. Create two Series indexed by date:\n",
    "   - df mid-rate from `df`\n",
    "   - SPY close from `us_mkt`\n",
    "2. Combine them into a yh_dfFrame (pandas aligns on dates).\n",
    "3. Separately, build two NumPy arrays by truncating to the same length.\n",
    "4. In markdown: explain why alignment is safer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.5 Dealing with Nulls \n",
    "Using `us_mkt`:\n",
    "\n",
    "1. Copy `us_mkt` to `us_mkt_nan`.\n",
    "2. Set 1% of `close` to NaN (fixed random seed).\n",
    "3. Create:\n",
    "   - `us_drop`: drop NaNs\n",
    "   - `us_fill`: fill NaNs with ticker-specific median close\n",
    "4. Compare shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.6 Duplicates \n",
    "\n",
    "1. Create `dup_df` by stacking the last 5 rows of `us_mkt` twice.\n",
    "2. Detect duplicates using `.duplicated()`.\n",
    "3. Remove them using `.drop_duplicates()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.8 Groupby \n",
    "\n",
    "\n",
    "Using `us_mkt`:\n",
    "\n",
    "1. Group by `ticker` and compute:\n",
    "   - mean close\n",
    "   - median close\n",
    "   - max volume\n",
    "2. Rename columns clearly.\n",
    "3. Sort by mean close descending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_close</th>\n",
       "      <th>median_close</th>\n",
       "      <th>max_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SPY</th>\n",
       "      <td>485.608584</td>\n",
       "      <td>460.740021</td>\n",
       "      <td>256611400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QQQ</th>\n",
       "      <td>411.276968</td>\n",
       "      <td>400.214539</td>\n",
       "      <td>198685800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLD</th>\n",
       "      <td>220.130422</td>\n",
       "      <td>187.864998</td>\n",
       "      <td>62025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TLT</th>\n",
       "      <td>91.395621</td>\n",
       "      <td>88.549698</td>\n",
       "      <td>131353500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEM</th>\n",
       "      <td>40.462350</td>\n",
       "      <td>39.107409</td>\n",
       "      <td>134225700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean_close  median_close  max_volume\n",
       "ticker                                      \n",
       "SPY     485.608584    460.740021   256611400\n",
       "QQQ     411.276968    400.214539   198685800\n",
       "GLD     220.130422    187.864998    62025000\n",
       "TLT      91.395621     88.549698   131353500\n",
       "EEM      40.462350     39.107409   134225700"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by ticker and compute closing price statistics\n",
    "# Mean and median are calculated over the close variable\n",
    "group_stats = us_mkt.groupby(\"ticker\").close.agg([\"mean\", \"median\"])\n",
    "\n",
    "# Add the maximum traded volume per ticker to the same DataFrame\n",
    "group_stats[\"max_volume\"] = us_mkt.groupby(\"ticker\").volume.max()\n",
    "\n",
    "# Rename columns for clarity and easier interpretation\n",
    "group_stats = group_stats.rename(columns={\n",
    "    \"mean\": \"mean_close\",\n",
    "    \"median\": \"median_close\"\n",
    "})\n",
    "\n",
    "# Sort assets by average closing price in descending order\n",
    "group_stats = group_stats.sort_values(\"mean_close\", ascending=False)\n",
    "\n",
    "group_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of results (3.3.8)\n",
    "\n",
    "The table summarizes the average behavior of closing prices and liquidity for each ETF over the 2022–2025 period.\n",
    "\n",
    "For all assets, the mean closing price is higher than the median, suggesting an upward trend, with relatively higher prices concentrated in more recent years.\n",
    "\n",
    "SPY and QQQ exhibit the highest average prices and the largest maximum trading volumes, reflecting their high liquidity and their importance as major U.S. equity ETFs. GLD shows a noticeable gap between the mean and the median, consistent with price spikes associated with its role as a safe-haven asset.\n",
    "\n",
    "In contrast, TLT displays lower and more stable prices, with relatively less dispersion, which is characteristic of fixed-income instruments. EEM presents lower average prices but relatively high trading volumes, indicating a high turnover rate.\n",
    "\n",
    "Overall, these results show that grouping by ticker allows for a clear comparison of price levels and liquidity across different types of financial assets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.9 Reshape \n",
    "\n",
    "1. Create a 1-row wide yh_dfFrame with last closes per ticker.\n",
    "2. Convert it to long format with `melt()` into columns: `ticker`, `last_close`.\n",
    "3. Pivot `us_mkt` into a wide table: index=`date`, columns=`ticker`, values=`close` (keep first 50 dates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ticker</th>\n",
       "      <th>EEM</th>\n",
       "      <th>GLD</th>\n",
       "      <th>QQQ</th>\n",
       "      <th>SPY</th>\n",
       "      <th>TLT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>close</th>\n",
       "      <td>52.599998</td>\n",
       "      <td>399.290009</td>\n",
       "      <td>599.63739</td>\n",
       "      <td>669.421936</td>\n",
       "      <td>87.459633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ticker        EEM         GLD        QQQ         SPY        TLT\n",
       "close   52.599998  399.290009  599.63739  669.421936  87.459633"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort observations by date and obtain the last available closing price per ticker\n",
    "last_close = (\n",
    "    us_mkt\n",
    "    .sort_values(\"date\")\n",
    "    .groupby(\"ticker\")\n",
    "    .close\n",
    "    .last()\n",
    ")\n",
    "\n",
    "last_close_wide = last_close.to_frame().T\n",
    "last_close_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of results (3.3.9.a)\n",
    "\n",
    "La tabla muestra un activo financiero y el valor corresponde al precio observado en la fecha más reciente de la base de datos.\n",
    "\n",
    "Este resumen reduce la dimensión temporal del dataset y presenta la información en formato wide, lo que facilita la comparación directa entre activos. Asi mismos sucede en 3.3.9.b y 3.3.9.c dado que el objetivo del ejercicio es ilustrar la transformación de formato long a wide y no analizar la serie completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>last_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EEM</td>\n",
       "      <td>52.599998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GLD</td>\n",
       "      <td>399.290009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QQQ</td>\n",
       "      <td>599.637390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPY</td>\n",
       "      <td>669.421936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TLT</td>\n",
       "      <td>87.459633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker  last_close\n",
       "0    EEM   52.599998\n",
       "1    GLD  399.290009\n",
       "2    QQQ  599.637390\n",
       "3    SPY  669.421936\n",
       "4    TLT   87.459633"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.3.9.B Change the DataFrame structure from wide to long format without losing information\n",
    "last_close_long = last_close_wide.melt(\n",
    "    var_name=\"ticker\",\n",
    "    value_name=\"last_close\"\n",
    ")\n",
    "\n",
    "last_close_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ticker</th>\n",
       "      <th>EEM</th>\n",
       "      <th>GLD</th>\n",
       "      <th>QQQ</th>\n",
       "      <th>SPY</th>\n",
       "      <th>TLT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>44.624969</td>\n",
       "      <td>168.330002</td>\n",
       "      <td>391.679504</td>\n",
       "      <td>451.875183</td>\n",
       "      <td>125.295364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04</th>\n",
       "      <td>44.470772</td>\n",
       "      <td>169.570007</td>\n",
       "      <td>386.599152</td>\n",
       "      <td>451.723755</td>\n",
       "      <td>124.774391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "      <td>43.745163</td>\n",
       "      <td>169.059998</td>\n",
       "      <td>374.722382</td>\n",
       "      <td>443.049683</td>\n",
       "      <td>124.097130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-06</th>\n",
       "      <td>43.944706</td>\n",
       "      <td>166.990005</td>\n",
       "      <td>374.459198</td>\n",
       "      <td>442.633514</td>\n",
       "      <td>124.418335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-07</th>\n",
       "      <td>44.343788</td>\n",
       "      <td>167.750000</td>\n",
       "      <td>370.402740</td>\n",
       "      <td>440.883514</td>\n",
       "      <td>123.524010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-10</th>\n",
       "      <td>44.343788</td>\n",
       "      <td>168.259995</td>\n",
       "      <td>370.646515</td>\n",
       "      <td>440.334930</td>\n",
       "      <td>123.827942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-11</th>\n",
       "      <td>45.368717</td>\n",
       "      <td>170.289993</td>\n",
       "      <td>376.214355</td>\n",
       "      <td>444.345703</td>\n",
       "      <td>124.652824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-12</th>\n",
       "      <td>46.121536</td>\n",
       "      <td>170.740005</td>\n",
       "      <td>377.706238</td>\n",
       "      <td>445.546936</td>\n",
       "      <td>124.175255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-13</th>\n",
       "      <td>45.468483</td>\n",
       "      <td>170.160004</td>\n",
       "      <td>368.257477</td>\n",
       "      <td>439.407928</td>\n",
       "      <td>125.277954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-14</th>\n",
       "      <td>45.450344</td>\n",
       "      <td>169.669998</td>\n",
       "      <td>370.549011</td>\n",
       "      <td>439.587646</td>\n",
       "      <td>123.385117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-18</th>\n",
       "      <td>44.643105</td>\n",
       "      <td>169.389999</td>\n",
       "      <td>361.324524</td>\n",
       "      <td>431.802765</td>\n",
       "      <td>121.648468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-19</th>\n",
       "      <td>44.833576</td>\n",
       "      <td>172.080002</td>\n",
       "      <td>357.355774</td>\n",
       "      <td>427.319092</td>\n",
       "      <td>122.490768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-20</th>\n",
       "      <td>45.096611</td>\n",
       "      <td>171.649994</td>\n",
       "      <td>352.714355</td>\n",
       "      <td>422.589447</td>\n",
       "      <td>123.246155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-21</th>\n",
       "      <td>44.443565</td>\n",
       "      <td>171.089996</td>\n",
       "      <td>342.934082</td>\n",
       "      <td>414.293793</td>\n",
       "      <td>124.713600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-24</th>\n",
       "      <td>43.817726</td>\n",
       "      <td>172.029999</td>\n",
       "      <td>344.503906</td>\n",
       "      <td>416.053192</td>\n",
       "      <td>123.688965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-25</th>\n",
       "      <td>43.736095</td>\n",
       "      <td>172.580002</td>\n",
       "      <td>336.517792</td>\n",
       "      <td>410.973602</td>\n",
       "      <td>123.489311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-26</th>\n",
       "      <td>43.182816</td>\n",
       "      <td>169.789993</td>\n",
       "      <td>335.991364</td>\n",
       "      <td>409.942566</td>\n",
       "      <td>121.995804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-27</th>\n",
       "      <td>42.683964</td>\n",
       "      <td>167.600006</td>\n",
       "      <td>332.607697</td>\n",
       "      <td>407.918274</td>\n",
       "      <td>124.236053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-28</th>\n",
       "      <td>42.892570</td>\n",
       "      <td>167.100006</td>\n",
       "      <td>343.041321</td>\n",
       "      <td>418.049042</td>\n",
       "      <td>124.279427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-31</th>\n",
       "      <td>44.298439</td>\n",
       "      <td>168.089996</td>\n",
       "      <td>354.011230</td>\n",
       "      <td>425.578644</td>\n",
       "      <td>123.636917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-01</th>\n",
       "      <td>44.570549</td>\n",
       "      <td>168.229996</td>\n",
       "      <td>356.419739</td>\n",
       "      <td>428.454193</td>\n",
       "      <td>123.226524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-02</th>\n",
       "      <td>44.497978</td>\n",
       "      <td>168.839996</td>\n",
       "      <td>359.315735</td>\n",
       "      <td>432.616272</td>\n",
       "      <td>123.643875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-03</th>\n",
       "      <td>44.026337</td>\n",
       "      <td>168.600006</td>\n",
       "      <td>344.747742</td>\n",
       "      <td>422.447601</td>\n",
       "      <td>122.678719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-04</th>\n",
       "      <td>44.135178</td>\n",
       "      <td>168.860001</td>\n",
       "      <td>349.096710</td>\n",
       "      <td>424.434082</td>\n",
       "      <td>120.870102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-07</th>\n",
       "      <td>44.044483</td>\n",
       "      <td>170.110001</td>\n",
       "      <td>346.288422</td>\n",
       "      <td>423.071869</td>\n",
       "      <td>120.948448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-08</th>\n",
       "      <td>44.470772</td>\n",
       "      <td>170.630005</td>\n",
       "      <td>350.179077</td>\n",
       "      <td>426.552887</td>\n",
       "      <td>120.139732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-09</th>\n",
       "      <td>45.169170</td>\n",
       "      <td>171.210007</td>\n",
       "      <td>357.599609</td>\n",
       "      <td>432.795898</td>\n",
       "      <td>120.365807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-10</th>\n",
       "      <td>44.869858</td>\n",
       "      <td>170.559998</td>\n",
       "      <td>349.506195</td>\n",
       "      <td>425.020447</td>\n",
       "      <td>118.452911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-11</th>\n",
       "      <td>44.189606</td>\n",
       "      <td>173.809998</td>\n",
       "      <td>338.419403</td>\n",
       "      <td>416.639679</td>\n",
       "      <td>120.209312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-14</th>\n",
       "      <td>43.881218</td>\n",
       "      <td>174.740005</td>\n",
       "      <td>338.838562</td>\n",
       "      <td>415.277496</td>\n",
       "      <td>118.713768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-15</th>\n",
       "      <td>44.833576</td>\n",
       "      <td>173.080002</td>\n",
       "      <td>347.263519</td>\n",
       "      <td>421.974670</td>\n",
       "      <td>117.366066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-16</th>\n",
       "      <td>45.160103</td>\n",
       "      <td>174.860001</td>\n",
       "      <td>347.175781</td>\n",
       "      <td>422.447601</td>\n",
       "      <td>118.061661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-17</th>\n",
       "      <td>44.634033</td>\n",
       "      <td>177.250000</td>\n",
       "      <td>336.849365</td>\n",
       "      <td>413.423553</td>\n",
       "      <td>118.939819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-18</th>\n",
       "      <td>44.189606</td>\n",
       "      <td>177.119995</td>\n",
       "      <td>333.007477</td>\n",
       "      <td>410.746613</td>\n",
       "      <td>120.191971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-22</th>\n",
       "      <td>43.563766</td>\n",
       "      <td>177.490005</td>\n",
       "      <td>329.662842</td>\n",
       "      <td>406.338623</td>\n",
       "      <td>120.504936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-23</th>\n",
       "      <td>43.055836</td>\n",
       "      <td>178.289993</td>\n",
       "      <td>321.218536</td>\n",
       "      <td>399.130707</td>\n",
       "      <td>118.844193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-24</th>\n",
       "      <td>42.166965</td>\n",
       "      <td>177.139999</td>\n",
       "      <td>332.012939</td>\n",
       "      <td>405.137268</td>\n",
       "      <td>118.922440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-25</th>\n",
       "      <td>42.946995</td>\n",
       "      <td>176.550003</td>\n",
       "      <td>337.161438</td>\n",
       "      <td>414.076202</td>\n",
       "      <td>119.009415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-28</th>\n",
       "      <td>42.384644</td>\n",
       "      <td>178.380005</td>\n",
       "      <td>338.165833</td>\n",
       "      <td>413.016846</td>\n",
       "      <td>121.617935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-01</th>\n",
       "      <td>41.822300</td>\n",
       "      <td>181.619995</td>\n",
       "      <td>332.988037</td>\n",
       "      <td>406.726410</td>\n",
       "      <td>123.024025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-02</th>\n",
       "      <td>41.894859</td>\n",
       "      <td>179.729996</td>\n",
       "      <td>338.575317</td>\n",
       "      <td>414.208649</td>\n",
       "      <td>118.818733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-03</th>\n",
       "      <td>41.305309</td>\n",
       "      <td>180.800003</td>\n",
       "      <td>333.738861</td>\n",
       "      <td>412.146545</td>\n",
       "      <td>120.028954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-04</th>\n",
       "      <td>40.470856</td>\n",
       "      <td>183.679993</td>\n",
       "      <td>328.902313</td>\n",
       "      <td>408.797974</td>\n",
       "      <td>122.101135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-07</th>\n",
       "      <td>38.956146</td>\n",
       "      <td>186.410004</td>\n",
       "      <td>316.772034</td>\n",
       "      <td>396.747009</td>\n",
       "      <td>121.169510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-08</th>\n",
       "      <td>39.083126</td>\n",
       "      <td>191.509995</td>\n",
       "      <td>315.299683</td>\n",
       "      <td>393.738953</td>\n",
       "      <td>119.950600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-09</th>\n",
       "      <td>40.189682</td>\n",
       "      <td>185.820007</td>\n",
       "      <td>326.649811</td>\n",
       "      <td>404.295471</td>\n",
       "      <td>118.775192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-10</th>\n",
       "      <td>39.436863</td>\n",
       "      <td>186.399994</td>\n",
       "      <td>323.022430</td>\n",
       "      <td>402.469727</td>\n",
       "      <td>117.068726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-11</th>\n",
       "      <td>38.611485</td>\n",
       "      <td>185.089996</td>\n",
       "      <td>316.323517</td>\n",
       "      <td>397.352325</td>\n",
       "      <td>117.460518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-14</th>\n",
       "      <td>37.677254</td>\n",
       "      <td>182.300003</td>\n",
       "      <td>310.248627</td>\n",
       "      <td>394.448395</td>\n",
       "      <td>114.717941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-15</th>\n",
       "      <td>37.731678</td>\n",
       "      <td>178.889999</td>\n",
       "      <td>319.980133</td>\n",
       "      <td>403.122528</td>\n",
       "      <td>114.517693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ticker            EEM         GLD         QQQ         SPY         TLT\n",
       "date                                                                 \n",
       "2022-01-03  44.624969  168.330002  391.679504  451.875183  125.295364\n",
       "2022-01-04  44.470772  169.570007  386.599152  451.723755  124.774391\n",
       "2022-01-05  43.745163  169.059998  374.722382  443.049683  124.097130\n",
       "2022-01-06  43.944706  166.990005  374.459198  442.633514  124.418335\n",
       "2022-01-07  44.343788  167.750000  370.402740  440.883514  123.524010\n",
       "2022-01-10  44.343788  168.259995  370.646515  440.334930  123.827942\n",
       "2022-01-11  45.368717  170.289993  376.214355  444.345703  124.652824\n",
       "2022-01-12  46.121536  170.740005  377.706238  445.546936  124.175255\n",
       "2022-01-13  45.468483  170.160004  368.257477  439.407928  125.277954\n",
       "2022-01-14  45.450344  169.669998  370.549011  439.587646  123.385117\n",
       "2022-01-18  44.643105  169.389999  361.324524  431.802765  121.648468\n",
       "2022-01-19  44.833576  172.080002  357.355774  427.319092  122.490768\n",
       "2022-01-20  45.096611  171.649994  352.714355  422.589447  123.246155\n",
       "2022-01-21  44.443565  171.089996  342.934082  414.293793  124.713600\n",
       "2022-01-24  43.817726  172.029999  344.503906  416.053192  123.688965\n",
       "2022-01-25  43.736095  172.580002  336.517792  410.973602  123.489311\n",
       "2022-01-26  43.182816  169.789993  335.991364  409.942566  121.995804\n",
       "2022-01-27  42.683964  167.600006  332.607697  407.918274  124.236053\n",
       "2022-01-28  42.892570  167.100006  343.041321  418.049042  124.279427\n",
       "2022-01-31  44.298439  168.089996  354.011230  425.578644  123.636917\n",
       "2022-02-01  44.570549  168.229996  356.419739  428.454193  123.226524\n",
       "2022-02-02  44.497978  168.839996  359.315735  432.616272  123.643875\n",
       "2022-02-03  44.026337  168.600006  344.747742  422.447601  122.678719\n",
       "2022-02-04  44.135178  168.860001  349.096710  424.434082  120.870102\n",
       "2022-02-07  44.044483  170.110001  346.288422  423.071869  120.948448\n",
       "2022-02-08  44.470772  170.630005  350.179077  426.552887  120.139732\n",
       "2022-02-09  45.169170  171.210007  357.599609  432.795898  120.365807\n",
       "2022-02-10  44.869858  170.559998  349.506195  425.020447  118.452911\n",
       "2022-02-11  44.189606  173.809998  338.419403  416.639679  120.209312\n",
       "2022-02-14  43.881218  174.740005  338.838562  415.277496  118.713768\n",
       "2022-02-15  44.833576  173.080002  347.263519  421.974670  117.366066\n",
       "2022-02-16  45.160103  174.860001  347.175781  422.447601  118.061661\n",
       "2022-02-17  44.634033  177.250000  336.849365  413.423553  118.939819\n",
       "2022-02-18  44.189606  177.119995  333.007477  410.746613  120.191971\n",
       "2022-02-22  43.563766  177.490005  329.662842  406.338623  120.504936\n",
       "2022-02-23  43.055836  178.289993  321.218536  399.130707  118.844193\n",
       "2022-02-24  42.166965  177.139999  332.012939  405.137268  118.922440\n",
       "2022-02-25  42.946995  176.550003  337.161438  414.076202  119.009415\n",
       "2022-02-28  42.384644  178.380005  338.165833  413.016846  121.617935\n",
       "2022-03-01  41.822300  181.619995  332.988037  406.726410  123.024025\n",
       "2022-03-02  41.894859  179.729996  338.575317  414.208649  118.818733\n",
       "2022-03-03  41.305309  180.800003  333.738861  412.146545  120.028954\n",
       "2022-03-04  40.470856  183.679993  328.902313  408.797974  122.101135\n",
       "2022-03-07  38.956146  186.410004  316.772034  396.747009  121.169510\n",
       "2022-03-08  39.083126  191.509995  315.299683  393.738953  119.950600\n",
       "2022-03-09  40.189682  185.820007  326.649811  404.295471  118.775192\n",
       "2022-03-10  39.436863  186.399994  323.022430  402.469727  117.068726\n",
       "2022-03-11  38.611485  185.089996  316.323517  397.352325  117.460518\n",
       "2022-03-14  37.677254  182.300003  310.248627  394.448395  114.717941\n",
       "2022-03-15  37.731678  178.889999  319.980133  403.122528  114.517693"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  3.3.9.C Reorganize the dataset from long to wide format: each row represents a date, each column represents a ticker, and the cell values correspond to closing prices\n",
    "us_wide_50 = (\n",
    "    us_mkt\n",
    "    .pivot(index=\"date\", columns=\"ticker\", values=\"close\")\n",
    "    .sort_index()\n",
    "    .head(50)\n",
    ")\n",
    "\n",
    "us_wide_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
