{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment\n",
    "\n",
    "It is totally prohibited to use any kind of loop. You can use stackoverflow. If you copy codes from previous answers, explain each step. No explanation is `0 points`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Tuple\n",
    "\n",
    "\n",
    "\n",
    "1. Print the first item of the second item of `tuple1` object. **Hint: Use indexing**<br><br>\n",
    "2. Print the last item of the `tuple1` object.**Hint: Use indexing**<br><br>\n",
    "3. Change the value \"orange\" for \"pink grapefruit\". Comment the output. **Hint: Is it possible?** <br><br>\n",
    "4. Print the length of `tuple1`. **Hint: Length function**<br><br>\n",
    "5. Sum all the elements of tuple2 and describe your steps and explain each of them. **Hint: Use `map` function.**<br><br>\n",
    "6. Generate a new tuple object named as `tuple3` with the half values of `tuple2`. This tuple should be similar as `tuple2`, tuple of lists.  **Hint: Use `map` funciont.**<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple1 = (\"Orange\", [10, 20, 30], (5, 15, 25))\n",
    "tuple2 = ([7, 8], [9, 1], [10, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "print(tuple1[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "print(tuple1[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "try:\n",
    "    tuple1[0]= \"pink grapefruit\"\n",
    "\n",
    "except TypeError:\n",
    "    print(\"No es posible hacer esta operación porque es una tuple y no es mutable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "print(len(tuple1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "print(sum(map(sum, tuple2)))\n",
    "\n",
    "Explicación = '''Usamos la función \"map\" para que la función \"sum\" agarre las listas separadas dentro del tuple 2 y genera la suma de cada una de las listas. \n",
    "Por último, nuevamente usamos la función \"sum\" para sumar cada uno de los resultados individualmente para obtener el resultado.'''\n",
    "print(Explicación)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "tuple3 = tuple(map(lambda x: list(map(lambda y: y/2, x)), tuple2))\n",
    "print(tuple3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Lists\n",
    "1. Show the indices of the `np.nan` values  in the `f_list` list. We want to see this output: `The indices 0, 1, 4, 7 have np.nan values.` **Hint: Use print function and [f-strings](https://realpython.com/python-f-strings/) to insert the indices values.**<br><br>\n",
    "\n",
    "2. Replicate 4 times the values of the list `p2_list`. We expect an ouput like this: `[ 2 , 3, 4, 5, 2 , 3, 4, 5, 2 , 3, 4, 5, 2 , 3, 4, 5]`.  **Hint: Use multiplication function in `lists`and see the output.**<br><br>\n",
    "3. Print the length of `f_list`. **Hint: Length function**<br><br>\n",
    "4. Print `My teacher assistant is so boring.` using `text1` list. **Hint: Use the [`join` function](https://stackoverflow.com/questions/493819/why-is-it-string-joinlist-instead-of-list-joinstring)**<br><br>\n",
    "5. Print `My TA is so boring, but is very funny.` using `text1` list.**Hint: Use the `join` function, and `extend` method.**<br><br>\n",
    "6. Print <br>\n",
    "`The max value of values1 is 86 and is located in the 0 index. ` <br>\n",
    "`The min value of values1 is 0 and is located in the 7 index. ` <br> **Hint: Use the `f-string`, `min`, and `max` functions.**\n",
    "<br>\n",
    "7. Get two lists: `names` and `last_names` using `last_and_name` list. **Hint: Use `map` and `split`.**\n",
    "<br>\n",
    "8. Give only the last names of students who do not have email. Use the `emails` and `last_names` listt. **Hint: Use `map` and `split`.**\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_list = [np.nan , np.nan, \"Austria\", \"Germany\", np.nan, \"Pakistan\", \"np.nan\", np.nan ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = ['My', 'teacher', 'assistant', 'is', 'so', 'boring.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2_list = [ 2 , 3, 4, 5 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "values1 = [ 86, 86, 85, 85, 85, 83, 23, 0, 84, 1 ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These two lists a\n",
    "last_and_name = [ \"CORNEJO SANCHEZ, CHRISTIAN SANTOS\", \"ORELLANA QUISPE, CRISTIAN NASSER\", \"MORALES CHOQUEHUANCA, ANGELICA KARINA\", \"GUIMARAY RIBEYRO, JOSE ROBERTO\", \"CAMACHO GAVIDIA, ABEL FERNANDO\", \"TINTAYA ORIHUELA, MEIR ALVARO\", \"CHAVEZ MARTINEZ, JOSELIN ALEXANDRA\", \"FIGUEROA MURO, LEONEL ARTURO\", \"GOMEZ CRIBILLERO, JOSE FELIPE\", \"PALOMINO SEGUÍN, AFRANIA\", \"LUZON CUEVA, BIANCA MARIETTE\", \"SUAÑA ZEGARRA, ADRIAN ANDRE\", \"SOTO POMACHAGUA, DORKAS YOMIRA JHERMY\", \"FIORENTINO MARTINEZ, LADY ALY\", \"LAMA MAVILA, HECTOR ANDRE\", \"MEZA HINOJO, GUSTAVO\", \"LOZADA MURILLO, PERSEO MARCELO\", \"ZAMBRANO JIMENEZ, MIGUEL ALONZO\", \"JACOBS LUQUE, NICOLAS\", \"VIDAL VIDAL, ROCIO GABRIELA\", \"TORRES ANICAMA, JANE CAMILA\", \"LOPEZ ESTRADA, MARIA ELISA\", \"BOYCO ORAMS, ALEJANDRO\", \"DIAZ BERROSPI, KARLINE ROSMELI\", \"RIEGA ESCALANTE, STEPHY ROSARIO\", \"LEVANO TORRES, VALERIA CECILIA\", \"ESQUIVES BRAVO, SEBASTIAN RENATO\", \"PEREZ GONZALES, JUAN CARLOS\", \"OTERO MAGUIÑA, MARIANA\", \"CLAVO CAMPOS, ANDREA BRIZETH\", \"AGUILAR GARCIA, ERICK JOSUE\", \"CALDAS VELASQUEZ, JOSUE DANIEL\", \"SALAS NUÑEZ BORJA, FABIO MANUEL\", \"PIZARRO VILLANES, FERNANDA NICOLLE\", \"QUILLATUPA MORALES, ANGELA ADELINA\", \"HUANCAYA IDONE, CESAR DANTE\", \"CALVO PORTOCARRERO, GABRIELA ISABEL\", \"IBAÑEZ ABANTO, ANGEL MAURICIO\", \"MELÉNDEZ APONTE, JUAN DIEGO\", \"CRISTIAN SERRANO, ARONE\", \"HINOJOSA CAHUANA, PERCY ALBERTH\", \"ANGLAS GARCÍA, KEVIN ARTURO\", \"ALDAVE ACOSTA, CESAR ERNESTO\", \"NÚÑEZ HUAMÁN, CÉSAR AGUSTO\", \"OBREGON HUAMAN, DIANA EDITH\", \"SOTO PACHERRES, RODRIGO FRANCO\", \"INGARUCA RIVERA, GRETTEL ALEXANDRA\", \"ROJAS HUAMAN, ROSA ANGELA\", \"NEYRA SALAS, DANTE OMAR\", \"HUERTA ESPINOZA, YAJAIRA ALEXANDRA\", \"HUANCA MARTINEZ, JORGE ALBERTO\", \"FLORES CADILLO, ALEXIS\" ]\n",
    "emails = [\"cscornejo@pucp.edu.pe\", \"orellana.cn@pucp.edu.pe\", \"karina.morales@pucp.edu.pe\", \"a20083223@pucp.pe\", \"abel.camacho@pucp.pe\", \"mtintaya@pucp.edu.pe\", \"joselin.chavez@pucp.edu.pe\", \"a20105737@pucp.pe\", \"jfgomezc@pucp.pe\", \"afrania.palomino@pucp.pe\", \"luzon.bianca@pucp.pe\", \"adrian.suanaz@pucp.pe\", \"soto.y@pucp.edu.pe\", \"a20132766@pucp.pe\", \"andre.lama@pucp.edu.pe\", \"gustavo.meza@pucp.edu.pe\", \"pmlozada@pucp.edu.pe\", \"m.zambranoj@pucp.edu.pe\", \"nicolas.jacobs@pucp.edu.pe\", \"gvidal@pucp.edu.pe\", \"jane.torres@pucp.edu.pe\", \"m.lopez@pucp.edu.pe\", \"alejandro.boyco@pucp.edu.pe\", \"a20167070@pucp.edu.pe\", \"riega.stephy@pucp.edu.pe\", \"vlevanot@pucp.edu.pe\", \"sesquives@pucp.edu.pe\", \"perez.juanc@pucp.edu.pe\", \"mariana.otero@pucp.edu.pe\", \"aclavo@pucp.edu.pe\", \"a20182474@pucp.edu.pe\", \"josue.caldas@pucp.edu.pe\", \"fabio.salas@pucp.edu.pe\", \"fernanda.pizarro@pucp.edu.pe\", \"aquillatupa@pucp.pe\", \"\", \"\", \"\", \"\", \"\", \"f0873079@pucp.edu.pe\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"flores.alexis@pucp.edu.pe\", ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EL PRIMER PASO IMPORTANTE ES DEFINIR LAS VARIABLE E IMPORTAR NUMPY. Asimismo, luego corre en python las variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The indices 0, 1, 4, 7 have np.nan values.\n"
     ]
    }
   ],
   "source": [
    "#Punto 1: Mostrar los índices de los valores (SIN BUCLE)\n",
    "import numpy as np\n",
    "\n",
    "indices_nan = list(\n",
    "    map(\n",
    "        lambda x: x[0],\n",
    "        filter(lambda x: isinstance(x[1], float) and np.isnan(x[1]), enumerate(f_list))\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"The indices {', '.join(map(str, indices_nan))} have np.nan values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "#Punto 2: Replicar 4 veces los valores de la lista \"p2_list\". CUIDADO CON EL RESULTADO porque tiene que ser 4 veces el mismo patrón\n",
    "result = p2_list * 4 #4 veces\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "#Punto 3: Imprime la longitud de \"f_list\"; OBSERVACIÓN: USA FUNCIÓN de \"length\"\n",
    "print(len(f_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My teacher assistant is so boring.\n"
     ]
    }
   ],
   "source": [
    "#Punto 4: Imprimir (Print): \"My teacher assistant is so boring\"; OBSERVACIÓN: USA FUNCIÓN de \"join\"\n",
    "print(\" \".join(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My TA is so boring, but is very funny.\n"
     ]
    }
   ],
   "source": [
    "#Punto 5: Armar otra oración agregando TA (Teacher assistant) y \",but is very funny\"\n",
    "\n",
    "text1_extended = \" \".join(text1)\n",
    "text1_extended = text1_extended.replace(\"teacher assistant\", \"TA\")\n",
    "text1_extended = text1_extended.replace(\"boring.\", \"boring,\")\n",
    "text1_extended = text1_extended.split()\n",
    "text1_extended.extend([\"but\", \"is\", \"very\", \"funny.\"])\n",
    "\n",
    "\n",
    "sentence = \" \".join(text1_extended)\n",
    "\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max value of values1 is 86 and is located in the 0 index.\n",
      "The min value of values1 is 0 and is located in the 7 index.\n"
     ]
    }
   ],
   "source": [
    "#Punto 6: Máximo y mínimo\n",
    "max_value = max(values1)\n",
    "min_value = min(values1)\n",
    "\n",
    "print(f\"The max value of values1 is {max_value} and is located in the {values1.index(max_value)} index.\")\n",
    "print(f\"The min value of values1 is {min_value} and is located in the {values1.index(min_value)} index.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Punto 7: Obtener dos listas\n",
    "names = list(map(lambda x: x.split()[0], last_and_name))\n",
    "last_names = list(map(lambda x: x.split()[1], last_and_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names list:\n",
      "['CHRISTIAN SANTOS', 'CRISTIAN NASSER', 'ANGELICA KARINA', 'JOSE ROBERTO', 'ABEL FERNANDO', 'MEIR ALVARO', 'JOSELIN ALEXANDRA', 'LEONEL ARTURO', 'JOSE FELIPE', 'AFRANIA', 'BIANCA MARIETTE', 'ADRIAN ANDRE', 'DORKAS YOMIRA JHERMY', 'LADY ALY', 'HECTOR ANDRE', 'GUSTAVO', 'PERSEO MARCELO', 'MIGUEL ALONZO', 'NICOLAS', 'ROCIO GABRIELA', 'JANE CAMILA', 'MARIA ELISA', 'ALEJANDRO', 'KARLINE ROSMELI', 'STEPHY ROSARIO', 'VALERIA CECILIA', 'SEBASTIAN RENATO', 'JUAN CARLOS', 'MARIANA', 'ANDREA BRIZETH', 'ERICK JOSUE', 'JOSUE DANIEL', 'FABIO MANUEL', 'FERNANDA NICOLLE', 'ANGELA ADELINA', 'CESAR DANTE', 'GABRIELA ISABEL', 'ANGEL MAURICIO', 'JUAN DIEGO', 'ARONE', 'PERCY ALBERTH', 'KEVIN ARTURO', 'CESAR ERNESTO', 'CÉSAR AGUSTO', 'DIANA EDITH', 'RODRIGO FRANCO', 'GRETTEL ALEXANDRA', 'ROSA ANGELA', 'DANTE OMAR', 'YAJAIRA ALEXANDRA', 'JORGE ALBERTO', 'ALEXIS']\n",
      "\n",
      "Last names list:\n",
      "['CORNEJO SANCHEZ', 'ORELLANA QUISPE', 'MORALES CHOQUEHUANCA', 'GUIMARAY RIBEYRO', 'CAMACHO GAVIDIA', 'TINTAYA ORIHUELA', 'CHAVEZ MARTINEZ', 'FIGUEROA MURO', 'GOMEZ CRIBILLERO', 'PALOMINO SEGUÍN', 'LUZON CUEVA', 'SUAÑA ZEGARRA', 'SOTO POMACHAGUA', 'FIORENTINO MARTINEZ', 'LAMA MAVILA', 'MEZA HINOJO', 'LOZADA MURILLO', 'ZAMBRANO JIMENEZ', 'JACOBS LUQUE', 'VIDAL VIDAL', 'TORRES ANICAMA', 'LOPEZ ESTRADA', 'BOYCO ORAMS', 'DIAZ BERROSPI', 'RIEGA ESCALANTE', 'LEVANO TORRES', 'ESQUIVES BRAVO', 'PEREZ GONZALES', 'OTERO MAGUIÑA', 'CLAVO CAMPOS', 'AGUILAR GARCIA', 'CALDAS VELASQUEZ', 'SALAS NUÑEZ BORJA', 'PIZARRO VILLANES', 'QUILLATUPA MORALES', 'HUANCAYA IDONE', 'CALVO PORTOCARRERO', 'IBAÑEZ ABANTO', 'MELÉNDEZ APONTE', 'CRISTIAN SERRANO', 'HINOJOSA CAHUANA', 'ANGLAS GARCÍA', 'ALDAVE ACOSTA', 'NÚÑEZ HUAMÁN', 'OBREGON HUAMAN', 'SOTO PACHERRES', 'INGARUCA RIVERA', 'ROJAS HUAMAN', 'NEYRA SALAS', 'HUERTA ESPINOZA', 'HUANCA MARTINEZ', 'FLORES CADILLO']\n"
     ]
    }
   ],
   "source": [
    "#corroborar las listas\n",
    "splitted = list(map(lambda x: x.split(\", \"), last_and_name))\n",
    "\n",
    "last_names = list(map(lambda x: x[0], splitted))\n",
    "names = list(map(lambda x: x[1], splitted))\n",
    "\n",
    "print(\"Names list:\")\n",
    "print(names)\n",
    "\n",
    "print(\"\\nLast names list:\")\n",
    "print(last_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HUANCAYA IDONE', 'CALVO PORTOCARRERO', 'IBAÑEZ ABANTO', 'MELÉNDEZ APONTE', 'CRISTIAN SERRANO', 'ANGLAS GARCÍA', 'ALDAVE ACOSTA', 'NÚÑEZ HUAMÁN', 'OBREGON HUAMAN', 'SOTO PACHERRES', 'INGARUCA RIVERA', 'ROJAS HUAMAN', 'NEYRA SALAS', 'HUERTA ESPINOZA', 'HUANCA MARTINEZ']\n"
     ]
    }
   ],
   "source": [
    "#Punto 8: Apellidos que no poseen correo electrónico\n",
    "students_without_email = list(\n",
    "    map(\n",
    "        lambda x: x[0],\n",
    "        filter(lambda x: x[1] == \"\", zip(last_names, emails))\n",
    "    )\n",
    ")\n",
    "\n",
    "print(students_without_email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Strings\n",
    "\n",
    "\n",
    "1. Drop the duplicated blank spaces in `str1`. Do not use the regular expresions. Do not use the code shown in class. Explain your steps.**Hint: Use `split` method and `join` function.**\n",
    "\n",
    "2. Get the number of letters in the string .**Hint: Use `len`function.**\n",
    "\n",
    "3. Get the number of blank spaces (all of them) in the string .**Hint: Use `len`function.**\n",
    "\n",
    "4. Get the position of `@` in each string in the emails list. **Hint: Use `map`function and `find` method.**\n",
    "\n",
    "5. Identifies if exists `.edu.`  in each string in the `emails` list. Get a list of Booleans. **Hint: Use `map`function and `find` method.**\n",
    "\n",
    "6. Get all the strings before the first dot `.`in each string in the `emails` list. Identifies how many of them has `@`. **Hint: Use `map`function and `find` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = 'I am                            too                                                        old'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Separo y elimino los missings\n",
    "str2 = str1.split()     # Separo los elementos no nulos\n",
    "str2 = ' '.join(str2)   # Los uno mediante un espacio simple\n",
    "print(str2)\n",
    "\n",
    "# 2. Consigo la cantidad de palabras en el string\n",
    "print(len(str2))\n",
    "\n",
    "# 3. Consigo la cantidad de caracteres vacíos\n",
    "blank = len(str1) - len(str2.split())  # Resto la cantidad de elementos con los que no son vacios\n",
    "print(blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = [\"cscornejo@pucp.edu.pe\", \"orellana.cn@pucp.edu.pe\", \"karina.morales@pucp.edu.pe\", \"a20083223@pucp.pe\", \"abel.camacho@pucp.pe\", \"mtintaya@pucp.edu.pe\", \"joselin.chavez@pucp.edu.pe\", \"a20105737@pucp.pe\", \"jfgomezc@pucp.pe\", \"afrania.palomino@pucp.pe\", \"luzon.bianca@pucp.pe\", \"adrian.suanaz@pucp.pe\", \"soto.y@pucp.edu.pe\", \"a20132766@pucp.pe\", \"andre.lama@pucp.edu.pe\", \"gustavo.meza@pucp.edu.pe\", \"pmlozada@pucp.edu.pe\", \"m.zambranoj@pucp.edu.pe\", \"nicolas.jacobs@pucp.edu.pe\", \"gvidal@pucp.edu.pe\", \"jane.torres@pucp.edu.pe\", \"m.lopez@pucp.edu.pe\", \"alejandro.boyco@pucp.edu.pe\", \"a20167070@pucp.edu.pe\", \"riega.stephy@pucp.edu.pe\", \"vlevanot@pucp.edu.pe\", \"sesquives@pucp.edu.pe\", \"perez.juanc@pucp.edu.pe\", \"mariana.otero@pucp.edu.pe\", \"aclavo@pucp.edu.pe\", \"a20182474@pucp.edu.pe\", \"josue.caldas@pucp.edu.pe\", \"fabio.salas@pucp.edu.pe\", \"fernanda.pizarro@pucp.edu.pe\", \"aquillatupa@pucp.pe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Posición de @ en cada email\n",
    "finder    = lambda s: s.find('@')       # Creo buscador\n",
    "positions = list(map(finder, emails))   # Busco las posicioens\n",
    "print(positions)                        # Imprimo las posiciones\n",
    "\n",
    "# 5. Existe '.edu.'?\n",
    "finder = lambda s: s.find('.edu.')      # Creo buscador\n",
    "exists = list(map(finder, emails))      # Existe o no? Si no, genera -1\n",
    "# exists = [i != -1 for i in exists]      # Genero booleado a partir de -1, aunque no se puede loops\n",
    "exists = list(map(lambda i: i != -1, exists))  # Genero booleano a partir de -1\n",
    "print(exists)\n",
    "\n",
    "# 6. Conseguir todos los caracteres previos al PRIMER punto de la lista\n",
    "emails2 = [i.split('.')[0] for i in emails]   # Consigo cada elemento de la lista previo a sus primeros puntos\n",
    "finder  = lambda s: s.find('@')               # Creo buscador\n",
    "arroba  = list(map(finder, emails2))          # Arroba o no? Si no, genera -1\n",
    "# arroba  = [i != -1 for i in arroba]           # Genero booleano a partir de -1, aunque no se puede loops\n",
    "arroba = list(map(lambda i: i != -1, arroba))   # Genero booleano a partir de -1\n",
    "print(arroba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "START = \"2022-01-01\"\n",
    "END = \"2025-12-18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        date ticker      close    volume\n",
       " 0 2022-01-03    EEM  44.624966  27572700\n",
       " 1 2022-01-04    EEM  44.470772  24579500\n",
       " 2 2022-01-05    EEM  43.745171  46425100\n",
       " 3 2022-01-06    EEM  43.944706  34288700\n",
       " 4 2022-01-07    EEM  44.343792  32640900,\n",
       " (4970, 4))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Yahoo Finance via yfinance: US tickers (real market yh_df) ---\n",
    "tickers = [\"SPY\", \"QQQ\", \"TLT\", \"GLD\", \"EEM\"]\n",
    "# SPY : S&P 500 index\n",
    "# QQQ : Nasdaq-100 index\n",
    "# TLT : U.S. Treasury bonds with 20+ year maturity\n",
    "# GLD : Physical gold prices\n",
    "# EEM : MSCI Emerging Markets index\n",
    "\n",
    "try:\n",
    "    import yfinance as yf\n",
    "except Exception as e:\n",
    "    yf = None\n",
    "    print(\"Could not import yfinance:\", type(e).__name__, str(e))\n",
    "\n",
    "if yf is not None:\n",
    "    try:\n",
    "        yh_df = yf.download(tickers, start=START, end=END, auto_adjust=True, progress=False)\n",
    "    except Exception as e:\n",
    "        yh_df = pd.DataFrame()\n",
    "        print(\"yfinance download failed:\", type(e).__name__, str(e))\n",
    "else:\n",
    "    yh_df = pd.DataFrame()\n",
    "\n",
    "# Convert to long format: date, ticker, close, volume\n",
    "if isinstance(yh_df, pd.DataFrame) and yh_df.shape[0] > 0:\n",
    "    if isinstance(yh_df.columns, pd.MultiIndex):\n",
    "        close = yh_df[\"Close\"].copy()\n",
    "        vol = yh_df[\"Volume\"].copy()\n",
    "    else:\n",
    "        close = yh_df[[\"Close\"]].rename(columns={\"Close\": tickers[0]})\n",
    "        vol = yh_df[[\"Volume\"]].rename(columns={\"Volume\": tickers[0]})\n",
    "\n",
    "    close.index.name = \"date\"\n",
    "    vol.index.name = \"date\"\n",
    "\n",
    "    us_close_long = close.reset_index().melt(id_vars=\"date\", var_name=\"ticker\", value_name=\"close\")\n",
    "    us_vol_long = vol.reset_index().melt(id_vars=\"date\", var_name=\"ticker\", value_name=\"volume\")\n",
    "    us_mkt = us_close_long.merge(us_vol_long, on=[\"date\",\"ticker\"], how=\"inner\").dropna(subset=[\"close\"])\n",
    "else:\n",
    "    us_mkt = pd.DataFrame(columns=[\"date\",\"ticker\",\"close\",\"volume\"])\n",
    "\n",
    "us_mkt.head(), us_mkt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- BCRP: daily exchange rate PEN/USD buy & sell (official API) ---\n",
    "# Codes:\n",
    "# - PD04637PD: USD/PEN (buy)\n",
    "# - PD04638PD: USD/PEN (sell)\n",
    "\n",
    "import requests\n",
    "\n",
    "bcrp_url = f\"https://estadisticas.bcrp.gob.pe/estadisticas/series/api/PD04637PD-PD04638PD/json/{START}/{END}/esp\"\n",
    "try:\n",
    "    r = requests.get(bcrp_url, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    bcrp_obj = r.json()\n",
    "except Exception as e:\n",
    "    bcrp_obj = {\"periods\": []}\n",
    "    print(\"BCRP request failed:\", type(e).__name__, str(e))\n",
    "\n",
    "periods = bcrp_obj.get(\"periods\", [])\n",
    "rows = []\n",
    "for p in periods:\n",
    "    name = p.get(\"name\")\n",
    "    vals = p.get(\"values\", [])\n",
    "    if isinstance(vals, str):\n",
    "        vals = [vals]\n",
    "    if name is None or not isinstance(vals, list) or len(vals) < 2:\n",
    "        continue\n",
    "    rows.append([name, vals[0], vals[1]])\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"date_raw\", \"PENUSD_buy\", \"PENUSD_sell\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 From NumPy array to Series \n",
    "\n",
    "Using `us_mkt`:\n",
    "\n",
    "1. Filter to `ticker == \"SPY\"`.\n",
    "2. Take `close` as a NumPy array.\n",
    "3. Create a Series indexed by `date` named `SPY_close_series`.\n",
    "4. Compute the mean/min/max with Series methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'us_mkt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m us_mkt_spy  \u001b[38;5;241m=\u001b[39m us_mkt[us_mkt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSPY\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      2\u001b[0m us_mkt_spy2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(us_mkt_spy[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m dates_spy2  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(us_mkt_spy[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'us_mkt' is not defined"
     ]
    }
   ],
   "source": [
    "us_mkt_spy  = us_mkt[us_mkt['ticker']=='SPY']\n",
    "us_mkt_spy2 = np.array(us_mkt_spy['close'])\n",
    "dates_spy2  = list(us_mkt_spy['date'])\n",
    "\n",
    "SPY_close_series = pd.Series(data=us_mkt_spy2, index=dates_spy2, name='SPY')\n",
    "\n",
    "print(\"Media:\", SPY_close_series.mean())\n",
    "print(\"Mínimo:\", SPY_close_series.min())\n",
    "print(\"Máximo:\", SPY_close_series.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 From Dictionary to Series \n",
    "\n",
    "Using `us_mkt`:\n",
    "\n",
    "1. Compute the **last available close** for each ticker in `tickers`.\n",
    "2. Store it in a dict `{ticker: last_close}`.\n",
    "3. Convert to a Series and sort descending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_close_by_ticker = (us_mkt.sort_values([\"ticker\", \"date\"]).groupby(\"ticker\")[\"close\"].last())\n",
    "last_close_dict = last_close_by_ticker.to_dict()\n",
    "last_close_series = pd.Series(last_close_dict).sort_values(ascending=False)\n",
    "print(last_close_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 Series vs NumPy \n",
    "\n",
    "Goal: show why pandas alignment matters.\n",
    "\n",
    "1. Create two Series indexed by date:\n",
    "   - df mid-rate from `df`\n",
    "   - SPY close from `us_mkt`\n",
    "2. Combine them into a yh_dfFrame (pandas aligns on dates).\n",
    "3. Separately, build two NumPy arrays by truncating to the same length.\n",
    "4. In markdown: explain why alignment is safer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar DataFrame del BCRP\n",
    "meses_bcrp = {\n",
    "    'Ene': 'Jan', 'Feb': 'Feb', 'Mar': 'Mar', 'Abr': 'Apr', \n",
    "    'May': 'May', 'Jun': 'Jun', 'Jul': 'Jul', 'Ago': 'Aug', \n",
    "    'Set': 'Sep', 'Oct': 'Oct', 'Nov': 'Nov', 'Dic': 'Dec'\n",
    "}\n",
    "\n",
    "# 2. Limpieza de la columna date_raw\n",
    "df['date_cleaned'] = df['date_raw'].copy()\n",
    "for esp, eng in meses_bcrp.items():\n",
    "    df['date_cleaned'] = df['date_cleaned'].str.replace(esp, eng, regex=False)\n",
    "df['date'] = pd.to_datetime(df['date_cleaned'], format='%d.%b.%y')\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# 3. Continuamos con el cálculo del mid-rate y alineación\n",
    "df['mid_rate'] = (df['PENUSD_buy'].astype(float) + df['PENUSD_sell'].astype(float)) / 2\n",
    "ser_bcrp = df['mid_rate']\n",
    "\n",
    "# Extraer SPY y alinear (Asegúrate que us_mkt['date'] sea datetime)\n",
    "spy_data = us_mkt[us_mkt['ticker'] == 'SPY'].copy()\n",
    "spy_data['date'] = pd.to_datetime(spy_data['date'])\n",
    "spy_data.set_index('date', inplace=True)\n",
    "ser_spy = spy_data['close']\n",
    "\n",
    "# Alineación automática de Pandas\n",
    "combined_df = pd.DataFrame({'PENUSD_Mid': ser_bcrp,'SPY_Close': ser_spy})\n",
    "\n",
    "print(\"Alineación corregida:\")\n",
    "print(combined_df.dropna().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.6 Dealing with Nulls \n",
    "Using `us_mkt`:\n",
    "\n",
    "1. Copy `us_mkt` to `us_mkt_nan`.\n",
    "2. Set 1% of `close` to NaN (fixed random seed).\n",
    "3. Create:\n",
    "   - `us_drop`: drop NaNs\n",
    "   - `us_fill`: fill NaNs with ticker-specific median close\n",
    "4. Compare shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.7 Duplicates \n",
    "\n",
    "1. Create `dup_df` by stacking the last 5 rows of `us_mkt` twice.\n",
    "2. Detect duplicates using `.duplicated()`.\n",
    "3. Remove them using `.drop_duplicates()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.8 Groupby \n",
    "\n",
    "\n",
    "Using `us_mkt`:\n",
    "\n",
    "1. Group by `ticker` and compute:\n",
    "   - mean close\n",
    "   - median close\n",
    "   - max volume\n",
    "2. Rename columns clearly.\n",
    "3. Sort by mean close descending."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.9 Reshape \n",
    "\n",
    "1. Create a 1-row wide yh_dfFrame with last closes per ticker.\n",
    "2. Convert it to long format with `melt()` into columns: `ticker`, `last_close`.\n",
    "3. Pivot `us_mkt` into a wide table: index=`date`, columns=`ticker`, values=`close` (keep first 50 dates)."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
