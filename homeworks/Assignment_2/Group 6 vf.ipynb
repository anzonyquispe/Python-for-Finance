{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment\n",
    "\n",
    "It is totally prohibited to use any kind of loop. You can use stackoverflow. If you copy codes from previous answers, explain each step. No explanation is `0 points`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Tuple\n",
    "\n",
    "\n",
    "\n",
    "1. Print the first item of the second item of `tuple1` object. **Hint: Use indexing**<br><br>\n",
    "2. Print the last item of the `tuple1` object.**Hint: Use indexing**<br><br>\n",
    "3. Change the value \"orange\" for \"pink grapefruit\". Comment the output. **Hint: Is it possible?** <br><br>\n",
    "4. Print the length of `tuple1`. **Hint: Length function**<br><br>\n",
    "5. Sum all the elements of tuple2 and describe your steps and explain each of them. **Hint: Use `map` function.**<br><br>\n",
    "6. Generate a new tuple object named as `tuple3` with the half values of `tuple2`. This tuple should be similar as `tuple2`, tuple of lists.  **Hint: Use `map` funciont.**<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple1 = (\"Orange\", [10, 20, 30], (5, 15, 25))\n",
    "tuple2 = ([7, 8], [9, 1], [10, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "#1. Print the first item of the second item of tuple1 object.\n",
    "#We recall that [1] represents the second element of the tuple (list 2).\n",
    "#Likewise, [0] refers to the first element of the required list, since indices start from zero.\n",
    "\n",
    "print(tuple1[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 15, 25)\n"
     ]
    }
   ],
   "source": [
    "#2. Print the last item of the tuple1 object.\n",
    "#Since tuple1 is a tuple containing three items (which are lists), requesting the last item returns the last list in the tuple.\n",
    "\n",
    "print(tuple1[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Change the value \"orange\" for \"pink grapefruit\". Comment the output. Hint: Is it possible?\n",
    "#It is NOT possible to modify tuples in Python directly. As mentioned in class, since they use less memory, they lose the ability to be modified.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "#4. Print the length of tuple1\n",
    "#We use the len() function to obtain the number of elements in the tuple.\n",
    "\n",
    "print(len(tuple1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 10, 17]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5. Sum all the elements of tuple2 and describe your steps and explain each of them.\n",
    "#1° tuple2 contains 3 lists of numbers.\n",
    "#2° We use the sum() function to add the numerical values in each list.\n",
    "#3° With map(), we ensure that the sum is applied to each element (list) in tuple2.\n",
    "#4° Finally, we use list() to convert them into a list for later use.\n",
    "\n",
    "list(map(sum, tuple2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([3.5, 4.0], [4.5, 0.5], [5.0, 3.5])\n"
     ]
    }
   ],
   "source": [
    "#6. Generate a new tuple object named as tuple3 with the half values of tuple2. This tuple should be similar as tuple2, tuple of lists.\n",
    "#1° [i / 2 for i in s] helps us take each element of the list and divide it by 2.\n",
    "#2° The lambda function (lambda s:) is used so that map can operate and be applied to each element.\n",
    "#3° As mentioned in the previous exercise, map determines how the division request is applied to the elements.\n",
    "#4° Finally, we use the tuple() function to create the required tuple.\n",
    "\n",
    "tuple3 = tuple(map(lambda s: [i / 2 for i in s], tuple2))\n",
    "print(tuple3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Lists\n",
    "1. Show the indices of the `np.nan` values  in the `f_list` list. We want to see this output: `The indices 0, 1, 4, 7 have np.nan values.` **Hint: Use print function and [f-strings](https://realpython.com/python-f-strings/) to insert the indices values.**<br><br>\n",
    "\n",
    "2. Replicate 4 times the values of the list `p2_list`. We expect an ouput like this: `[ 2 , 3, 4, 5, 2 , 3, 4, 5, 2 , 3, 4, 5, 2 , 3, 4, 5]`.  **Hint: Use multiplication function in `lists`and see the output.**<br><br>\n",
    "3. Print the length of `f_list`. **Hint: Length function**<br><br>\n",
    "4. Print `My teacher assistant is so boring.` using `text1` list. **Hint: Use the [`join` function](https://stackoverflow.com/questions/493819/why-is-it-string-joinlist-instead-of-list-joinstring)**<br><br>\n",
    "5. Print `My TA is so boring, but is very funny.` using `text1` list.**Hint: Use the `join` function, and `extend` method.**<br><br>\n",
    "6. Print <br>\n",
    "`The max value of values1 is 86 and is located in the 0 index. ` <br>\n",
    "`The min value of values1 is 0 and is located in the 7 index. ` <br> **Hint: Use the `f-string`, `min`, and `max` functions.**\n",
    "<br>\n",
    "7. Get two lists: `names` and `last_names` using `last_and_name` list. **Hint: Use `map` and `split`.**\n",
    "<br>\n",
    "8. Give only the last names of students who do not have email. Use the `emails` and `last_names` listt. **Hint: Use `map` and `split`.**\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_list = [np.nan , np.nan, \"Austria\", \"Germany\", np.nan, \"Pakistan\", \"np.nan\", np.nan ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = ['My', 'teacher', 'assistant', 'is', 'so', 'boring.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2_list = [ 2 , 3, 4, 5 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "values1 = [ 86, 86, 85, 85, 85, 83, 23, 0, 84, 1 ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These two lists a\n",
    "last_and_name = [ \"CORNEJO SANCHEZ, CHRISTIAN SANTOS\", \"ORELLANA QUISPE, CRISTIAN NASSER\", \"MORALES CHOQUEHUANCA, ANGELICA KARINA\", \"GUIMARAY RIBEYRO, JOSE ROBERTO\", \"CAMACHO GAVIDIA, ABEL FERNANDO\", \"TINTAYA ORIHUELA, MEIR ALVARO\", \"CHAVEZ MARTINEZ, JOSELIN ALEXANDRA\", \"FIGUEROA MURO, LEONEL ARTURO\", \"GOMEZ CRIBILLERO, JOSE FELIPE\", \"PALOMINO SEGUÍN, AFRANIA\", \"LUZON CUEVA, BIANCA MARIETTE\", \"SUAÑA ZEGARRA, ADRIAN ANDRE\", \"SOTO POMACHAGUA, DORKAS YOMIRA JHERMY\", \"FIORENTINO MARTINEZ, LADY ALY\", \"LAMA MAVILA, HECTOR ANDRE\", \"MEZA HINOJO, GUSTAVO\", \"LOZADA MURILLO, PERSEO MARCELO\", \"ZAMBRANO JIMENEZ, MIGUEL ALONZO\", \"JACOBS LUQUE, NICOLAS\", \"VIDAL VIDAL, ROCIO GABRIELA\", \"TORRES ANICAMA, JANE CAMILA\", \"LOPEZ ESTRADA, MARIA ELISA\", \"BOYCO ORAMS, ALEJANDRO\", \"DIAZ BERROSPI, KARLINE ROSMELI\", \"RIEGA ESCALANTE, STEPHY ROSARIO\", \"LEVANO TORRES, VALERIA CECILIA\", \"ESQUIVES BRAVO, SEBASTIAN RENATO\", \"PEREZ GONZALES, JUAN CARLOS\", \"OTERO MAGUIÑA, MARIANA\", \"CLAVO CAMPOS, ANDREA BRIZETH\", \"AGUILAR GARCIA, ERICK JOSUE\", \"CALDAS VELASQUEZ, JOSUE DANIEL\", \"SALAS NUÑEZ BORJA, FABIO MANUEL\", \"PIZARRO VILLANES, FERNANDA NICOLLE\", \"QUILLATUPA MORALES, ANGELA ADELINA\", \"HUANCAYA IDONE, CESAR DANTE\", \"CALVO PORTOCARRERO, GABRIELA ISABEL\", \"IBAÑEZ ABANTO, ANGEL MAURICIO\", \"MELÉNDEZ APONTE, JUAN DIEGO\", \"CRISTIAN SERRANO, ARONE\", \"HINOJOSA CAHUANA, PERCY ALBERTH\", \"ANGLAS GARCÍA, KEVIN ARTURO\", \"ALDAVE ACOSTA, CESAR ERNESTO\", \"NÚÑEZ HUAMÁN, CÉSAR AGUSTO\", \"OBREGON HUAMAN, DIANA EDITH\", \"SOTO PACHERRES, RODRIGO FRANCO\", \"INGARUCA RIVERA, GRETTEL ALEXANDRA\", \"ROJAS HUAMAN, ROSA ANGELA\", \"NEYRA SALAS, DANTE OMAR\", \"HUERTA ESPINOZA, YAJAIRA ALEXANDRA\", \"HUANCA MARTINEZ, JORGE ALBERTO\", \"FLORES CADILLO, ALEXIS\" ]\n",
    "emails = [\"cscornejo@pucp.edu.pe\", \"orellana.cn@pucp.edu.pe\", \"karina.morales@pucp.edu.pe\", \"a20083223@pucp.pe\", \"abel.camacho@pucp.pe\", \"mtintaya@pucp.edu.pe\", \"joselin.chavez@pucp.edu.pe\", \"a20105737@pucp.pe\", \"jfgomezc@pucp.pe\", \"afrania.palomino@pucp.pe\", \"luzon.bianca@pucp.pe\", \"adrian.suanaz@pucp.pe\", \"soto.y@pucp.edu.pe\", \"a20132766@pucp.pe\", \"andre.lama@pucp.edu.pe\", \"gustavo.meza@pucp.edu.pe\", \"pmlozada@pucp.edu.pe\", \"m.zambranoj@pucp.edu.pe\", \"nicolas.jacobs@pucp.edu.pe\", \"gvidal@pucp.edu.pe\", \"jane.torres@pucp.edu.pe\", \"m.lopez@pucp.edu.pe\", \"alejandro.boyco@pucp.edu.pe\", \"a20167070@pucp.edu.pe\", \"riega.stephy@pucp.edu.pe\", \"vlevanot@pucp.edu.pe\", \"sesquives@pucp.edu.pe\", \"perez.juanc@pucp.edu.pe\", \"mariana.otero@pucp.edu.pe\", \"aclavo@pucp.edu.pe\", \"a20182474@pucp.edu.pe\", \"josue.caldas@pucp.edu.pe\", \"fabio.salas@pucp.edu.pe\", \"fernanda.pizarro@pucp.edu.pe\", \"aquillatupa@pucp.pe\", \"\", \"\", \"\", \"\", \"\", \"f0873079@pucp.edu.pe\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"flores.alexis@pucp.edu.pe\", ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The indices 0, 1, 4, 7 have np.nan values.\n"
     ]
    }
   ],
   "source": [
    "#1. Show the indices of the np.nan values in the f_list list. We want to see this output: The indices 0, 1, 4, 7 have np.nan values.\n",
    "#1° We use the enumerate function to obtain both the position of the object and the value at that position.\n",
    "#2° To ensure the elements are of the same type (numbers), we use isinstance. Then, we apply np.isnan() to check whether the element corresponds to np.nan.\n",
    "#3° If the above condition is met, the index of the element is stored in the list called nan_indices.\n",
    "#4° Finally, we use an f-string to print the requested message and join to display the indices separated by commas in the final te\n",
    "\n",
    "nan_indices = [i for i, s in enumerate(f_list)\n",
    "    if isinstance(s, (int, float)) and np.isnan(s)]\n",
    "\n",
    "print(f\"The indices {', '.join(map(str, nan_indices))} have np.nan values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "#2. Replicate 4 times the values of the list p2_list. We expect an ouput like this: [ 2 , 3, 4, 5, 2 , 3, 4, 5, 2 , 3, 4, 5, 2 , 3, 4, 5].\n",
    "#1° We indicate to Python that we want to multiply the list, so its elements are repeated the required number of times while preserving their original order.\n",
    "#2° We create a list called replicated_list, which gives us a new list with repeated values.\n",
    "\n",
    "replicated_list = p2_list * 4\n",
    "\n",
    "print(replicated_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "#3. Print the length of f_list\n",
    "#The len() function allows us to determine the size of a specific list; in this case, f_list has 8 elements.\n",
    "\n",
    "print(len(f_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My teacher assistant is so boring.\n"
     ]
    }
   ],
   "source": [
    "#4. Print My teacher assistant is so boring. using text1 list.\n",
    "#The join() function allows us to concatenate the elements of a list into a single text. It also allows adding a space between each word.\n",
    "\n",
    "print(\" \".join(text1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My TA is so boring, but is very funny.\n"
     ]
    }
   ],
   "source": [
    "#5. Print My TA is so boring, but is very funny.\n",
    "#1° We replace 'teacher' and 'assistant' with 'TA' and remove the period from 'boring.'.\n",
    "#2° We use the extend() function to add the required elements to text1.\n",
    "#3° We join the list into a single string and call it new_text1.\n",
    "\n",
    "text1 = ['My', 'teacher', 'assistant', 'is', 'so', 'boring.']\n",
    "\n",
    "text1[1:3] = ['TA'] \n",
    "text1[4] = 'boring,'\n",
    "\n",
    "text1.extend(['but', 'is', 'very', 'funny.'])\n",
    "\n",
    "new_text1 = \" \".join(text1)\n",
    "\n",
    "print(new_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max value of values1 is 86 and is located in the 0 index.\n",
      "The min value of values1 is 0 and is located in the 7 index.\n"
     ]
    }
   ],
   "source": [
    "#6. Print \n",
    "#The max value of values1 is 86 and is located in the 0 index.\n",
    "#The min value of values1 is 0 and is located in the 7 index.\n",
    "#1° We must find the maximum and minimum values,\n",
    "#2° as well as their indices, which give us the first position where each value appears.\n",
    "#3° Then, using f-strings, we obtain the required text by inserting the results inside braces.\n",
    "\n",
    "values1 = [86, 86, 85, 85, 85, 83, 23, 0, 84, 1]\n",
    "\n",
    "max_val = max(values1)\n",
    "min_val = min(values1)\n",
    "\n",
    "max_index = values1.index(max_val)\n",
    "min_index = values1.index(min_val)\n",
    "\n",
    "print(f\"The max value of values1 is {max_val} and is located in the {max_index} index.\")\n",
    "print(f\"The min value of values1 is {min_val} and is located in the {min_index} index.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names: ['CHRISTIAN SANTOS', 'CRISTIAN NASSER', 'ANGELICA KARINA', 'JOSE ROBERTO', 'ABEL FERNANDO', 'MEIR ALVARO', 'JOSELIN ALEXANDRA', 'LEONEL ARTURO', 'JOSE FELIPE', 'AFRANIA', 'BIANCA MARIETTE', 'ADRIAN ANDRE', 'DORKAS YOMIRA JHERMY', 'LADY ALY', 'HECTOR ANDRE', 'GUSTAVO', 'PERSEO MARCELO', 'MIGUEL ALONZO', 'NICOLAS', 'ROCIO GABRIELA', 'JANE CAMILA', 'MARIA ELISA', 'ALEJANDRO', 'KARLINE ROSMELI', 'STEPHY ROSARIO', 'VALERIA CECILIA', 'SEBASTIAN RENATO', 'JUAN CARLOS', 'MARIANA', 'ANDREA BRIZETH', 'ERICK JOSUE', 'JOSUE DANIEL', 'FABIO MANUEL', 'FERNANDA NICOLLE', 'ANGELA ADELINA', 'CESAR DANTE', 'GABRIELA ISABEL', 'ANGEL MAURICIO', 'JUAN DIEGO', 'ARONE', 'PERCY ALBERTH', 'KEVIN ARTURO', 'CESAR ERNESTO', 'CÉSAR AGUSTO', 'DIANA EDITH', 'RODRIGO FRANCO', 'GRETTEL ALEXANDRA', 'ROSA ANGELA', 'DANTE OMAR', 'YAJAIRA ALEXANDRA', 'JORGE ALBERTO', 'ALEXIS']\n",
      "Last Names: ['CORNEJO SANCHEZ', 'ORELLANA QUISPE', 'MORALES CHOQUEHUANCA', 'GUIMARAY RIBEYRO', 'CAMACHO GAVIDIA', 'TINTAYA ORIHUELA', 'CHAVEZ MARTINEZ', 'FIGUEROA MURO', 'GOMEZ CRIBILLERO', 'PALOMINO SEGUÍN', 'LUZON CUEVA', 'SUAÑA ZEGARRA', 'SOTO POMACHAGUA', 'FIORENTINO MARTINEZ', 'LAMA MAVILA', 'MEZA HINOJO', 'LOZADA MURILLO', 'ZAMBRANO JIMENEZ', 'JACOBS LUQUE', 'VIDAL VIDAL', 'TORRES ANICAMA', 'LOPEZ ESTRADA', 'BOYCO ORAMS', 'DIAZ BERROSPI', 'RIEGA ESCALANTE', 'LEVANO TORRES', 'ESQUIVES BRAVO', 'PEREZ GONZALES', 'OTERO MAGUIÑA', 'CLAVO CAMPOS', 'AGUILAR GARCIA', 'CALDAS VELASQUEZ', 'SALAS NUÑEZ BORJA', 'PIZARRO VILLANES', 'QUILLATUPA MORALES', 'HUANCAYA IDONE', 'CALVO PORTOCARRERO', 'IBAÑEZ ABANTO', 'MELÉNDEZ APONTE', 'CRISTIAN SERRANO', 'HINOJOSA CAHUANA', 'ANGLAS GARCÍA', 'ALDAVE ACOSTA', 'NÚÑEZ HUAMÁN', 'OBREGON HUAMAN', 'SOTO PACHERRES', 'INGARUCA RIVERA', 'ROJAS HUAMAN', 'NEYRA SALAS', 'HUERTA ESPINOZA', 'HUANCA MARTINEZ', 'FLORES CADILLO']\n"
     ]
    }
   ],
   "source": [
    "#7. Get two lists: names and last_names using last_and_name list. \n",
    "#1° We use the map() function to split each element into a sublist. In this case, it will be two elements: [Last Name, First Name].\n",
    "#2° We \"unpack\" the results into two lists using zip(*), which separates them and then groups them as required.\n",
    "#This automatically separates the first elements from the second ones.\n",
    "\n",
    "split_data = map(lambda x: x.split(\", \"), last_and_name)\n",
    "\n",
    "last_names, names = map(list, zip(*split_data))\n",
    "\n",
    "print(\"Names:\", names)\n",
    "print(\"Last Names:\", last_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last name of students without gmail: ['HUANCAYA', 'CALVO', 'IBAÑEZ', 'MELÉNDEZ', 'CRISTIAN', 'ANGLAS', 'ALDAVE', 'NÚÑEZ', 'OBREGON', 'SOTO', 'INGARUCA', 'ROJAS', 'NEYRA', 'HUERTA', 'HUANCA']\n"
     ]
    }
   ],
   "source": [
    "#8. Give only the last names of students who do not have email. Use the emails and last_names\n",
    "#1° We use the map() function to separate first names and last names.\n",
    "#2° We create a list that contains only last names.\n",
    "#3° With the zip() function, we pair each last name with its corresponding email.\n",
    "#4° We filter the students who do not have an email (empty string \"\") and keep only their last name.\n",
    "\n",
    "split_data = map(lambda x: x.split(\", \"), last_and_name)\n",
    "\n",
    "last_names = list(map(lambda x: x[0], split_data))\n",
    "\n",
    "students = zip(emails, last_names)\n",
    "\n",
    "no_email_last_names = list(\n",
    "    map(lambda x: x.split()[0],\n",
    "        [last for email, last in students if email == \"\"]))\n",
    "\n",
    "print(\"Last name of students without gmail:\", no_email_last_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Strings\n",
    "\n",
    "\n",
    "1. Drop the duplicated blank spaces in `str1`. Do not use the regular expresions. Do not use the code shown in class. Explain your steps.**Hint: Use `split` method and `join` function.**\n",
    "\n",
    "2. Get the number of letters in the string .**Hint: Use `len`function.**\n",
    "\n",
    "3. Get the number of blank spaces (all of them) in the string .**Hint: Use `len`function.**\n",
    "\n",
    "4. Get the position of `@` in each string in the emails list. **Hint: Use `map`function and `find` method.**\n",
    "\n",
    "5. Identifies if exists `.edu.`  in each string in the `emails` list. Get a list of Booleans. **Hint: Use `map`function and `find` method.**\n",
    "\n",
    "6. Get all the strings before the first dot `.`in each string in the `emails` list. Identifies how many of them has `@`. **Hint: Use `map`function and `find` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = 'I am                            too                                                        old'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = [\"cscornejo@pucp.edu.pe\", \"orellana.cn@pucp.edu.pe\", \"karina.morales@pucp.edu.pe\", \"a20083223@pucp.pe\", \"abel.camacho@pucp.pe\", \"mtintaya@pucp.edu.pe\", \"joselin.chavez@pucp.edu.pe\", \"a20105737@pucp.pe\", \"jfgomezc@pucp.pe\", \"afrania.palomino@pucp.pe\", \"luzon.bianca@pucp.pe\", \"adrian.suanaz@pucp.pe\", \"soto.y@pucp.edu.pe\", \"a20132766@pucp.pe\", \"andre.lama@pucp.edu.pe\", \"gustavo.meza@pucp.edu.pe\", \"pmlozada@pucp.edu.pe\", \"m.zambranoj@pucp.edu.pe\", \"nicolas.jacobs@pucp.edu.pe\", \"gvidal@pucp.edu.pe\", \"jane.torres@pucp.edu.pe\", \"m.lopez@pucp.edu.pe\", \"alejandro.boyco@pucp.edu.pe\", \"a20167070@pucp.edu.pe\", \"riega.stephy@pucp.edu.pe\", \"vlevanot@pucp.edu.pe\", \"sesquives@pucp.edu.pe\", \"perez.juanc@pucp.edu.pe\", \"mariana.otero@pucp.edu.pe\", \"aclavo@pucp.edu.pe\", \"a20182474@pucp.edu.pe\", \"josue.caldas@pucp.edu.pe\", \"fabio.salas@pucp.edu.pe\", \"fernanda.pizarro@pucp.edu.pe\", \"aquillatupa@pucp.pe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Cleaned string: I am too old\n",
      "2) Number of letters (no spaces): 9\n",
      "3) Number of blank spaces: 85\n",
      "4) Positions of '@': [9, 11, 14, 9, 12, 8, 14, 9, 8, 16, 12, 13, 6, 9, 10, 12, 8, 11, 14, 6, 11, 7, 15, 9, 12, 8, 9, 11, 13, 6, 9, 12, 11, 16, 11]\n",
      "5) Contains '.edu.': [True, True, True, False, False, True, True, False, False, False, False, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False]\n",
      "6A) Before first dot: ['cscornejo@pucp', 'orellana', 'karina', 'a20083223@pucp', 'abel', 'mtintaya@pucp', 'joselin', 'a20105737@pucp', 'jfgomezc@pucp', 'afrania', 'luzon', 'adrian', 'soto', 'a20132766@pucp', 'andre', 'gustavo', 'pmlozada@pucp', 'm', 'nicolas', 'gvidal@pucp', 'jane', 'm', 'alejandro', 'a20167070@pucp', 'riega', 'vlevanot@pucp', 'sesquives@pucp', 'perez', 'mariana', 'aclavo@pucp', 'a20182474@pucp', 'josue', 'fabio', 'fernanda', 'aquillatupa@pucp']\n",
      "6B) How many of them have '@': 14\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# 1.3 STRINGS (NO LOOPS / NO REGEX)\n",
    "# ======================================================\n",
    "\n",
    "str1 = 'I am                            too                                                        old'\n",
    "\n",
    "emails = [\n",
    "    \"cscornejo@pucp.edu.pe\", \"orellana.cn@pucp.edu.pe\", \"karina.morales@pucp.edu.pe\",\n",
    "    \"a20083223@pucp.pe\", \"abel.camacho@pucp.pe\", \"mtintaya@pucp.edu.pe\",\n",
    "    \"joselin.chavez@pucp.edu.pe\", \"a20105737@pucp.pe\", \"jfgomezc@pucp.pe\",\n",
    "    \"afrania.palomino@pucp.pe\", \"luzon.bianca@pucp.pe\", \"adrian.suanaz@pucp.edu.pe\",\n",
    "    \"soto.y@pucp.edu.pe\", \"a20132766@pucp.pe\", \"andre.lama@pucp.edu.pe\",\n",
    "    \"gustavo.meza@pucp.edu.pe\", \"pmlozada@pucp.edu.pe\", \"m.zambranoj@pucp.edu.pe\",\n",
    "    \"nicolas.jacobs@pucp.edu.pe\", \"gvidal@pucp.edu.pe\", \"jane.torres@pucp.edu.pe\",\n",
    "    \"m.lopez@pucp.edu.pe\", \"alejandro.boyco@pucp.edu.pe\", \"a20167070@pucp.edu.pe\",\n",
    "    \"riega.stephy@pucp.edu.pe\", \"vlevanot@pucp.edu.pe\", \"sesquives@pucp.edu.pe\",\n",
    "    \"perez.juanc@pucp.edu.pe\", \"mariana.otero@pucp.edu.pe\", \"aclavo@pucp.edu.pe\",\n",
    "    \"a20182474@pucp.edu.pe\", \"josue.caldas@pucp.edu.pe\", \"fabio.salas@pucp.edu.pe\",\n",
    "    \"fernanda.pizarro@pucp.edu.pe\", \"aquillatupa@pucp.pe\"\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 1) Drop duplicated blank spaces in str1 (no regex)\n",
    "# Explanation:\n",
    "# - str1.split() (sin argumento) separa por cualquier espacio en blanco y colapsa múltiples espacios.\n",
    "# - \" \".join(...) une las palabras usando un solo espacio.\n",
    "# Resultado: elimina todos los espacios duplicados.\n",
    "# ------------------------------------------------------\n",
    "clean_str1 = \" \".join(str1.split())\n",
    "print(\"1) Cleaned string:\", clean_str1)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 2) Get the number of letters in the string\n",
    "# Explanation:\n",
    "# - str1.split() elimina espacios al devolver solo las palabras.\n",
    "# - \"\".join(...) une las palabras sin espacios.\n",
    "# - len(...) cuenta caracteres (letras) sin espacios.\n",
    "# ------------------------------------------------------\n",
    "letters_count = len(\"\".join(str1.split()))\n",
    "print(\"2) Number of letters (no spaces):\", letters_count)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3) Get the number of blank spaces (all of them) in the string\n",
    "# Explanation:\n",
    "# - len(str1) cuenta todos los caracteres incluyendo espacios.\n",
    "# - str1.replace(\" \", \"\") elimina todos los espacios.\n",
    "# - La diferencia = cantidad total de espacios.\n",
    "# ------------------------------------------------------\n",
    "spaces_count = len(str1) - len(str1.replace(\" \", \"\"))\n",
    "print(\"3) Number of blank spaces:\", spaces_count)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 4) Get the position of '@' in each string in the emails list\n",
    "# Hint: map function + find method\n",
    "# Explanation:\n",
    "# - x.find(\"@\") devuelve la posición del '@' o -1 si no existe.\n",
    "# - map aplica esa operación a cada email sin usar loops.\n",
    "# ------------------------------------------------------\n",
    "at_positions = list(map(lambda x: x.find(\"@\"), emails))\n",
    "print(\"4) Positions of '@':\", at_positions)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 5) Identify if exists '.edu.' in each string in the emails list (Booleans)\n",
    "# Explanation:\n",
    "# - x.find(\".edu.\") devuelve -1 si no encuentra el texto.\n",
    "# - (find != -1) produce True/False.\n",
    "# - map lo aplica a todos los emails sin loops.\n",
    "# ------------------------------------------------------\n",
    "has_edu = list(map(lambda x: x.find(\".edu.\") != -1, emails))\n",
    "print(\"5) Contains '.edu.':\", has_edu)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 6) Get all strings before the first dot '.' in each email\n",
    "# and identify how many of them has '@'\n",
    "# Explanation (parte A):\n",
    "# - x.find(\".\") obtiene la posición del primer punto.\n",
    "# - x[:pos] extrae lo que está antes del primer punto.\n",
    "# Explanation (parte B):\n",
    "# - verifico si el substring antes del punto contiene '@' con find(\"@\") != -1\n",
    "# - sum(True/False) cuenta cuántos True hay.\n",
    "# ------------------------------------------------------\n",
    "before_first_dot = list(map(lambda x: x[:x.find(\".\")] if x.find(\".\") != -1 else x, emails))\n",
    "count_has_at = sum(map(lambda s: s.find(\"@\") != -1, before_first_dot))\n",
    "\n",
    "print(\"6A) Before first dot:\", before_first_dot)\n",
    "print(\"6B) How many of them have '@':\", count_has_at)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment (Part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "START = \"2022-01-01\"\n",
    "END = \"2025-12-18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        date ticker      close    volume\n",
       " 0 2022-01-03    EEM  44.624966  27572700\n",
       " 1 2022-01-04    EEM  44.470768  24579500\n",
       " 2 2022-01-05    EEM  43.745167  46425100\n",
       " 3 2022-01-06    EEM  43.944710  34288700\n",
       " 4 2022-01-07    EEM  44.343792  32640900,\n",
       " (4970, 4))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Yahoo Finance via yfinance: US tickers (real market yh_df) ---\n",
    "tickers = [\"SPY\", \"QQQ\", \"TLT\", \"GLD\", \"EEM\"]\n",
    "# SPY : S&P 500 index\n",
    "# QQQ : Nasdaq-100 index\n",
    "# TLT : U.S. Treasury bonds with 20+ year maturity\n",
    "# GLD : Physical gold prices\n",
    "# EEM : MSCI Emerging Markets index\n",
    "\n",
    "try:\n",
    "    import yfinance as yf\n",
    "except Exception as e:\n",
    "    yf = None\n",
    "    print(\"Could not import yfinance:\", type(e).__name__, str(e))\n",
    "\n",
    "if yf is not None:\n",
    "    try:\n",
    "        yh_df = yf.download(tickers, start=START, end=END, auto_adjust=True, progress=False)\n",
    "    except Exception as e:\n",
    "        yh_df = pd.DataFrame()\n",
    "        print(\"yfinance download failed:\", type(e).__name__, str(e))\n",
    "else:\n",
    "    yh_df = pd.DataFrame()\n",
    "\n",
    "# Convert to long format: date, ticker, close, volume\n",
    "if isinstance(yh_df, pd.DataFrame) and yh_df.shape[0] > 0:\n",
    "    if isinstance(yh_df.columns, pd.MultiIndex):\n",
    "        close = yh_df[\"Close\"].copy()\n",
    "        vol = yh_df[\"Volume\"].copy()\n",
    "    else:\n",
    "        close = yh_df[[\"Close\"]].rename(columns={\"Close\": tickers[0]})\n",
    "        vol = yh_df[[\"Volume\"]].rename(columns={\"Volume\": tickers[0]})\n",
    "\n",
    "    close.index.name = \"date\"\n",
    "    vol.index.name = \"date\"\n",
    "\n",
    "    us_close_long = close.reset_index().melt(id_vars=\"date\", var_name=\"ticker\", value_name=\"close\")\n",
    "    us_vol_long = vol.reset_index().melt(id_vars=\"date\", var_name=\"ticker\", value_name=\"volume\")\n",
    "    us_mkt = us_close_long.merge(us_vol_long, on=[\"date\",\"ticker\"], how=\"inner\").dropna(subset=[\"close\"])\n",
    "else:\n",
    "    us_mkt = pd.DataFrame(columns=[\"date\",\"ticker\",\"close\",\"volume\"])\n",
    "\n",
    "us_mkt.head(), us_mkt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 From NumPy array to Series \n",
    "\n",
    "Using `us_mkt`:\n",
    "\n",
    "1. Filter to `ticker == \"SPY\"`.\n",
    "2. Take `close` as a NumPy array.\n",
    "3. Create a Series indexed by `date` named `SPY_close_series`.\n",
    "4. Compute the mean/min/max with Series methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 485.61\n",
      "Min: 341.18\n",
      "Max: 687.14\n"
     ]
    }
   ],
   "source": [
    "# 1° Filter the DataFrame to only SPY ticker rows\n",
    "spy_data = us_mkt[us_mkt[\"ticker\"] == \"SPY\"]\n",
    "\n",
    "# 2° Extract the 'close' column as a NumPy array (loses date information)\n",
    "spy_close_array = spy_data[\"close\"].values\n",
    "\n",
    "# 3° Create a pandas Series using the NumPy array as values and dates as index\n",
    "# This restores the date information that was lost when converting to array\n",
    "SPY_close_series = pd.Series(spy_close_array, index=spy_data[\"date\"].values, name=\"SPY_close\")\n",
    "\n",
    "# 4° Use Series methods to compute statistics (mean, min, max)\n",
    "print(f\"Mean: {SPY_close_series.mean():.2f}\")\n",
    "print(f\"Min: {SPY_close_series.min():.2f}\")\n",
    "print(f\"Max: {SPY_close_series.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 From Dictionary to Series \n",
    "\n",
    "Using `us_mkt`:\n",
    "\n",
    "1. Compute the **last available close** for each ticker in `tickers`.\n",
    "2. Store it in a dict `{ticker: last_close}`.\n",
    "3. Convert to a Series and sort descending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPY    669.421936\n",
      "QQQ    599.637390\n",
      "GLD    399.290009\n",
      "TLT     87.459633\n",
      "EEM     52.599998\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1° Use dictionary comprehension to get the last close price for each ticker\n",
    "# Filter us_mkt by ticker, then use .iloc[-1] to get the last row's close value\n",
    "last_close_dict = {ticker: us_mkt[us_mkt[\"ticker\"] == ticker][\"close\"].iloc[-1]\n",
    "                   for ticker in tickers}\n",
    "\n",
    "# 2° Convert the dictionary to a pandas Series (keys become index, values become data)\n",
    "last_close_series = pd.Series(last_close_dict)\n",
    "\n",
    "# 3° Sort the Series in descending order by values (highest close prices first)\n",
    "last_close_series = last_close_series.sort_values(ascending=False)\n",
    "\n",
    "print(last_close_series)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 Series vs NumPy \n",
    "\n",
    "Goal: show why pandas alignment matters.\n",
    "\n",
    "1. Create two Series indexed by date:\n",
    "   - df mid-rate from `df`\n",
    "   - SPY close from `us_mkt`\n",
    "2. Combine them into a yh_dfFrame (pandas aligns on dates).\n",
    "3. Separately, build two NumPy arrays by truncating to the same length.\n",
    "4. In markdown: explain why alignment is safer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas alignment:\n",
      "               mid_rate       close\n",
      "2022-01-03  450.115787  451.875183\n",
      "2022-01-04  451.941357  451.723785\n",
      "2022-01-05  447.542861  443.049744\n",
      "2022-01-06  442.808538  442.633545\n",
      "2022-01-07  441.673424  440.883575 \n",
      "Shape: (994, 2)\n",
      "\n",
      "NumPy arrays truncated to length: 994\n"
     ]
    }
   ],
   "source": [
    "# 1° Create first Series: mid-rate from yh_df (average of High and Low for SPY)\n",
    "# Access MultiIndex columns with [\"High\"][\"SPY\"], compute average, remove NaN\n",
    "mid_rate = ((yh_df[\"High\"][\"SPY\"] + yh_df[\"Low\"][\"SPY\"]) / 2).dropna()\n",
    "\n",
    "# 2° Create second Series: SPY close prices from us_mkt with date as index\n",
    "# Filter by ticker, set date as index, extract close column\n",
    "spy_close = us_mkt[us_mkt[\"ticker\"] == \"SPY\"].set_index(\"date\")[\"close\"]\n",
    "\n",
    "# 3° Combine both Series into a DataFrame\n",
    "# Pandas automatically aligns by date index (matching dates), creates NaN for missing dates\n",
    "combined_df = pd.DataFrame({\"mid_rate\": mid_rate, \"close\": spy_close})\n",
    "print(\"Pandas alignment:\\n\", combined_df.head(), f\"\\nShape: {combined_df.shape}\")\n",
    "\n",
    "# 4° Alternative approach: using NumPy arrays (manual truncation required)\n",
    "# Find the minimum length between both series\n",
    "min_len = min(len(mid_rate), len(spy_close))\n",
    "# Truncate both arrays to the same length (assumes positions correspond to same dates!)\n",
    "mid_array, close_array = mid_rate.values[:min_len], spy_close.values[:min_len]\n",
    "print(f\"\\nNumPy arrays truncated to length: {min_len}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why pandas alignment is safer:**\n",
    " Pandas aligns by index (dates), not position. Handles missing dates with NaN and different lengths automatically.\n",
    "NumPy aligns by position only, requiring manual truncation and assuming positions match same dates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.6 Dealing with Nulls \n",
    "Using `us_mkt`:\n",
    "\n",
    "1. Copy `us_mkt` to `us_mkt_nan`.\n",
    "2. Set 1% of `close` to NaN (fixed random seed).\n",
    "3. Create:\n",
    "   - `us_drop`: drop NaNs\n",
    "   - `us_fill`: fill NaNs with ticker-specific median close\n",
    "4. Compare shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.7 Duplicates \n",
    "\n",
    "1. Create `dup_df` by stacking the last 5 rows of `us_mkt` twice.\n",
    "2. Detect duplicates using `.duplicated()`.\n",
    "3. Remove them using `.drop_duplicates()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.8 Groupby \n",
    "\n",
    "\n",
    "Using `us_mkt`:\n",
    "\n",
    "1. Group by `ticker` and compute:\n",
    "   - mean close\n",
    "   - median close\n",
    "   - max volume\n",
    "2. Rename columns clearly.\n",
    "3. Sort by mean close descending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.9 Reshape \n",
    "\n",
    "1. Create a 1-row wide yh_dfFrame with last closes per ticker.\n",
    "2. Convert it to long format with `melt()` into columns: `ticker`, `last_close`.\n",
    "3. Pivot `us_mkt` into a wide table: index=`date`, columns=`ticker`, values=`close` (keep first 50 dates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
