{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment\n",
    "\n",
    "It is totally prohibited to use any kind of loop. You can use stackoverflow. If you copy codes from previous answers, explain each step. No explanation is `0 points`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Tuple\n",
    "\n",
    "\n",
    "\n",
    "1. Print the first item of the second item of `tuple1` object. **Hint: Use indexing**<br><br>\n",
    "2. Print the last item of the `tuple1` object.**Hint: Use indexing**<br><br>\n",
    "3. Change the value \"orange\" for \"pink grapefruit\". Comment the output. **Hint: Is it possible?** <br><br>\n",
    "4. Print the length of `tuple1`. **Hint: Length function**<br><br>\n",
    "5. Sum all the elements of tuple2 and describe your steps and explain each of them. **Hint: Use `map` function.**<br><br>\n",
    "6. Generate a new tuple object named as `tuple3` with the half values of `tuple2`. This tuple should be similar as `tuple2`, tuple of lists.  **Hint: Use `map` funciont.**<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple1 = (\"Orange\", [10, 20, 30], (5, 15, 25))\n",
    "tuple2 = ([7, 8], [9, 1], [10, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# 1) Print the first item of the second item of tuple1\n",
    "# The second item of tuple1 is the list [10, 20, 30] at index 1.\n",
    "# The first item of that list is 10 at index 0.\n",
    "print(tuple1[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 15, 25)\n"
     ]
    }
   ],
   "source": [
    "# 2) Print the last item of the tuple1 object\n",
    "# We use negative indexing [-1] to access the last element dynamically.\n",
    "print(tuple1[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TypeError: 'tuple' object does not support item assignment\n",
      "Comment: It is impossible to modify a tuple item directly because tuples are immutable objects.\n"
     ]
    }
   ],
   "source": [
    "# 3) Change the value \"orange\" for \"pink grapefruit\"\n",
    "# Tuples are immutable, so item assignment is not supported. \n",
    "# We use a try-except block to handle the TypeError gracefully and print the explanation.\n",
    "try:\n",
    "    tuple1[0] = \"pink grapefruit\"\n",
    "except TypeError as e:\n",
    "    print(\"TypeError:\", e)\n",
    "    print(\"Comment: It is impossible to modify a tuple item directly because tuples are immutable objects.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# 4) Print the length of tuple1\n",
    "# The len() function returns the number of top-level items in the tuple.\n",
    "print(len(tuple1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# 5) Sum all the elements of tuple2\n",
    "# tuple2 consists of lists. We cannot sum lists directly.\n",
    "# Step 1: Use map(sum, tuple2) to apply the sum function to each inner list: ([7,8]->15, [9,1]->10, [10,7]->17).\n",
    "# Step 2: Use sum() again on the result of the map to get the total aggregation (15+10+17).\n",
    "total_sum = sum(map(sum, tuple2))\n",
    "print(total_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([3.5, 4.0], [4.5, 0.5], [5.0, 3.5])\n"
     ]
    }
   ],
   "source": [
    "# 6) Generate a new tuple object named as tuple3 with the half values of tuple2\n",
    "# We need to divide each number inside the nested lists by 2.\n",
    "# Since loops are prohibited, we use nested map functions with lambda expressions.\n",
    "# Outer map: Iterates through each list 'x' in tuple2.\n",
    "# Inner map: Iterates through each item 'y' in list 'x' and performs y/2.\n",
    "# Finally, we convert the inner maps back to lists and the outer map to a tuple to match the original structure.\n",
    "tuple3 = tuple(map(lambda x: list(map(lambda y: y/2, x)), tuple2))\n",
    "print(tuple3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Lists\n",
    "1. Show the indices of the `np.nan` values  in the `f_list` list. We want to see this output: `The indices 0, 1, 4, 7 have np.nan values.` **Hint: Use print function and [f-strings](https://realpython.com/python-f-strings/) to insert the indices values.**<br><br>\n",
    "\n",
    "2. Replicate 4 times the values of the list `p2_list`. We expect an ouput like this: `[ 2 , 3, 4, 5, 2 , 3, 4, 5, 2 , 3, 4, 5, 2 , 3, 4, 5]`.  **Hint: Use multiplication function in `lists`and see the output.**<br><br>\n",
    "3. Print the length of `f_list`. **Hint: Length function**<br><br>\n",
    "4. Print `My teacher assistant is so boring.` using `text1` list. **Hint: Use the [`join` function](https://stackoverflow.com/questions/493819/why-is-it-string-joinlist-instead-of-list-joinstring)**<br><br>\n",
    "5. Print `My TA is so boring, but is very funny.` using `text1` list.**Hint: Use the `join` function, and `extend` method.**<br><br>\n",
    "6. Print <br>\n",
    "`The max value of values1 is 86 and is located in the 0 index. ` <br>\n",
    "`The min value of values1 is 0 and is located in the 7 index. ` <br> **Hint: Use the `f-string`, `min`, and `max` functions.**\n",
    "<br>\n",
    "7. Get two lists: `names` and `last_names` using `last_and_name` list. **Hint: Use `map` and `split`.**\n",
    "<br>\n",
    "8. Give only the last names of students who do not have email. Use the `emails` and `last_names` listt. **Hint: Use `map` and `split`.**\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_list = [np.nan , np.nan, \"Austria\", \"Germany\", np.nan, \"Pakistan\", \"np.nan\", np.nan ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = ['My', 'teacher', 'assistant', 'is', 'so', 'boring.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2_list = [ 2 , 3, 4, 5 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "values1 = [ 86, 86, 85, 85, 85, 83, 23, 0, 84, 1 ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These two lists a\n",
    "last_and_name = [ \"CORNEJO SANCHEZ, CHRISTIAN SANTOS\", \"ORELLANA QUISPE, CRISTIAN NASSER\", \"MORALES CHOQUEHUANCA, ANGELICA KARINA\", \"GUIMARAY RIBEYRO, JOSE ROBERTO\", \"CAMACHO GAVIDIA, ABEL FERNANDO\", \"TINTAYA ORIHUELA, MEIR ALVARO\", \"CHAVEZ MARTINEZ, JOSELIN ALEXANDRA\", \"FIGUEROA MURO, LEONEL ARTURO\", \"GOMEZ CRIBILLERO, JOSE FELIPE\", \"PALOMINO SEGUÍN, AFRANIA\", \"LUZON CUEVA, BIANCA MARIETTE\", \"SUAÑA ZEGARRA, ADRIAN ANDRE\", \"SOTO POMACHAGUA, DORKAS YOMIRA JHERMY\", \"FIORENTINO MARTINEZ, LADY ALY\", \"LAMA MAVILA, HECTOR ANDRE\", \"MEZA HINOJO, GUSTAVO\", \"LOZADA MURILLO, PERSEO MARCELO\", \"ZAMBRANO JIMENEZ, MIGUEL ALONZO\", \"JACOBS LUQUE, NICOLAS\", \"VIDAL VIDAL, ROCIO GABRIELA\", \"TORRES ANICAMA, JANE CAMILA\", \"LOPEZ ESTRADA, MARIA ELISA\", \"BOYCO ORAMS, ALEJANDRO\", \"DIAZ BERROSPI, KARLINE ROSMELI\", \"RIEGA ESCALANTE, STEPHY ROSARIO\", \"LEVANO TORRES, VALERIA CECILIA\", \"ESQUIVES BRAVO, SEBASTIAN RENATO\", \"PEREZ GONZALES, JUAN CARLOS\", \"OTERO MAGUIÑA, MARIANA\", \"CLAVO CAMPOS, ANDREA BRIZETH\", \"AGUILAR GARCIA, ERICK JOSUE\", \"CALDAS VELASQUEZ, JOSUE DANIEL\", \"SALAS NUÑEZ BORJA, FABIO MANUEL\", \"PIZARRO VILLANES, FERNANDA NICOLLE\", \"QUILLATUPA MORALES, ANGELA ADELINA\", \"HUANCAYA IDONE, CESAR DANTE\", \"CALVO PORTOCARRERO, GABRIELA ISABEL\", \"IBAÑEZ ABANTO, ANGEL MAURICIO\", \"MELÉNDEZ APONTE, JUAN DIEGO\", \"CRISTIAN SERRANO, ARONE\", \"HINOJOSA CAHUANA, PERCY ALBERTH\", \"ANGLAS GARCÍA, KEVIN ARTURO\", \"ALDAVE ACOSTA, CESAR ERNESTO\", \"NÚÑEZ HUAMÁN, CÉSAR AGUSTO\", \"OBREGON HUAMAN, DIANA EDITH\", \"SOTO PACHERRES, RODRIGO FRANCO\", \"INGARUCA RIVERA, GRETTEL ALEXANDRA\", \"ROJAS HUAMAN, ROSA ANGELA\", \"NEYRA SALAS, DANTE OMAR\", \"HUERTA ESPINOZA, YAJAIRA ALEXANDRA\", \"HUANCA MARTINEZ, JORGE ALBERTO\", \"FLORES CADILLO, ALEXIS\" ]\n",
    "emails = [\"cscornejo@pucp.edu.pe\", \"orellana.cn@pucp.edu.pe\", \"karina.morales@pucp.edu.pe\", \"a20083223@pucp.pe\", \"abel.camacho@pucp.pe\", \"mtintaya@pucp.edu.pe\", \"joselin.chavez@pucp.edu.pe\", \"a20105737@pucp.pe\", \"jfgomezc@pucp.pe\", \"afrania.palomino@pucp.pe\", \"luzon.bianca@pucp.pe\", \"adrian.suanaz@pucp.pe\", \"soto.y@pucp.edu.pe\", \"a20132766@pucp.pe\", \"andre.lama@pucp.edu.pe\", \"gustavo.meza@pucp.edu.pe\", \"pmlozada@pucp.edu.pe\", \"m.zambranoj@pucp.edu.pe\", \"nicolas.jacobs@pucp.edu.pe\", \"gvidal@pucp.edu.pe\", \"jane.torres@pucp.edu.pe\", \"m.lopez@pucp.edu.pe\", \"alejandro.boyco@pucp.edu.pe\", \"a20167070@pucp.edu.pe\", \"riega.stephy@pucp.edu.pe\", \"vlevanot@pucp.edu.pe\", \"sesquives@pucp.edu.pe\", \"perez.juanc@pucp.edu.pe\", \"mariana.otero@pucp.edu.pe\", \"aclavo@pucp.edu.pe\", \"a20182474@pucp.edu.pe\", \"josue.caldas@pucp.edu.pe\", \"fabio.salas@pucp.edu.pe\", \"fernanda.pizarro@pucp.edu.pe\", \"aquillatupa@pucp.pe\", \"\", \"\", \"\", \"\", \"\", \"f0873079@pucp.edu.pe\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"flores.alexis@pucp.edu.pe\", ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The indices 0, 1, 4, 7 have np.nan values.\n"
     ]
    }
   ],
   "source": [
    "# 1) It asks to determine the index of the elements that are np.nan in the f_list list and print them.\n",
    "\n",
    "# There is no native tool to index lists with np.nan, but we can use numpy and pandas to do it.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# We convert the list into a numpy array\n",
    "f_array = np.array(f_list, dtype=object)\n",
    "\n",
    "# We use np.isnan to get a boolean array indicating where the np.nan values are\n",
    "nan_indices = pd.isna(f_array)\n",
    "\n",
    "# We obtain the indices where the value is True (that is, where there is np.nan)\n",
    "indices = np.where(nan_indices)[0]\n",
    "\n",
    "# We put the result into a string to print it\n",
    "indices = indices.tolist()\n",
    "indices = ', '.join(map(str, indices))\n",
    "\n",
    "# We print the indices\n",
    "print(f\"The indices {indices} have np.nan values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "# 2) It asks to replicate the p2_list list four times using the list multiplication function.\n",
    "\n",
    "# We replicate the list p2_list four times\n",
    "p2_list_replicated = p2_list * 4\n",
    "\n",
    "# We print the replicated list\n",
    "print(p2_list_replicated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of f_list is 8.\n"
     ]
    }
   ],
   "source": [
    "# 3) It asks to determine the length of the f_list list using the len() function.\n",
    "\n",
    "# We calculate the length of f_list\n",
    "length_f_list = len(f_list)\n",
    "\n",
    "# We print the length of f_list\n",
    "print(f\"The length of f_list is {length_f_list}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My teacher assistant is so boring.\n"
     ]
    }
   ],
   "source": [
    "# 4) It asks to print the string \"My teacher assistant is so boring.\" as a single text string using the join() function.\n",
    "\n",
    "# We join the elements of text1 into a single string with spaces in between\n",
    "full_text = ' '.join(text1)\n",
    "\n",
    "# We print the complete text\n",
    "print(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My TA assistant is so boring, but is very funny.\n"
     ]
    }
   ],
   "source": [
    "# 5) It asks to print the string \"My TA is so boring, but is very funny.\" using text1, the join function, and the extend method.\n",
    "\n",
    "# We create a copy of text1 to avoid modifying the original\n",
    "text1_extended = text1.copy()\n",
    "\n",
    "# We edit the necessary words\n",
    "text1_extended[1] = \"TA\"\n",
    "text1_extended[5] = \"boring,\"\n",
    "\n",
    "# We extend the list with the new words\n",
    "text1_extended.extend([\"but\", \"is\", \"very\", \"funny.\"])\n",
    "\n",
    "# We join the list into a single string\n",
    "full_text_extended = \" \".join(text1_extended)\n",
    "\n",
    "# We print the complete text\n",
    "print(full_text_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max value of values1 is 86 and is located in the 0 index.\n",
      "The min value of values1 is 0 and is located in the 7 index.\n"
     ]
    }
   ],
   "source": [
    "# 6) It asks to determine the min and max of the values1 list using the min() and max() functions.\n",
    "\n",
    "# We calculate the minimum and maximum values of values1\n",
    "min_value = min(values1)\n",
    "max_value = max(values1)\n",
    "\n",
    "# We print the minimum and maximum values\n",
    "print(f\"The max value of values1 is {max_value} and is located in the {values1.index(max_value)} index.\")\n",
    "print(f\"The min value of values1 is {min_value} and is located in the {values1.index(min_value)} index.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names: ('CHRISTIAN SANTOS', 'CRISTIAN NASSER', 'ANGELICA KARINA', 'JOSE ROBERTO', 'ABEL FERNANDO', 'MEIR ALVARO', 'JOSELIN ALEXANDRA', 'LEONEL ARTURO', 'JOSE FELIPE', 'AFRANIA', 'BIANCA MARIETTE', 'ADRIAN ANDRE', 'DORKAS YOMIRA JHERMY', 'LADY ALY', 'HECTOR ANDRE', 'GUSTAVO', 'PERSEO MARCELO', 'MIGUEL ALONZO', 'NICOLAS', 'ROCIO GABRIELA', 'JANE CAMILA', 'MARIA ELISA', 'ALEJANDRO', 'KARLINE ROSMELI', 'STEPHY ROSARIO', 'VALERIA CECILIA', 'SEBASTIAN RENATO', 'JUAN CARLOS', 'MARIANA', 'ANDREA BRIZETH', 'ERICK JOSUE', 'JOSUE DANIEL', 'FABIO MANUEL', 'FERNANDA NICOLLE', 'ANGELA ADELINA', 'CESAR DANTE', 'GABRIELA ISABEL', 'ANGEL MAURICIO', 'JUAN DIEGO', 'ARONE', 'PERCY ALBERTH', 'KEVIN ARTURO', 'CESAR ERNESTO', 'CÉSAR AGUSTO', 'DIANA EDITH', 'RODRIGO FRANCO', 'GRETTEL ALEXANDRA', 'ROSA ANGELA', 'DANTE OMAR', 'YAJAIRA ALEXANDRA', 'JORGE ALBERTO', 'ALEXIS')\n",
      "Last Names: ('CORNEJO SANCHEZ', 'ORELLANA QUISPE', 'MORALES CHOQUEHUANCA', 'GUIMARAY RIBEYRO', 'CAMACHO GAVIDIA', 'TINTAYA ORIHUELA', 'CHAVEZ MARTINEZ', 'FIGUEROA MURO', 'GOMEZ CRIBILLERO', 'PALOMINO SEGUÍN', 'LUZON CUEVA', 'SUAÑA ZEGARRA', 'SOTO POMACHAGUA', 'FIORENTINO MARTINEZ', 'LAMA MAVILA', 'MEZA HINOJO', 'LOZADA MURILLO', 'ZAMBRANO JIMENEZ', 'JACOBS LUQUE', 'VIDAL VIDAL', 'TORRES ANICAMA', 'LOPEZ ESTRADA', 'BOYCO ORAMS', 'DIAZ BERROSPI', 'RIEGA ESCALANTE', 'LEVANO TORRES', 'ESQUIVES BRAVO', 'PEREZ GONZALES', 'OTERO MAGUIÑA', 'CLAVO CAMPOS', 'AGUILAR GARCIA', 'CALDAS VELASQUEZ', 'SALAS NUÑEZ BORJA', 'PIZARRO VILLANES', 'QUILLATUPA MORALES', 'HUANCAYA IDONE', 'CALVO PORTOCARRERO', 'IBAÑEZ ABANTO', 'MELÉNDEZ APONTE', 'CRISTIAN SERRANO', 'HINOJOSA CAHUANA', 'ANGLAS GARCÍA', 'ALDAVE ACOSTA', 'NÚÑEZ HUAMÁN', 'OBREGON HUAMAN', 'SOTO PACHERRES', 'INGARUCA RIVERA', 'ROJAS HUAMAN', 'NEYRA SALAS', 'HUERTA ESPINOZA', 'HUANCA MARTINEZ', 'FLORES CADILLO')\n"
     ]
    }
   ],
   "source": [
    "# 7) It asks to separate the last_and_name list into two lists: names and last_names using map() and split(). \n",
    "\n",
    "# We use map and split to separate last names and names\n",
    "separated = list(map(lambda x: x.split(\", \"), last_and_name))\n",
    "# Explanation: The lambda function takes each element x from the last_and_name list and\n",
    "# splits it into a list of two elements using \", \" as the separator.\n",
    "\n",
    "# We separate the new list into two lists\n",
    "last_names, names = zip(*separated)\n",
    "\n",
    "# We print the results\n",
    "print(\"Names:\", names)\n",
    "print(\"Last Names:\", last_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last names of students without email: ['HUANCAYA IDONE', 'CALVO PORTOCARRERO', 'IBAÑEZ ABANTO', 'MELÉNDEZ APONTE', 'CRISTIAN SERRANO', 'ANGLAS GARCÍA', 'ALDAVE ACOSTA', 'NÚÑEZ HUAMÁN', 'OBREGON HUAMAN', 'SOTO PACHERRES', 'INGARUCA RIVERA', 'ROJAS HUAMAN', 'NEYRA SALAS', 'HUERTA ESPINOZA', 'HUANCA MARTINEZ']\n"
     ]
    }
   ],
   "source": [
    "# 8) It asks to print the last names of students who do not have an email registered in the emails list using map() and split().\n",
    "\n",
    "# We obtain the boolean values for empty emails\n",
    "empty_email_flags = list(map(lambda x: x == \"\", emails))\n",
    "\n",
    "# We filter the last names corresponding to empty emails\n",
    "filtered_last_names = [last_names[i] for i in range(len(emails)) if empty_email_flags[i]]\n",
    "# Explanation: For each index in the range of the length of emails, if the value in empty_email_flags\n",
    "# is True (empty email), we add the corresponding last name to filtered_last_names.\n",
    "\n",
    "# We print the filtered last names\n",
    "print(\"Last names of students without email:\", filtered_last_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Strings\n",
    "\n",
    "\n",
    "1. Drop the duplicated blank spaces in `str1`. Do not use the regular expresions. Do not use the code shown in class. Explain your steps.**Hint: Use `split` method and `join` function.**\n",
    "\n",
    "2. Get the number of letters in the string .**Hint: Use `len`function.**\n",
    "\n",
    "3. Get the number of blank spaces (all of them) in the string .**Hint: Use `len`function.**\n",
    "\n",
    "4. Get the position of `@` in each string in the emails list. **Hint: Use `map`function and `find` method.**\n",
    "\n",
    "5. Identifies if exists `.edu.`  in each string in the `emails` list. Get a list of Booleans. **Hint: Use `map`function and `find` method.**\n",
    "\n",
    "6. Get all the strings before the first dot `.`in each string in the `emails` list. Identifies how many of them has `@`. **Hint: Use `map`function and `find` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = 'I am                            too                                                        old'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = [\"cscornejo@pucp.edu.pe\", \"orellana.cn@pucp.edu.pe\", \"karina.morales@pucp.edu.pe\", \"a20083223@pucp.pe\", \"abel.camacho@pucp.pe\", \"mtintaya@pucp.edu.pe\", \"joselin.chavez@pucp.edu.pe\", \"a20105737@pucp.pe\", \"jfgomezc@pucp.pe\", \"afrania.palomino@pucp.pe\", \"luzon.bianca@pucp.pe\", \"adrian.suanaz@pucp.pe\", \"soto.y@pucp.edu.pe\", \"a20132766@pucp.pe\", \"andre.lama@pucp.edu.pe\", \"gustavo.meza@pucp.edu.pe\", \"pmlozada@pucp.edu.pe\", \"m.zambranoj@pucp.edu.pe\", \"nicolas.jacobs@pucp.edu.pe\", \"gvidal@pucp.edu.pe\", \"jane.torres@pucp.edu.pe\", \"m.lopez@pucp.edu.pe\", \"alejandro.boyco@pucp.edu.pe\", \"a20167070@pucp.edu.pe\", \"riega.stephy@pucp.edu.pe\", \"vlevanot@pucp.edu.pe\", \"sesquives@pucp.edu.pe\", \"perez.juanc@pucp.edu.pe\", \"mariana.otero@pucp.edu.pe\", \"aclavo@pucp.edu.pe\", \"a20182474@pucp.edu.pe\", \"josue.caldas@pucp.edu.pe\", \"fabio.salas@pucp.edu.pe\", \"fernanda.pizarro@pucp.edu.pe\", \"aquillatupa@pucp.pe\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am too old\n"
     ]
    }
   ],
   "source": [
    "# 1) It asks to remove unnecessary blank spaces in the str1 string using the split() and join() functions.\n",
    "\n",
    "# We use split to divide the string into words, removing unnecessary blank spaces\n",
    "words = str1.split()\n",
    "# Explanation: The split() function without arguments divides the string into words\n",
    "# using any amount of whitespace as a separator.\n",
    "\n",
    "# We use join to combine the words with a single space between them\n",
    "cleaned_str1 = ' '.join(words)\n",
    "\n",
    "# We print the cleaned string\n",
    "print(cleaned_str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of letters in str1 is 9.\n"
     ]
    }
   ],
   "source": [
    "# 2) It asks to calculate the number of letters in str1 using the len() function.\n",
    "\n",
    "# From the cleaned string, we count the number of letters excluding spaces\n",
    "num_letters = len(cleaned_str1.replace(\" \", \"\"))\n",
    "\n",
    "# We print the number of letters\n",
    "print(f\"The number of letters in str1 is {num_letters}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of spaces in str1 is 85.\n"
     ]
    }
   ],
   "source": [
    "# 3) It asks to calculate the number of spaces in the original str1 using the len() function.\n",
    "\n",
    "# We count the number of characters in the original str1 string\n",
    "len_str1 = len(str1)\n",
    "\n",
    "# We subtract the number of letters calculated previously\n",
    "num_spaces = len_str1 - num_letters\n",
    "\n",
    "# We print the number of spaces\n",
    "print(f\"The number of spaces in str1 is {num_spaces}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 11, 14, 9, 12, 8, 14, 9, 8, 16, 12, 13, 6, 9, 10, 12, 8, 11, 14, 6, 11, 7, 15, 9, 12, 8, 9, 11, 13, 6, 9, 12, 11, 16, 11]\n"
     ]
    }
   ],
   "source": [
    "# 4) It asks to identify the index of \"@\" in each element of the emails list and return the result using the map() and find() functions.\n",
    "\n",
    "# We use map and find to obtain the index of \"@\" in each email.\n",
    "list_of_at_index = list(map(lambda x: x.find(\"@\"), emails))\n",
    "# Explanation: The lambda function takes each email x and uses find() to search for the \"@\" character.\n",
    "\n",
    "# We print the result\n",
    "print(list_of_at_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, False, False, True, True, False, False, False, False, False, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False]\n"
     ]
    }
   ],
   "source": [
    "# 5) It asks to identify whether the string \".edu.\" exists in each element of the emails list and return a boolean using the map() and find() functions.\n",
    "\n",
    "# We use map and find to check the presence of \".edu.\" in each email.\n",
    "list_of_edu = list(map(lambda x: x.find(\".edu.\") != -1, emails))\n",
    "# Explanation: The lambda function takes each email x and uses find() to search for the substring \".edu.\".\n",
    "# If it is found, find() returns an index >= 0, so we compare it with -1 to get a boolean.\n",
    "\n",
    "# We print the result\n",
    "print(list_of_edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cscornejo@pucp', 'orellana', 'karina', 'a20083223@pucp', 'abel', 'mtintaya@pucp', 'joselin', 'a20105737@pucp', 'jfgomezc@pucp', 'afrania', 'luzon', 'adrian', 'soto', 'a20132766@pucp', 'andre', 'gustavo', 'pmlozada@pucp', 'm', 'nicolas', 'gvidal@pucp', 'jane', 'm', 'alejandro', 'a20167070@pucp', 'riega', 'vlevanot@pucp', 'sesquives@pucp', 'perez', 'mariana', 'aclavo@pucp', 'a20182474@pucp', 'josue', 'fabio', 'fernanda', 'aquillatupa@pucp']\n",
      "The number of elements with '@' is 35.\n"
     ]
    }
   ],
   "source": [
    "# 6) It asks to print the string before the \".\" character and count the number of elements that have \"@\" in them using the map() and find() functions.\n",
    "\n",
    "# We use map and find to get the string before the first \".\" in each email.\n",
    "list_before_dot = list(map(lambda x: x[:x.find(\".\")], emails))\n",
    "# Explanation: The lambda function takes each email x and uses find() to search for the \".\" character.\n",
    "# With the obtained index, we extract the substring from the beginning up to that index.\n",
    "\n",
    "# We count the number of elements that have \"@\" in them\n",
    "list_with_at = list(map(lambda x: x.find(\"@\") != -1, emails))\n",
    "# Explanation: The lambda function takes each email x and uses find() to search for the \"@\" character.\n",
    "# If it is found, find() returns an index >= 0, so we compare it with -1 to get a boolean.\n",
    "\n",
    "# We sum the boolean values to get the count of elements with \"@\"\n",
    "count_with_at = sum(list_with_at)\n",
    "\n",
    "# We print the results\n",
    "print(list_before_dot)\n",
    "print(f\"The number of elements with '@' is {count_with_at}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Assignment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance<1.0\n",
      "  Downloading yfinance-0.2.66-py2.py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\aaron\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\aaron\\anaconda3\\lib\\site-packages (from yfinance<1.0) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\aaron\\anaconda3\\lib\\site-packages (from yfinance<1.0) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\aaron\\anaconda3\\lib\\site-packages (from yfinance<1.0) (2.32.2)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\aaron\\anaconda3\\lib\\site-packages (from yfinance<1.0) (0.0.12)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\aaron\\anaconda3\\lib\\site-packages (from yfinance<1.0) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\aaron\\anaconda3\\lib\\site-packages (from yfinance<1.0) (2024.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\aaron\\anaconda3\\lib\\site-packages (from yfinance<1.0) (2.4.2)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\aaron\\anaconda3\\lib\\site-packages (from yfinance<1.0) (3.18.3)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\aaron\\anaconda3\\lib\\site-packages (from yfinance<1.0) (4.12.3)\n",
      "Requirement already satisfied: curl_cffi>=0.7 in c:\\users\\aaron\\anaconda3\\lib\\site-packages (from yfinance<1.0) (0.13.0)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in c:\\users\\aaron\\anaconda3\\lib\\site-packages (from yfinance<1.0) (5.29.3)\n",
      "Requirement already satisfied: websockets>=13.0 in c:\\users\\aaron\\anaconda3\\lib\\site-packages (from yfinance<1.0) (15.0.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\aaron\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance<1.0) (2.5)\n",
      "Requirement already satisfied: cffi>=1.12.0 in c:\\users\\aaron\\anaconda3\\lib\\site-packages (from curl_cffi>=0.7->yfinance<1.0) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in c:\\users\\aaron\\anaconda3\\lib\\site-packages (from curl_cffi>=0.7->yfinance<1.0) (2025.10.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aaron\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance<1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aaron\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance<1.0) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aaron\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance<1.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aaron\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance<1.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aaron\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance<1.0) (2.2.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\aaron\\anaconda3\\lib\\site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance<1.0) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aaron\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance<1.0) (1.16.0)\n",
      "Downloading yfinance-0.2.66-py2.py3-none-any.whl (123 kB)\n",
      "   ---------------------------------------- 0.0/123.4 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 20.5/123.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 123.4/123.4 kB 1.8 MB/s eta 0:00:00\n",
      "Installing collected packages: yfinance\n",
      "  Attempting uninstall: yfinance\n",
      "    Found existing installation: yfinance 1.0\n",
      "    Uninstalling yfinance-1.0:\n",
      "      Successfully uninstalled yfinance-1.0\n",
      "Successfully installed yfinance-0.2.66\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"yfinance<1.0\" typing_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "START = \"2022-01-01\"\n",
    "END = \"2025-12-18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        date ticker      close    volume\n",
       " 0 2022-01-03    EEM  44.624966  27572700\n",
       " 1 2022-01-04    EEM  44.470776  24579500\n",
       " 2 2022-01-05    EEM  43.745167  46425100\n",
       " 3 2022-01-06    EEM  43.944710  34288700\n",
       " 4 2022-01-07    EEM  44.343792  32640900,\n",
       " (4970, 4))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Yahoo Finance via yfinance: US tickers (real market yh_df) ---\n",
    "tickers = [\"SPY\", \"QQQ\", \"TLT\", \"GLD\", \"EEM\"]\n",
    "# SPY : S&P 500 index\n",
    "# QQQ : Nasdaq-100 index\n",
    "# TLT : U.S. Treasury bonds with 20+ year maturity\n",
    "# GLD : Physical gold prices\n",
    "# EEM : MSCI Emerging Markets index\n",
    "\n",
    "try:\n",
    "    import yfinance as yf\n",
    "except Exception as e:\n",
    "    yf = None\n",
    "    print(\"Could not import yfinance:\", type(e).__name__, str(e))\n",
    "\n",
    "if yf is not None:\n",
    "    try:\n",
    "        yh_df = yf.download(tickers, start=START, end=END, auto_adjust=True, progress=False)\n",
    "    except Exception as e:\n",
    "        yh_df = pd.DataFrame()\n",
    "        print(\"yfinance download failed:\", type(e).__name__, str(e))\n",
    "else:\n",
    "    yh_df = pd.DataFrame()\n",
    "\n",
    "# Convert to long format: date, ticker, close, volume\n",
    "if isinstance(yh_df, pd.DataFrame) and yh_df.shape[0] > 0:\n",
    "    if isinstance(yh_df.columns, pd.MultiIndex):\n",
    "        close = yh_df[\"Close\"].copy()\n",
    "        vol = yh_df[\"Volume\"].copy()\n",
    "    else:\n",
    "        close = yh_df[[\"Close\"]].rename(columns={\"Close\": tickers[0]})\n",
    "        vol = yh_df[[\"Volume\"]].rename(columns={\"Volume\": tickers[0]})\n",
    "\n",
    "    close.index.name = \"date\"\n",
    "    vol.index.name = \"date\"\n",
    "\n",
    "    us_close_long = close.reset_index().melt(id_vars=\"date\", var_name=\"ticker\", value_name=\"close\")\n",
    "    us_vol_long = vol.reset_index().melt(id_vars=\"date\", var_name=\"ticker\", value_name=\"volume\")\n",
    "    us_mkt = us_close_long.merge(us_vol_long, on=[\"date\",\"ticker\"], how=\"inner\").dropna(subset=[\"close\"])\n",
    "else:\n",
    "    us_mkt = pd.DataFrame(columns=[\"date\",\"ticker\",\"close\",\"volume\"])\n",
    "\n",
    "us_mkt.head(), us_mkt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_raw</th>\n",
       "      <th>PENUSD_buy</th>\n",
       "      <th>PENUSD_sell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03.Ene.22</td>\n",
       "      <td>3.98366666666667</td>\n",
       "      <td>3.98883333333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04.Ene.22</td>\n",
       "      <td>3.9595</td>\n",
       "      <td>3.964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05.Ene.22</td>\n",
       "      <td>3.952</td>\n",
       "      <td>3.95633333333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06.Ene.22</td>\n",
       "      <td>3.96716666666667</td>\n",
       "      <td>3.96966666666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07.Ene.22</td>\n",
       "      <td>3.94516666666667</td>\n",
       "      <td>3.94816666666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>12.Dic.25</td>\n",
       "      <td>3.36685714285714</td>\n",
       "      <td>3.36885714285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>15.Dic.25</td>\n",
       "      <td>3.36871428571429</td>\n",
       "      <td>3.3705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>16.Dic.25</td>\n",
       "      <td>3.36985714285714</td>\n",
       "      <td>3.37142857142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>17.Dic.25</td>\n",
       "      <td>3.36771428571429</td>\n",
       "      <td>3.36914285714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>18.Dic.25</td>\n",
       "      <td>3.36514285714286</td>\n",
       "      <td>3.36664285714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>988 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      date_raw        PENUSD_buy       PENUSD_sell\n",
       "0    03.Ene.22  3.98366666666667  3.98883333333333\n",
       "1    04.Ene.22            3.9595             3.964\n",
       "2    05.Ene.22             3.952  3.95633333333333\n",
       "3    06.Ene.22  3.96716666666667  3.96966666666667\n",
       "4    07.Ene.22  3.94516666666667  3.94816666666667\n",
       "..         ...               ...               ...\n",
       "983  12.Dic.25  3.36685714285714  3.36885714285714\n",
       "984  15.Dic.25  3.36871428571429            3.3705\n",
       "985  16.Dic.25  3.36985714285714  3.37142857142857\n",
       "986  17.Dic.25  3.36771428571429  3.36914285714286\n",
       "987  18.Dic.25  3.36514285714286  3.36664285714286\n",
       "\n",
       "[988 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- BCRP: daily exchange rate PEN/USD buy & sell (official API) ---\n",
    "# Codes:\n",
    "# - PD04637PD: USD/PEN (buy)\n",
    "# - PD04638PD: USD/PEN (sell)\n",
    "\n",
    "import requests\n",
    "\n",
    "bcrp_url = f\"https://estadisticas.bcrp.gob.pe/estadisticas/series/api/PD04637PD-PD04638PD/json/{START}/{END}/esp\"\n",
    "try:\n",
    "    r = requests.get(bcrp_url, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    bcrp_obj = r.json()\n",
    "except Exception as e:\n",
    "    bcrp_obj = {\"periods\": []}\n",
    "    print(\"BCRP request failed:\", type(e).__name__, str(e))\n",
    "\n",
    "periods = bcrp_obj.get(\"periods\", [])\n",
    "rows = []\n",
    "for p in periods:\n",
    "    name = p.get(\"name\")\n",
    "    vals = p.get(\"values\", [])\n",
    "    if isinstance(vals, str):\n",
    "        vals = [vals]\n",
    "    if name is None or not isinstance(vals, list) or len(vals) < 2:\n",
    "        continue\n",
    "    rows.append([name, vals[0], vals[1]])\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"date_raw\", \"PENUSD_buy\", \"PENUSD_sell\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.2 From NumPy array to Series \n",
    "\n",
    "Using `us_mkt`:\n",
    "\n",
    "1. Filter to `ticker == \"SPY\"`.\n",
    "2. Take `close` as a NumPy array.\n",
    "3. Create a Series indexed by `date` named `SPY_close_series`.\n",
    "4. Compute the mean/min/max with Series methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.3 From Dictionary to Series \n",
    "\n",
    "Using `us_mkt`:\n",
    "\n",
    "1. Compute the **last available close** for each ticker in `tickers`.\n",
    "2. Store it in a dict `{ticker: last_close}`.\n",
    "3. Convert to a Series and sort descending."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.4 Series vs NumPy \n",
    "\n",
    "Goal: show why pandas alignment matters.\n",
    "\n",
    "1. Create two Series indexed by date:\n",
    "   - df mid-rate from `df`\n",
    "   - SPY close from `us_mkt`\n",
    "2. Combine them into a yh_dfFrame (pandas aligns on dates).\n",
    "3. Separately, build two NumPy arrays by truncating to the same length.\n",
    "4. In markdown: explain why alignment is safer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>EEM</td>\n",
       "      <td>44.624966</td>\n",
       "      <td>27572700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>SPY</td>\n",
       "      <td>451.875183</td>\n",
       "      <td>72668200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>QQQ</td>\n",
       "      <td>391.679474</td>\n",
       "      <td>40575900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>TLT</td>\n",
       "      <td>125.295334</td>\n",
       "      <td>33860400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>GLD</td>\n",
       "      <td>168.330002</td>\n",
       "      <td>9014400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-17</th>\n",
       "      <td>SPY</td>\n",
       "      <td>669.421936</td>\n",
       "      <td>110625200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-17</th>\n",
       "      <td>GLD</td>\n",
       "      <td>399.290009</td>\n",
       "      <td>10456900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-17</th>\n",
       "      <td>EEM</td>\n",
       "      <td>52.599998</td>\n",
       "      <td>35740800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-17</th>\n",
       "      <td>QQQ</td>\n",
       "      <td>599.637390</td>\n",
       "      <td>70654300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-17</th>\n",
       "      <td>TLT</td>\n",
       "      <td>87.459633</td>\n",
       "      <td>24668300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4970 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ticker       close     volume\n",
       "date                                    \n",
       "2022-01-03    EEM   44.624966   27572700\n",
       "2022-01-03    SPY  451.875183   72668200\n",
       "2022-01-03    QQQ  391.679474   40575900\n",
       "2022-01-03    TLT  125.295334   33860400\n",
       "2022-01-03    GLD  168.330002    9014400\n",
       "...           ...         ...        ...\n",
       "2025-12-17    SPY  669.421936  110625200\n",
       "2025-12-17    GLD  399.290009   10456900\n",
       "2025-12-17    EEM   52.599998   35740800\n",
       "2025-12-17    QQQ  599.637390   70654300\n",
       "2025-12-17    TLT   87.459633   24668300\n",
       "\n",
       "[4970 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert date column to datetime and sort ascending\n",
    "us_mkt[\"date\"] = pd.to_datetime(us_mkt[\"date\"])\n",
    "us_mkt = us_mkt.sort_values(\"date\")\n",
    "\n",
    "# Set date as the index \n",
    "us_mkt = us_mkt.set_index(\"date\")\n",
    "us_mkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PENUSD_buy</th>\n",
       "      <th>PENUSD_sell</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>3.98366666666667</td>\n",
       "      <td>3.98883333333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04</th>\n",
       "      <td>3.9595</td>\n",
       "      <td>3.964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "      <td>3.952</td>\n",
       "      <td>3.95633333333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-06</th>\n",
       "      <td>3.96716666666667</td>\n",
       "      <td>3.96966666666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-07</th>\n",
       "      <td>3.94516666666667</td>\n",
       "      <td>3.94816666666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-12</th>\n",
       "      <td>3.36685714285714</td>\n",
       "      <td>3.36885714285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-15</th>\n",
       "      <td>3.36871428571429</td>\n",
       "      <td>3.3705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-16</th>\n",
       "      <td>3.36985714285714</td>\n",
       "      <td>3.37142857142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-17</th>\n",
       "      <td>3.36771428571429</td>\n",
       "      <td>3.36914285714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-18</th>\n",
       "      <td>3.36514285714286</td>\n",
       "      <td>3.36664285714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>988 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  PENUSD_buy       PENUSD_sell\n",
       "date                                          \n",
       "2022-01-03  3.98366666666667  3.98883333333333\n",
       "2022-01-04            3.9595             3.964\n",
       "2022-01-05             3.952  3.95633333333333\n",
       "2022-01-06  3.96716666666667  3.96966666666667\n",
       "2022-01-07  3.94516666666667  3.94816666666667\n",
       "...                      ...               ...\n",
       "2025-12-12  3.36685714285714  3.36885714285714\n",
       "2025-12-15  3.36871428571429            3.3705\n",
       "2025-12-16  3.36985714285714  3.37142857142857\n",
       "2025-12-17  3.36771428571429  3.36914285714286\n",
       "2025-12-18  3.36514285714286  3.36664285714286\n",
       "\n",
       "[988 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# date_raw was originally in Spanish, so we map months to English before parsing.\n",
    "month = {\n",
    "    \"Ene\":\"Jan\",\"Feb\":\"Feb\",\"Mar\":\"Mar\",\"Abr\":\"Apr\",\"May\":\"May\",\"Jun\":\"Jun\",\n",
    "    \"Jul\":\"Jul\",\"Ago\":\"Aug\",\"Set\":\"Sep\",\"Sep\":\"Sep\",\"Oct\":\"Oct\",\"Nov\":\"Nov\",\"Dic\":\"Dec\"\n",
    "}\n",
    "\n",
    "# Convert date_raw to datetime \n",
    "df[\"date_raw\"] = df[\"date_raw\"].replace(month, regex=True)\n",
    "df[\"date_raw\"] = pd.to_datetime(df[\"date_raw\"], format=\"%d.%b.%y\")  \n",
    "\n",
    "# Sort ascending\n",
    "df = df.rename(columns={\"date_raw\": \"date\"})\n",
    "df = df.sort_values(\"date\")\n",
    "\n",
    "# Set date as the index \n",
    "df = df.set_index(\"date\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2022-01-03    451.875183\n",
       "2022-01-04    451.723816\n",
       "2022-01-05    443.049774\n",
       "2022-01-06    442.633514\n",
       "2022-01-07    440.883606\n",
       "                 ...    \n",
       "2025-12-11    687.139526\n",
       "2025-12-12    679.751404\n",
       "2025-12-15    678.724426\n",
       "2025-12-16    676.869934\n",
       "2025-12-17    669.421936\n",
       "Name: SPY_close, Length: 994, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert FX bid/ask columns to numeric\n",
    "df[\"PENUSD_buy\"] = pd.to_numeric(df[\"PENUSD_buy\"], errors=\"coerce\")\n",
    "df[\"PENUSD_sell\"] = pd.to_numeric(df[\"PENUSD_sell\"], errors=\"coerce\")\n",
    "\n",
    "# Compute the mid-rate series\n",
    "mid_rate = (df[\"PENUSD_buy\"] + df[\"PENUSD_sell\"]) / 2\n",
    "mid_rate.name = \"PENUSD_mid\"\n",
    "\n",
    "# SPY close prices as a series \n",
    "spy_close = us_mkt[us_mkt[\"ticker\"] == \"SPY\"][\"close\"]\n",
    "spy_close.name = \"SPY_close\"\n",
    "\n",
    "spy_close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PENUSD_mid</th>\n",
       "      <th>SPY_close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>3.986250</td>\n",
       "      <td>451.875183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04</th>\n",
       "      <td>3.961750</td>\n",
       "      <td>451.723816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "      <td>3.954167</td>\n",
       "      <td>443.049774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-06</th>\n",
       "      <td>3.968417</td>\n",
       "      <td>442.633514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-07</th>\n",
       "      <td>3.946667</td>\n",
       "      <td>440.883606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-12</th>\n",
       "      <td>3.367857</td>\n",
       "      <td>679.751404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-15</th>\n",
       "      <td>3.369607</td>\n",
       "      <td>678.724426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-16</th>\n",
       "      <td>3.370643</td>\n",
       "      <td>676.869934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-17</th>\n",
       "      <td>3.368429</td>\n",
       "      <td>669.421936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-18</th>\n",
       "      <td>3.365893</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1025 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PENUSD_mid   SPY_close\n",
       "date                              \n",
       "2022-01-03    3.986250  451.875183\n",
       "2022-01-04    3.961750  451.723816\n",
       "2022-01-05    3.954167  443.049774\n",
       "2022-01-06    3.968417  442.633514\n",
       "2022-01-07    3.946667  440.883606\n",
       "...                ...         ...\n",
       "2025-12-12    3.367857  679.751404\n",
       "2025-12-15    3.369607  678.724426\n",
       "2025-12-16    3.370643  676.869934\n",
       "2025-12-17    3.368429  669.421936\n",
       "2025-12-18    3.365893         NaN\n",
       "\n",
       "[1025 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine both Series into a DataFrame \n",
    "yh_dfFrame = pd.concat([mid_rate, spy_close], axis=1)\n",
    "yh_dfFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.98625   , 451.87518311],\n",
       "       [  3.96175   , 451.72381592],\n",
       "       [  3.95416667, 443.04977417],\n",
       "       ...,\n",
       "       [  3.37064286, 683.6697998 ],\n",
       "       [  3.36842857, 681.61590576],\n",
       "       [  3.36589286, 681.02758789]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert both series to numpy arrays \n",
    "mid_np = mid_rate.to_numpy()\n",
    "spy_np = spy_close.to_numpy()\n",
    "\n",
    "# Truncate to the same length \n",
    "n = min(len(mid_np), len(spy_np))\n",
    "mid_np = mid_np[:n]\n",
    "spy_np = spy_np[:n]\n",
    "\n",
    "both = np.column_stack((mid_np, spy_np))\n",
    "both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "\n",
    "- In pandas, each series has a date index, so when we combine them, pandas matches values by date. If one series is missing a date, pandas keeps the date and fills the missing value with NaN. This is safer because it avoids matching values from different days.\n",
    "\n",
    "- In NumPy, converting a series to an array drops the date index and keeps only the values. To make both arrays the same size, we truncate to the shorter length (e.g., 988), which drops extra observations. After truncation, values are matched by position (row 1 with row 1), which can silently mix different dates and give incorrect results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.5 Dealing with Nulls \n",
    "Using `us_mkt`:\n",
    "\n",
    "1. Copy `us_mkt` to `us_mkt_nan`.\n",
    "2. Set 1% of `close` to NaN (fixed random seed).\n",
    "3. Create:\n",
    "   - `us_drop`: drop NaNs\n",
    "   - `us_fill`: fill NaNs with ticker-specific median close\n",
    "4. Compare shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-11</th>\n",
       "      <td>TLT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24388700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-11</th>\n",
       "      <td>GLD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8369000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-11</th>\n",
       "      <td>SPY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74303100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-11</th>\n",
       "      <td>EEM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57536400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-11</th>\n",
       "      <td>QQQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68295700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-14</th>\n",
       "      <td>GLD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13650700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-14</th>\n",
       "      <td>TLT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23157400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-14</th>\n",
       "      <td>QQQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80254400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-14</th>\n",
       "      <td>EEM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59439800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-14</th>\n",
       "      <td>SPY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123006300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ticker  close     volume\n",
       "date                               \n",
       "2022-01-11    TLT    NaN   24388700\n",
       "2022-01-11    GLD    NaN    8369000\n",
       "2022-01-11    SPY    NaN   74303100\n",
       "2022-01-11    EEM    NaN   57536400\n",
       "2022-01-11    QQQ    NaN   68295700\n",
       "2022-02-14    GLD    NaN   13650700\n",
       "2022-02-14    TLT    NaN   23157400\n",
       "2022-02-14    QQQ    NaN   80254400\n",
       "2022-02-14    EEM    NaN   59439800\n",
       "2022-02-14    SPY    NaN  123006300"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy us_mkt to us_mkt_nan\n",
    "us_mkt_nan = us_mkt.copy()\n",
    "\n",
    "# Set 1% of close to NaN (fixed random seed)\n",
    "np.random.seed(123)\n",
    "num_missing = int(len(us_mkt_nan) * 0.01)\n",
    "\n",
    "# Randomly select 1% of rows and set close to NaN\n",
    "random_rows = np.random.choice(us_mkt_nan.index, size=num_missing, replace=False)\n",
    "us_mkt_nan.loc[random_rows, \"close\"] = np.nan\n",
    "\n",
    "us_mkt_nan[us_mkt_nan[\"close\"].isna()].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN close\n",
    "us_drop = us_mkt_nan.dropna(subset=[\"close\"])\n",
    "\n",
    "# Fill NaN close with the median close for each ticker\n",
    "us_fill = us_mkt_nan.copy()\n",
    "us_fill[\"close\"] = us_fill[\"close\"].fillna(us_fill.groupby(\"ticker\")[\"close\"].transform(\"median\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4970, 3), (4730, 3), (4970, 3))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare shapes\n",
    "us_mkt_nan.shape, us_drop.shape, us_fill.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "us_mkt_nan keeps the same shape; us_drop has fewer rows; us_fill keeps the same shape after filling NaNs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.6 Duplicates \n",
    "\n",
    "1. Create `dup_df` by stacking the last 5 rows of `us_mkt` twice.\n",
    "2. Detect duplicates using `.duplicated()`.\n",
    "3. Remove them using `.drop_duplicates()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2025-12-17    False\n",
       "2025-12-17    False\n",
       "2025-12-17    False\n",
       "2025-12-17    False\n",
       "2025-12-17    False\n",
       "2025-12-17     True\n",
       "2025-12-17     True\n",
       "2025-12-17     True\n",
       "2025-12-17     True\n",
       "2025-12-17     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dup_df by stacking the last 5 rows twice\n",
    "dup_df = pd.concat([us_mkt.tail(5), us_mkt.tail(5)])\n",
    "\n",
    "# Detect duplicates\n",
    "dup_df.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-12-17</th>\n",
       "      <td>SPY</td>\n",
       "      <td>669.421936</td>\n",
       "      <td>110625200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-17</th>\n",
       "      <td>GLD</td>\n",
       "      <td>399.290009</td>\n",
       "      <td>10456900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-17</th>\n",
       "      <td>EEM</td>\n",
       "      <td>52.599998</td>\n",
       "      <td>35740800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-17</th>\n",
       "      <td>QQQ</td>\n",
       "      <td>599.637390</td>\n",
       "      <td>70654300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-17</th>\n",
       "      <td>TLT</td>\n",
       "      <td>87.459633</td>\n",
       "      <td>24668300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ticker       close     volume\n",
       "date                                    \n",
       "2025-12-17    SPY  669.421936  110625200\n",
       "2025-12-17    GLD  399.290009   10456900\n",
       "2025-12-17    EEM   52.599998   35740800\n",
       "2025-12-17    QQQ  599.637390   70654300\n",
       "2025-12-17    TLT   87.459633   24668300"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "dup_clean = dup_df.drop_duplicates()\n",
    "dup_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.8 Groupby \n",
    "\n",
    "\n",
    "Using `us_mkt`:\n",
    "\n",
    "1. Group by `ticker` and compute:\n",
    "   - mean close\n",
    "   - median close\n",
    "   - max volume\n",
    "2. Rename columns clearly.\n",
    "3. Sort by mean close descending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_close</th>\n",
       "      <th>median_close</th>\n",
       "      <th>max_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SPY</th>\n",
       "      <td>485.608584</td>\n",
       "      <td>460.739975</td>\n",
       "      <td>256611400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QQQ</th>\n",
       "      <td>411.276966</td>\n",
       "      <td>400.214539</td>\n",
       "      <td>198685800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLD</th>\n",
       "      <td>220.130422</td>\n",
       "      <td>187.864998</td>\n",
       "      <td>62025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TLT</th>\n",
       "      <td>91.395622</td>\n",
       "      <td>88.549709</td>\n",
       "      <td>131353500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEM</th>\n",
       "      <td>40.462350</td>\n",
       "      <td>39.107407</td>\n",
       "      <td>134225700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean_close  median_close  max_volume\n",
       "ticker                                      \n",
       "SPY     485.608584    460.739975   256611400\n",
       "QQQ     411.276966    400.214539   198685800\n",
       "GLD     220.130422    187.864998    62025000\n",
       "TLT      91.395622     88.549709   131353500\n",
       "EEM      40.462350     39.107407   134225700"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by ticker and compute closing price statistics\n",
    "# Mean and median are calculated over the close variable\n",
    "group_stats = us_mkt.groupby(\"ticker\").close.agg([\"mean\", \"median\"])\n",
    "\n",
    "# Add the maximum traded volume per ticker to the same DataFrame\n",
    "group_stats[\"max_volume\"] = us_mkt.groupby(\"ticker\").volume.max()\n",
    "\n",
    "# Rename columns for clarity and easier interpretation\n",
    "group_stats = group_stats.rename(columns={\n",
    "    \"mean\": \"mean_close\",\n",
    "    \"median\": \"median_close\"\n",
    "})\n",
    "\n",
    "# Sort assets by average closing price in descending order\n",
    "group_stats = group_stats.sort_values(\"mean_close\", ascending=False)\n",
    "\n",
    "group_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of results (3.3.8)\n",
    "\n",
    "The table summarizes the average behavior of closing prices and liquidity for each ETF over the 2022–2025 period.\n",
    "\n",
    "For all assets, the mean closing price is higher than the median, suggesting an upward trend, with relatively higher prices concentrated in more recent years.\n",
    "\n",
    "SPY and QQQ exhibit the highest average prices and the largest maximum trading volumes, reflecting their high liquidity and their importance as major U.S. equity ETFs. GLD shows a noticeable gap between the mean and the median, consistent with price spikes associated with its role as a safe-haven asset.\n",
    "\n",
    "In contrast, TLT displays lower and more stable prices, with relatively less dispersion, which is characteristic of fixed-income instruments. EEM presents lower average prices but relatively high trading volumes, indicating a high turnover rate.\n",
    "\n",
    "Overall, these results show that grouping by ticker allows for a clear comparison of price levels and liquidity across different types of financial assets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.9 Reshape \n",
    "\n",
    "1. Create a 1-row wide yh_dfFrame with last closes per ticker.\n",
    "2. Convert it to long format with `melt()` into columns: `ticker`, `last_close`.\n",
    "3. Pivot `us_mkt` into a wide table: index=`date`, columns=`ticker`, values=`close` (keep first 50 dates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ticker</th>\n",
       "      <th>EEM</th>\n",
       "      <th>GLD</th>\n",
       "      <th>QQQ</th>\n",
       "      <th>SPY</th>\n",
       "      <th>TLT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>close</th>\n",
       "      <td>52.599998</td>\n",
       "      <td>399.290009</td>\n",
       "      <td>599.63739</td>\n",
       "      <td>669.421936</td>\n",
       "      <td>87.459633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ticker        EEM         GLD        QQQ         SPY        TLT\n",
       "close   52.599998  399.290009  599.63739  669.421936  87.459633"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort observations by date and obtain the last available closing price per ticker\n",
    "last_close = (\n",
    "    us_mkt\n",
    "    .sort_values(\"date\")\n",
    "    .groupby(\"ticker\")\n",
    "    .close\n",
    "    .last()\n",
    ")\n",
    "\n",
    "last_close_wide = last_close.to_frame().T\n",
    "last_close_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of results (3.3.9.a)\n",
    "\n",
    "La tabla muestra un activo financiero y el valor corresponde al precio observado en la fecha más reciente de la base de datos.\n",
    "\n",
    "Este resumen reduce la dimensión temporal del dataset y presenta la información en formato wide, lo que facilita la comparación directa entre activos. Asi mismos sucede en 3.3.9.b y 3.3.9.c dado que el objetivo del ejercicio es ilustrar la transformación de formato long a wide y no analizar la serie completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>last_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EEM</td>\n",
       "      <td>52.599998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GLD</td>\n",
       "      <td>399.290009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QQQ</td>\n",
       "      <td>599.637390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPY</td>\n",
       "      <td>669.421936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TLT</td>\n",
       "      <td>87.459633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker  last_close\n",
       "0    EEM   52.599998\n",
       "1    GLD  399.290009\n",
       "2    QQQ  599.637390\n",
       "3    SPY  669.421936\n",
       "4    TLT   87.459633"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.3.9.B Change the DataFrame structure from wide to long format without losing information\n",
    "last_close_long = last_close_wide.melt(\n",
    "    var_name=\"ticker\",\n",
    "    value_name=\"last_close\"\n",
    ")\n",
    "\n",
    "last_close_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ticker</th>\n",
       "      <th>EEM</th>\n",
       "      <th>GLD</th>\n",
       "      <th>QQQ</th>\n",
       "      <th>SPY</th>\n",
       "      <th>TLT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>44.624966</td>\n",
       "      <td>168.330002</td>\n",
       "      <td>391.679474</td>\n",
       "      <td>451.875183</td>\n",
       "      <td>125.295334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04</th>\n",
       "      <td>44.470776</td>\n",
       "      <td>169.570007</td>\n",
       "      <td>386.599121</td>\n",
       "      <td>451.723816</td>\n",
       "      <td>124.774330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "      <td>43.745167</td>\n",
       "      <td>169.059998</td>\n",
       "      <td>374.722443</td>\n",
       "      <td>443.049774</td>\n",
       "      <td>124.097153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-06</th>\n",
       "      <td>43.944710</td>\n",
       "      <td>166.990005</td>\n",
       "      <td>374.459045</td>\n",
       "      <td>442.633514</td>\n",
       "      <td>124.418411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-07</th>\n",
       "      <td>44.343792</td>\n",
       "      <td>167.750000</td>\n",
       "      <td>370.402649</td>\n",
       "      <td>440.883606</td>\n",
       "      <td>123.524040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-10</th>\n",
       "      <td>44.343792</td>\n",
       "      <td>168.259995</td>\n",
       "      <td>370.646515</td>\n",
       "      <td>440.334930</td>\n",
       "      <td>123.827942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-11</th>\n",
       "      <td>45.368717</td>\n",
       "      <td>170.289993</td>\n",
       "      <td>376.214355</td>\n",
       "      <td>444.345642</td>\n",
       "      <td>124.652847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-12</th>\n",
       "      <td>46.121532</td>\n",
       "      <td>170.740005</td>\n",
       "      <td>377.706207</td>\n",
       "      <td>445.546936</td>\n",
       "      <td>124.175255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-13</th>\n",
       "      <td>45.468487</td>\n",
       "      <td>170.160004</td>\n",
       "      <td>368.257507</td>\n",
       "      <td>439.407928</td>\n",
       "      <td>125.278046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-14</th>\n",
       "      <td>45.450344</td>\n",
       "      <td>169.669998</td>\n",
       "      <td>370.548981</td>\n",
       "      <td>439.587677</td>\n",
       "      <td>123.385162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-18</th>\n",
       "      <td>44.643112</td>\n",
       "      <td>169.389999</td>\n",
       "      <td>361.324493</td>\n",
       "      <td>431.802734</td>\n",
       "      <td>121.648499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-19</th>\n",
       "      <td>44.833576</td>\n",
       "      <td>172.080002</td>\n",
       "      <td>357.355835</td>\n",
       "      <td>427.319061</td>\n",
       "      <td>122.490761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-20</th>\n",
       "      <td>45.096615</td>\n",
       "      <td>171.649994</td>\n",
       "      <td>352.714325</td>\n",
       "      <td>422.589569</td>\n",
       "      <td>123.246162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-21</th>\n",
       "      <td>44.443565</td>\n",
       "      <td>171.089996</td>\n",
       "      <td>342.934021</td>\n",
       "      <td>414.293762</td>\n",
       "      <td>124.713593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-24</th>\n",
       "      <td>43.817722</td>\n",
       "      <td>172.029999</td>\n",
       "      <td>344.503998</td>\n",
       "      <td>416.053192</td>\n",
       "      <td>123.688980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-25</th>\n",
       "      <td>43.736095</td>\n",
       "      <td>172.580002</td>\n",
       "      <td>336.517883</td>\n",
       "      <td>410.973572</td>\n",
       "      <td>123.489288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-26</th>\n",
       "      <td>43.182816</td>\n",
       "      <td>169.789993</td>\n",
       "      <td>335.991394</td>\n",
       "      <td>409.942535</td>\n",
       "      <td>121.995819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-27</th>\n",
       "      <td>42.683968</td>\n",
       "      <td>167.600006</td>\n",
       "      <td>332.607758</td>\n",
       "      <td>407.918274</td>\n",
       "      <td>124.236015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-28</th>\n",
       "      <td>42.892578</td>\n",
       "      <td>167.100006</td>\n",
       "      <td>343.041321</td>\n",
       "      <td>418.049042</td>\n",
       "      <td>124.279457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-31</th>\n",
       "      <td>44.298447</td>\n",
       "      <td>168.089996</td>\n",
       "      <td>354.011230</td>\n",
       "      <td>425.578552</td>\n",
       "      <td>123.636940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-01</th>\n",
       "      <td>44.570541</td>\n",
       "      <td>168.229996</td>\n",
       "      <td>356.419678</td>\n",
       "      <td>428.454193</td>\n",
       "      <td>123.226524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-02</th>\n",
       "      <td>44.497986</td>\n",
       "      <td>168.839996</td>\n",
       "      <td>359.315796</td>\n",
       "      <td>432.616241</td>\n",
       "      <td>123.643898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-03</th>\n",
       "      <td>44.026333</td>\n",
       "      <td>168.600006</td>\n",
       "      <td>344.747711</td>\n",
       "      <td>422.447632</td>\n",
       "      <td>122.678688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-04</th>\n",
       "      <td>44.135185</td>\n",
       "      <td>168.860001</td>\n",
       "      <td>349.096741</td>\n",
       "      <td>424.434052</td>\n",
       "      <td>120.870117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-07</th>\n",
       "      <td>44.044476</td>\n",
       "      <td>170.110001</td>\n",
       "      <td>346.288452</td>\n",
       "      <td>423.071899</td>\n",
       "      <td>120.948425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-08</th>\n",
       "      <td>44.470776</td>\n",
       "      <td>170.630005</td>\n",
       "      <td>350.179047</td>\n",
       "      <td>426.552856</td>\n",
       "      <td>120.139748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-09</th>\n",
       "      <td>45.169170</td>\n",
       "      <td>171.210007</td>\n",
       "      <td>357.599579</td>\n",
       "      <td>432.795990</td>\n",
       "      <td>120.365814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-10</th>\n",
       "      <td>44.869862</td>\n",
       "      <td>170.559998</td>\n",
       "      <td>349.506287</td>\n",
       "      <td>425.020508</td>\n",
       "      <td>118.452919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-11</th>\n",
       "      <td>44.189598</td>\n",
       "      <td>173.809998</td>\n",
       "      <td>338.419312</td>\n",
       "      <td>416.639648</td>\n",
       "      <td>120.209312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-14</th>\n",
       "      <td>43.881214</td>\n",
       "      <td>174.740005</td>\n",
       "      <td>338.838562</td>\n",
       "      <td>415.277496</td>\n",
       "      <td>118.713776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-15</th>\n",
       "      <td>44.833576</td>\n",
       "      <td>173.080002</td>\n",
       "      <td>347.263489</td>\n",
       "      <td>421.974609</td>\n",
       "      <td>117.365982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-16</th>\n",
       "      <td>45.160103</td>\n",
       "      <td>174.860001</td>\n",
       "      <td>347.175842</td>\n",
       "      <td>422.447632</td>\n",
       "      <td>118.061623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-17</th>\n",
       "      <td>44.634037</td>\n",
       "      <td>177.250000</td>\n",
       "      <td>336.849426</td>\n",
       "      <td>413.423553</td>\n",
       "      <td>118.939842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-18</th>\n",
       "      <td>44.189598</td>\n",
       "      <td>177.119995</td>\n",
       "      <td>333.007507</td>\n",
       "      <td>410.746521</td>\n",
       "      <td>120.191956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-22</th>\n",
       "      <td>43.563763</td>\n",
       "      <td>177.490005</td>\n",
       "      <td>329.662872</td>\n",
       "      <td>406.338562</td>\n",
       "      <td>120.504997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-23</th>\n",
       "      <td>43.055840</td>\n",
       "      <td>178.289993</td>\n",
       "      <td>321.218567</td>\n",
       "      <td>399.130768</td>\n",
       "      <td>118.844193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-24</th>\n",
       "      <td>42.166965</td>\n",
       "      <td>177.139999</td>\n",
       "      <td>332.012878</td>\n",
       "      <td>405.137238</td>\n",
       "      <td>118.922447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-25</th>\n",
       "      <td>42.946999</td>\n",
       "      <td>176.550003</td>\n",
       "      <td>337.161377</td>\n",
       "      <td>414.076202</td>\n",
       "      <td>119.009384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-28</th>\n",
       "      <td>42.384644</td>\n",
       "      <td>178.380005</td>\n",
       "      <td>338.165802</td>\n",
       "      <td>413.016846</td>\n",
       "      <td>121.617943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-01</th>\n",
       "      <td>41.822300</td>\n",
       "      <td>181.619995</td>\n",
       "      <td>332.987946</td>\n",
       "      <td>406.726440</td>\n",
       "      <td>123.024010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-02</th>\n",
       "      <td>41.894859</td>\n",
       "      <td>179.729996</td>\n",
       "      <td>338.575287</td>\n",
       "      <td>414.208618</td>\n",
       "      <td>118.818748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-03</th>\n",
       "      <td>41.305313</td>\n",
       "      <td>180.800003</td>\n",
       "      <td>333.738892</td>\n",
       "      <td>412.146545</td>\n",
       "      <td>120.028984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-04</th>\n",
       "      <td>40.470852</td>\n",
       "      <td>183.679993</td>\n",
       "      <td>328.902313</td>\n",
       "      <td>408.797974</td>\n",
       "      <td>122.101143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-07</th>\n",
       "      <td>38.956139</td>\n",
       "      <td>186.410004</td>\n",
       "      <td>316.772064</td>\n",
       "      <td>396.746948</td>\n",
       "      <td>121.169525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-08</th>\n",
       "      <td>39.083122</td>\n",
       "      <td>191.509995</td>\n",
       "      <td>315.299652</td>\n",
       "      <td>393.738922</td>\n",
       "      <td>119.950569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-09</th>\n",
       "      <td>40.189678</td>\n",
       "      <td>185.820007</td>\n",
       "      <td>326.649780</td>\n",
       "      <td>404.295410</td>\n",
       "      <td>118.775215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-10</th>\n",
       "      <td>39.436855</td>\n",
       "      <td>186.399994</td>\n",
       "      <td>323.022430</td>\n",
       "      <td>402.469788</td>\n",
       "      <td>117.068718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-11</th>\n",
       "      <td>38.611481</td>\n",
       "      <td>185.089996</td>\n",
       "      <td>316.323486</td>\n",
       "      <td>397.352325</td>\n",
       "      <td>117.460518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-14</th>\n",
       "      <td>37.677261</td>\n",
       "      <td>182.300003</td>\n",
       "      <td>310.248627</td>\n",
       "      <td>394.448364</td>\n",
       "      <td>114.717941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-15</th>\n",
       "      <td>37.731678</td>\n",
       "      <td>178.889999</td>\n",
       "      <td>319.980103</td>\n",
       "      <td>403.122528</td>\n",
       "      <td>114.517731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ticker            EEM         GLD         QQQ         SPY         TLT\n",
       "date                                                                 \n",
       "2022-01-03  44.624966  168.330002  391.679474  451.875183  125.295334\n",
       "2022-01-04  44.470776  169.570007  386.599121  451.723816  124.774330\n",
       "2022-01-05  43.745167  169.059998  374.722443  443.049774  124.097153\n",
       "2022-01-06  43.944710  166.990005  374.459045  442.633514  124.418411\n",
       "2022-01-07  44.343792  167.750000  370.402649  440.883606  123.524040\n",
       "2022-01-10  44.343792  168.259995  370.646515  440.334930  123.827942\n",
       "2022-01-11  45.368717  170.289993  376.214355  444.345642  124.652847\n",
       "2022-01-12  46.121532  170.740005  377.706207  445.546936  124.175255\n",
       "2022-01-13  45.468487  170.160004  368.257507  439.407928  125.278046\n",
       "2022-01-14  45.450344  169.669998  370.548981  439.587677  123.385162\n",
       "2022-01-18  44.643112  169.389999  361.324493  431.802734  121.648499\n",
       "2022-01-19  44.833576  172.080002  357.355835  427.319061  122.490761\n",
       "2022-01-20  45.096615  171.649994  352.714325  422.589569  123.246162\n",
       "2022-01-21  44.443565  171.089996  342.934021  414.293762  124.713593\n",
       "2022-01-24  43.817722  172.029999  344.503998  416.053192  123.688980\n",
       "2022-01-25  43.736095  172.580002  336.517883  410.973572  123.489288\n",
       "2022-01-26  43.182816  169.789993  335.991394  409.942535  121.995819\n",
       "2022-01-27  42.683968  167.600006  332.607758  407.918274  124.236015\n",
       "2022-01-28  42.892578  167.100006  343.041321  418.049042  124.279457\n",
       "2022-01-31  44.298447  168.089996  354.011230  425.578552  123.636940\n",
       "2022-02-01  44.570541  168.229996  356.419678  428.454193  123.226524\n",
       "2022-02-02  44.497986  168.839996  359.315796  432.616241  123.643898\n",
       "2022-02-03  44.026333  168.600006  344.747711  422.447632  122.678688\n",
       "2022-02-04  44.135185  168.860001  349.096741  424.434052  120.870117\n",
       "2022-02-07  44.044476  170.110001  346.288452  423.071899  120.948425\n",
       "2022-02-08  44.470776  170.630005  350.179047  426.552856  120.139748\n",
       "2022-02-09  45.169170  171.210007  357.599579  432.795990  120.365814\n",
       "2022-02-10  44.869862  170.559998  349.506287  425.020508  118.452919\n",
       "2022-02-11  44.189598  173.809998  338.419312  416.639648  120.209312\n",
       "2022-02-14  43.881214  174.740005  338.838562  415.277496  118.713776\n",
       "2022-02-15  44.833576  173.080002  347.263489  421.974609  117.365982\n",
       "2022-02-16  45.160103  174.860001  347.175842  422.447632  118.061623\n",
       "2022-02-17  44.634037  177.250000  336.849426  413.423553  118.939842\n",
       "2022-02-18  44.189598  177.119995  333.007507  410.746521  120.191956\n",
       "2022-02-22  43.563763  177.490005  329.662872  406.338562  120.504997\n",
       "2022-02-23  43.055840  178.289993  321.218567  399.130768  118.844193\n",
       "2022-02-24  42.166965  177.139999  332.012878  405.137238  118.922447\n",
       "2022-02-25  42.946999  176.550003  337.161377  414.076202  119.009384\n",
       "2022-02-28  42.384644  178.380005  338.165802  413.016846  121.617943\n",
       "2022-03-01  41.822300  181.619995  332.987946  406.726440  123.024010\n",
       "2022-03-02  41.894859  179.729996  338.575287  414.208618  118.818748\n",
       "2022-03-03  41.305313  180.800003  333.738892  412.146545  120.028984\n",
       "2022-03-04  40.470852  183.679993  328.902313  408.797974  122.101143\n",
       "2022-03-07  38.956139  186.410004  316.772064  396.746948  121.169525\n",
       "2022-03-08  39.083122  191.509995  315.299652  393.738922  119.950569\n",
       "2022-03-09  40.189678  185.820007  326.649780  404.295410  118.775215\n",
       "2022-03-10  39.436855  186.399994  323.022430  402.469788  117.068718\n",
       "2022-03-11  38.611481  185.089996  316.323486  397.352325  117.460518\n",
       "2022-03-14  37.677261  182.300003  310.248627  394.448364  114.717941\n",
       "2022-03-15  37.731678  178.889999  319.980103  403.122528  114.517731"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  3.3.9.C Reorganize the dataset from long to wide format: each row represents a date, each column represents a ticker, and the cell values correspond to closing prices\n",
    "us_wide_50 = (\n",
    "    us_mkt\n",
    "    .pivot(columns=\"ticker\", values=\"close\")\n",
    "    .sort_index()\n",
    "    .head(50)\n",
    ")\n",
    "\n",
    "us_wide_50"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
