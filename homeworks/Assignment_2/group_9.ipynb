{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment\n",
    "\n",
    "It is totally prohibited to use any kind of loop. You can use stackoverflow. If you copy codes from previous answers, explain each step. No explanation is `0 points`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Tuple\n",
    "\n",
    "\n",
    "\n",
    "1. Print the first item of the second item of `tuple1` object. **Hint: Use indexing**<br><br>\n",
    "2. Print the last item of the `tuple1` object.**Hint: Use indexing**<br><br>\n",
    "3. Change the value \"orange\" for \"pink grapefruit\". Comment the output. **Hint: Is it possible?** <br><br>\n",
    "4. Print the length of `tuple1`. **Hint: Length function**<br><br>\n",
    "5. Sum all the elements of tuple2 and describe your steps and explain each of them. **Hint: Use `map` function.**<br><br>\n",
    "6. Generate a new tuple object named as `tuple3` with the half values of `tuple2`. This tuple should be similar as `tuple2`, tuple of lists.  **Hint: Use `map` funciont.**<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple1 = (\"Orange\", [10, 20, 30], (5, 15, 25))\n",
    "tuple2 = ([7, 8], [9, 1], [10, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "#Sol 1.1 Renzo Update\n",
    "# 1) Print the first item of the second item of tuple1 (indexing)\n",
    "# This line defines the tuple named tuple1, containing a string, a list, and a nested tuple.\n",
    "tuple1 = (\"Orange\", [10, 20, 30], (5, 15, 25))\n",
    "# This line selects the second element of tuple1 (index 1), which is the list, and then selects its first element (index 0).\n",
    "print(tuple1[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 15, 25)\n"
     ]
    }
   ],
   "source": [
    "# 2) Print the last item of the tuple1 object (indexing)\n",
    "# This line accesses the last element of tuple1 using negative indexing (-1), which refers to the final item.\n",
    "print(tuple1[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pink grapefruit', [10, 20, 30], (5, 15, 25))\n"
     ]
    }
   ],
   "source": [
    "# 3) Change \"Orange\" to \"pink grapefruit\" and comment whether it is possible\n",
    "# This commented-out line illustrates an invalid operation, because tuples are immutable and do not support item reassignment.\n",
    "# tuple1[0] = \"pink grapefruit\"  # TypeError: tuples do not support item assignment.\n",
    "\n",
    "# This line constructs a new tuple by placing the replacement string first (as a 1-item tuple) and concatenating the remaining slice of tuple1.\n",
    "tuple1_new = (\"pink grapefruit\",) + tuple1[1:]\n",
    "\n",
    "# This line prints the newly created tuple, which reflects the desired change without modifying the original tuple1.\n",
    "print(tuple1_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# 4) Print the length of tuple1 (length function)\n",
    "# This line computes the number of top-level elements contained in tuple1 using the built-in len() function.\n",
    "print(len(tuple1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# 5) Sum all elements of tuple2 using map (no loops)\n",
    "# This line defines the tuple named tuple2, which contains three lists of integers.\n",
    "tuple2 = ([7, 8], [9, 1], [10, 7])\n",
    "\n",
    "# This line applies sum() to each list inside tuple2 using map, and then sums those intermediate results into one total.\n",
    "total = sum(map(sum, tuple2))\n",
    "\n",
    "# This line prints the final scalar total obtained from summing all numbers across the nested lists.\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([3.5, 4.0], [4.5, 0.5], [5.0, 3.5])\n"
     ]
    }
   ],
   "source": [
    "# 6) Create tuple3 with half the values of tuple2, preserving the same structure, using map\n",
    "# This line constructs tuple3 by mapping over each inner list, halving each element via a nested map, converting each mapped result into a list, and finally converting the outer result into a tuple.\n",
    "tuple3 = tuple(map(lambda lst: list(map(lambda x: x / 2, lst)), tuple2))\n",
    "\n",
    "# This line prints tuple3 to display the transformed structure (a tuple of lists) with each original value divided by two.\n",
    "print(tuple3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Lists\n",
    "1. Show the indices of the `np.nan` values  in the `f_list` list. We want to see this output: `The indices 0, 1, 4, 7 have np.nan values.` **Hint: Use print function and [f-strings](https://realpython.com/python-f-strings/) to insert the indices values.**<br><br>\n",
    "\n",
    "2. Replicate 4 times the values of the list `p2_list`. We expect an ouput like this: `[ 2 , 3, 4, 5, 2 , 3, 4, 5, 2 , 3, 4, 5, 2 , 3, 4, 5]`.  **Hint: Use multiplication function in `lists`and see the output.**<br><br>\n",
    "3. Print the length of `f_list`. **Hint: Length function**<br><br>\n",
    "4. Print `My teacher assistant is so boring.` using `text1` list. **Hint: Use the [`join` function](https://stackoverflow.com/questions/493819/why-is-it-string-joinlist-instead-of-list-joinstring)**<br><br>\n",
    "5. Print `My TA is so boring, but is very funny.` using `text1` list.**Hint: Use the `join` function, and `extend` method.**<br><br>\n",
    "6. Print <br>\n",
    "`The max value of values1 is 86 and is located in the 0 index. ` <br>\n",
    "`The min value of values1 is 0 and is located in the 7 index. ` <br> **Hint: Use the `f-string`, `min`, and `max` functions.**\n",
    "<br>\n",
    "7. Get two lists: `names` and `last_names` using `last_and_name` list. **Hint: Use `map` and `split`.**\n",
    "<br>\n",
    "8. Give only the last names of students who do not have email. Use the `emails` and `last_names` listt. **Hint: Use `map` and `split`.**\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_list = [np.nan , np.nan, \"Austria\", \"Germany\", np.nan, \"Pakistan\", \"np.nan\", np.nan ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = ['My', 'teacher', 'assistant', 'is', 'so', 'boring.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2_list = [ 2 , 3, 4, 5 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "values1 = [ 86, 86, 85, 85, 85, 83, 23, 0, 84, 1 ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These two lists a\n",
    "last_and_name = [ \"CORNEJO SANCHEZ, CHRISTIAN SANTOS\", \"ORELLANA QUISPE, CRISTIAN NASSER\", \"MORALES CHOQUEHUANCA, ANGELICA KARINA\", \"GUIMARAY RIBEYRO, JOSE ROBERTO\", \"CAMACHO GAVIDIA, ABEL FERNANDO\", \"TINTAYA ORIHUELA, MEIR ALVARO\", \"CHAVEZ MARTINEZ, JOSELIN ALEXANDRA\", \"FIGUEROA MURO, LEONEL ARTURO\", \"GOMEZ CRIBILLERO, JOSE FELIPE\", \"PALOMINO SEGUÍN, AFRANIA\", \"LUZON CUEVA, BIANCA MARIETTE\", \"SUAÑA ZEGARRA, ADRIAN ANDRE\", \"SOTO POMACHAGUA, DORKAS YOMIRA JHERMY\", \"FIORENTINO MARTINEZ, LADY ALY\", \"LAMA MAVILA, HECTOR ANDRE\", \"MEZA HINOJO, GUSTAVO\", \"LOZADA MURILLO, PERSEO MARCELO\", \"ZAMBRANO JIMENEZ, MIGUEL ALONZO\", \"JACOBS LUQUE, NICOLAS\", \"VIDAL VIDAL, ROCIO GABRIELA\", \"TORRES ANICAMA, JANE CAMILA\", \"LOPEZ ESTRADA, MARIA ELISA\", \"BOYCO ORAMS, ALEJANDRO\", \"DIAZ BERROSPI, KARLINE ROSMELI\", \"RIEGA ESCALANTE, STEPHY ROSARIO\", \"LEVANO TORRES, VALERIA CECILIA\", \"ESQUIVES BRAVO, SEBASTIAN RENATO\", \"PEREZ GONZALES, JUAN CARLOS\", \"OTERO MAGUIÑA, MARIANA\", \"CLAVO CAMPOS, ANDREA BRIZETH\", \"AGUILAR GARCIA, ERICK JOSUE\", \"CALDAS VELASQUEZ, JOSUE DANIEL\", \"SALAS NUÑEZ BORJA, FABIO MANUEL\", \"PIZARRO VILLANES, FERNANDA NICOLLE\", \"QUILLATUPA MORALES, ANGELA ADELINA\", \"HUANCAYA IDONE, CESAR DANTE\", \"CALVO PORTOCARRERO, GABRIELA ISABEL\", \"IBAÑEZ ABANTO, ANGEL MAURICIO\", \"MELÉNDEZ APONTE, JUAN DIEGO\", \"CRISTIAN SERRANO, ARONE\", \"HINOJOSA CAHUANA, PERCY ALBERTH\", \"ANGLAS GARCÍA, KEVIN ARTURO\", \"ALDAVE ACOSTA, CESAR ERNESTO\", \"NÚÑEZ HUAMÁN, CÉSAR AGUSTO\", \"OBREGON HUAMAN, DIANA EDITH\", \"SOTO PACHERRES, RODRIGO FRANCO\", \"INGARUCA RIVERA, GRETTEL ALEXANDRA\", \"ROJAS HUAMAN, ROSA ANGELA\", \"NEYRA SALAS, DANTE OMAR\", \"HUERTA ESPINOZA, YAJAIRA ALEXANDRA\", \"HUANCA MARTINEZ, JORGE ALBERTO\", \"FLORES CADILLO, ALEXIS\" ]\n",
    "emails = [\"cscornejo@pucp.edu.pe\", \"orellana.cn@pucp.edu.pe\", \"karina.morales@pucp.edu.pe\", \"a20083223@pucp.pe\", \"abel.camacho@pucp.pe\", \"mtintaya@pucp.edu.pe\", \"joselin.chavez@pucp.edu.pe\", \"a20105737@pucp.pe\", \"jfgomezc@pucp.pe\", \"afrania.palomino@pucp.pe\", \"luzon.bianca@pucp.pe\", \"adrian.suanaz@pucp.pe\", \"soto.y@pucp.edu.pe\", \"a20132766@pucp.pe\", \"andre.lama@pucp.edu.pe\", \"gustavo.meza@pucp.edu.pe\", \"pmlozada@pucp.edu.pe\", \"m.zambranoj@pucp.edu.pe\", \"nicolas.jacobs@pucp.edu.pe\", \"gvidal@pucp.edu.pe\", \"jane.torres@pucp.edu.pe\", \"m.lopez@pucp.edu.pe\", \"alejandro.boyco@pucp.edu.pe\", \"a20167070@pucp.edu.pe\", \"riega.stephy@pucp.edu.pe\", \"vlevanot@pucp.edu.pe\", \"sesquives@pucp.edu.pe\", \"perez.juanc@pucp.edu.pe\", \"mariana.otero@pucp.edu.pe\", \"aclavo@pucp.edu.pe\", \"a20182474@pucp.edu.pe\", \"josue.caldas@pucp.edu.pe\", \"fabio.salas@pucp.edu.pe\", \"fernanda.pizarro@pucp.edu.pe\", \"aquillatupa@pucp.pe\", \"\", \"\", \"\", \"\", \"\", \"f0873079@pucp.edu.pe\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"flores.alexis@pucp.edu.pe\", ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The indices 0, 1, 4, 7 have np.nan values.\n",
      "[2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5]\n",
      "8\n",
      "My teacher assistant is so boring.\n",
      "My TA is so boring. but is very funny.\n",
      "The max value of values1 is 86 and is located in the 0 index.\n",
      "The min value of values1 is 0 and is located in the 7 index.\n",
      "['HUANCAYA IDONE', 'CALVO PORTOCARRERO', 'IBAÑEZ ABANTO', 'MELÉNDEZ APONTE', 'CRISTIAN SERRANO', 'ANGLAS GARCÍA', 'ALDAVE ACOSTA', 'NÚÑEZ HUAMÁN', 'OBREGON HUAMAN', 'SOTO PACHERRES', 'INGARUCA RIVERA', 'ROJAS HUAMAN', 'NEYRA SALAS', 'HUERTA ESPINOZA', 'HUANCA MARTINEZ']\n"
     ]
    }
   ],
   "source": [
    "#Sol 1.2 Carmen Update:\n",
    "# 1\n",
    "# Get index-value pairs, filter only np.nan values, and extract indices\n",
    "nan_indices = list(map(lambda x: x[0], filter(lambda x: x[1] is np.nan, enumerate(f_list))))\n",
    "\n",
    "# Print indices using f-string\n",
    "print(f\"The indices {nan_indices[0]}, {nan_indices[1]}, {nan_indices[2]}, {nan_indices[3]} have np.nan values.\")\n",
    "\n",
    "#2\n",
    "# Multiply the list to repeat its elements\n",
    "replicated_list = p2_list * 4\n",
    "\n",
    "# Print the replicated list\n",
    "print(replicated_list)\n",
    "\n",
    "#3\n",
    "# Use len() to get the number of elements in the list\n",
    "print(len(f_list))\n",
    "\n",
    "#4\n",
    "# Join list elements into a single string separated by spaces\n",
    "sentence = \" \".join(text1)\n",
    "\n",
    "# Print the sentence\n",
    "print(sentence)\n",
    "\n",
    "#5\n",
    "# Create a copy of the original list\n",
    "text1_extended = text1.copy()\n",
    "\n",
    "# Replace 'teacher assistant' with 'TA'\n",
    "text1_extended[1:3] = [\"TA\"]\n",
    "\n",
    "# Add extra words to the list\n",
    "text1_extended.extend([\"but\", \"is\", \"very\", \"funny.\"])\n",
    "\n",
    "# Join list into a sentence\n",
    "sentence2 = \" \".join(text1_extended)\n",
    "\n",
    "# Print the sentence\n",
    "print(sentence2)\n",
    "\n",
    "#6\n",
    "# Get maximum value from the list\n",
    "max_value = max(values1)\n",
    "\n",
    "# Get minimum value from the list\n",
    "min_value = min(values1)\n",
    "\n",
    "# Print max value and its index\n",
    "print(f\"The max value of values1 is {max_value} and is located in the {values1.index(max_value)} index.\")\n",
    "\n",
    "# Print min value and its index\n",
    "print(f\"The min value of values1 is {min_value} and is located in the {values1.index(min_value)} index.\")\n",
    "\n",
    "\n",
    "#7\n",
    "# Split each full name into last names and first names\n",
    "split_names = list(map(lambda x: x.split(\", \"), last_and_name))\n",
    "\n",
    "# Extract last names\n",
    "last_names = list(map(lambda x: x[0], split_names))\n",
    "\n",
    "# Extract first names\n",
    "names = list(map(lambda x: x[1], split_names))\n",
    "\n",
    "#8\n",
    "# Pair last names with emails, filter empty emails, and extract last names\n",
    "no_email_last_names = list(\n",
    "    map(\n",
    "        lambda x: x[0],\n",
    "        filter(lambda x: x[1] == \"\", zip(last_names, emails))\n",
    "    )\n",
    ")\n",
    "\n",
    "# Print last names without email\n",
    "print(no_email_last_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Strings\n",
    "\n",
    "\n",
    "1. Drop the duplicated blank spaces in `str1`. Do not use the regular expresions. Do not use the code shown in class. Explain your steps.**Hint: Use `split` method and `join` function.**\n",
    "\n",
    "2. Get the number of letters in the string .**Hint: Use `len`function.**\n",
    "\n",
    "3. Get the number of blank spaces (all of them) in the string .**Hint: Use `len`function.**\n",
    "\n",
    "4. Get the position of `@` in each string in the emails list. **Hint: Use `map`function and `find` method.**\n",
    "\n",
    "5. Identifies if exists `.edu.`  in each string in the `emails` list. Get a list of Booleans. **Hint: Use `map`function and `find` method.**\n",
    "\n",
    "6. Get all the strings before the first dot `.`in each string in the `emails` list. Identifies how many of them has `@`. **Hint: Use `map`function and `find` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = 'I am                            too                                                        old'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = [\"cscornejo@pucp.edu.pe\", \"orellana.cn@pucp.edu.pe\", \"karina.morales@pucp.edu.pe\", \"a20083223@pucp.pe\", \"abel.camacho@pucp.pe\", \"mtintaya@pucp.edu.pe\", \"joselin.chavez@pucp.edu.pe\", \"a20105737@pucp.pe\", \"jfgomezc@pucp.pe\", \"afrania.palomino@pucp.pe\", \"luzon.bianca@pucp.pe\", \"adrian.suanaz@pucp.pe\", \"soto.y@pucp.edu.pe\", \"a20132766@pucp.pe\", \"andre.lama@pucp.edu.pe\", \"gustavo.meza@pucp.edu.pe\", \"pmlozada@pucp.edu.pe\", \"m.zambranoj@pucp.edu.pe\", \"nicolas.jacobs@pucp.edu.pe\", \"gvidal@pucp.edu.pe\", \"jane.torres@pucp.edu.pe\", \"m.lopez@pucp.edu.pe\", \"alejandro.boyco@pucp.edu.pe\", \"a20167070@pucp.edu.pe\", \"riega.stephy@pucp.edu.pe\", \"vlevanot@pucp.edu.pe\", \"sesquives@pucp.edu.pe\", \"perez.juanc@pucp.edu.pe\", \"mariana.otero@pucp.edu.pe\", \"aclavo@pucp.edu.pe\", \"a20182474@pucp.edu.pe\", \"josue.caldas@pucp.edu.pe\", \"fabio.salas@pucp.edu.pe\", \"fernanda.pizarro@pucp.edu.pe\", \"aquillatupa@pucp.pe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am too old'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sol: 1.3 Kevin update\n",
    "#1\n",
    "# split() separates the string into words ignoring multiple spaces\n",
    "# join() rebuilds the string using only one space between words\n",
    "clean_str1 = \" \".join(str1.split())\n",
    "\n",
    "clean_str1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2\n",
    "# Remove all blank spaces\n",
    "# len() counts only the letters\n",
    "num_letters = len(clean_str1.replace(\" \", \"\"))\n",
    "\n",
    "num_letters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3\n",
    "# Total length of the original string\n",
    "# Minus length after removing spaces\n",
    "# The difference is the number of blank spaces\n",
    "num_spaces = len(str1) - len(str1.replace(\" \", \"\"))\n",
    "\n",
    "num_spaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9,\n",
       " 11,\n",
       " 14,\n",
       " 9,\n",
       " 12,\n",
       " 8,\n",
       " 14,\n",
       " 9,\n",
       " 8,\n",
       " 16,\n",
       " 12,\n",
       " 13,\n",
       " 6,\n",
       " 9,\n",
       " 10,\n",
       " 12,\n",
       " 8,\n",
       " 11,\n",
       " 14,\n",
       " 6,\n",
       " 11,\n",
       " 7,\n",
       " 15,\n",
       " 9,\n",
       " 12,\n",
       " 8,\n",
       " 9,\n",
       " 11,\n",
       " 13,\n",
       " 6,\n",
       " 9,\n",
       " 12,\n",
       " 11,\n",
       " 16,\n",
       " 11]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4\n",
    "# map() applies find(\"@\") to each email\n",
    "# find() returns the index of '@' or -1 if not found\n",
    "at_positions = list(map(lambda x: x.find(\"@\"), emails))\n",
    "\n",
    "at_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5\n",
    "# find(\".edu.\") returns -1 if the substring does not exist\n",
    "# != -1 converts the result into a Boolean value\n",
    "has_edu = list(map(lambda x: x.find(\".edu.\") != -1, emails))\n",
    "\n",
    "has_edu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6\n",
    "# split(\".\", 1) splits only at the first dot\n",
    "# [0] keeps the part before the dot\n",
    "before_dot = list(map(lambda x: x.split(\".\", 1)[0], emails))\n",
    "\n",
    "before_dot\n",
    "\n",
    "# \"@\" in x returns True or False\n",
    "# sum() counts True as 1 and False as 0\n",
    "count_at_before_dot = sum(map(lambda x: \"@\" in x, before_dot))\n",
    "\n",
    "count_at_before_dot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance\n",
      "  Downloading yfinance-1.0-py2.py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from yfinance) (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from yfinance) (2.1.3)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\user\\anaconda3\\lib\\site-packages (from yfinance) (2.32.3)\n",
      "Collecting multitasking>=0.0.7 (from yfinance)\n",
      "  Downloading multitasking-0.0.12.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from yfinance) (4.3.7)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from yfinance) (2024.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from yfinance) (2.4.2)\n",
      "Collecting peewee>=3.16.2 (from yfinance)\n",
      "  Downloading peewee-3.19.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from yfinance) (4.14.2)\n",
      "Collecting curl_cffi<0.14,>=0.7 (from yfinance)\n",
      "  Downloading curl_cffi-0.13.0-cp39-abi3-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from yfinance) (5.29.3)\n",
      "Collecting websockets>=13.0 (from yfinance)\n",
      "  Downloading websockets-15.0.1-cp313-cp313-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: cffi>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from curl_cffi<0.14,>=0.7->yfinance) (1.17.1)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from curl_cffi<0.14,>=0.7->yfinance) (2025.11.12)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\anaconda3\\lib\\site-packages (from cffi>=1.12.0->curl_cffi<0.14,>=0.7->yfinance) (2.21)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (2.5.0)\n",
      "Downloading yfinance-1.0-py2.py3-none-any.whl (127 kB)\n",
      "Downloading curl_cffi-0.13.0-cp39-abi3-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 74.4 MB/s eta 0:00:00\n",
      "Downloading peewee-3.19.0-py3-none-any.whl (411 kB)\n",
      "Downloading websockets-15.0.1-cp313-cp313-win_amd64.whl (176 kB)\n",
      "Building wheels for collected packages: multitasking\n",
      "  Building wheel for multitasking (setup.py): started\n",
      "  Building wheel for multitasking (setup.py): finished with status 'done'\n",
      "  Created wheel for multitasking: filename=multitasking-0.0.12-py3-none-any.whl size=15618 sha256=c82df569d0a8cfca790b730e925cd707e87c731b5866d989b3383c6b4e612a1f\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\1e\\df\\0f\\e2bbb22d689b30c681feb5410ab64a2523437b34c8ecfc6476\n",
      "Successfully built multitasking\n",
      "Installing collected packages: peewee, multitasking, websockets, curl_cffi, yfinance\n",
      "\n",
      "   ---------------------------------------- 0/5 [peewee]\n",
      "   ---------------- ----------------------- 2/5 [websockets]\n",
      "   ------------------------ --------------- 3/5 [curl_cffi]\n",
      "   -------------------------------- ------- 4/5 [yfinance]\n",
      "   ---------------------------------------- 5/5 [yfinance]\n",
      "\n",
      "Successfully installed curl_cffi-0.13.0 multitasking-0.0.12 peewee-3.19.0 websockets-15.0.1 yfinance-1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'multitasking' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'multitasking'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "START = \"2022-01-01\"\n",
    "END = \"2025-12-18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        date ticker      close    volume\n",
       " 0 2022-01-03    EEM  44.624969  27572700\n",
       " 1 2022-01-04    EEM  44.470776  24579500\n",
       " 2 2022-01-05    EEM  43.745167  46425100\n",
       " 3 2022-01-06    EEM  43.944706  34288700\n",
       " 4 2022-01-07    EEM  44.343788  32640900,\n",
       " (4970, 4))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Yahoo Finance via yfinance: US tickers (real market yh_df) ---\n",
    "tickers = [\"SPY\", \"QQQ\", \"TLT\", \"GLD\", \"EEM\"]\n",
    "# SPY : S&P 500 index\n",
    "# QQQ : Nasdaq-100 index\n",
    "# TLT : U.S. Treasury bonds with 20+ year maturity\n",
    "# GLD : Physical gold prices\n",
    "# EEM : MSCI Emerging Markets index\n",
    "\n",
    "try:\n",
    "    import yfinance as yf\n",
    "except Exception as e:\n",
    "    yf = None\n",
    "    print(\"Could not import yfinance:\", type(e).__name__, str(e))\n",
    "\n",
    "if yf is not None:\n",
    "    try:\n",
    "        yh_df = yf.download(tickers, start=START, end=END, auto_adjust=True, progress=False)\n",
    "    except Exception as e:\n",
    "        yh_df = pd.DataFrame()\n",
    "        print(\"yfinance download failed:\", type(e).__name__, str(e))\n",
    "else:\n",
    "    yh_df = pd.DataFrame()\n",
    "\n",
    "# Convert to long format: date, ticker, close, volume\n",
    "if isinstance(yh_df, pd.DataFrame) and yh_df.shape[0] > 0:\n",
    "    if isinstance(yh_df.columns, pd.MultiIndex):\n",
    "        close = yh_df[\"Close\"].copy()\n",
    "        vol = yh_df[\"Volume\"].copy()\n",
    "    else:\n",
    "        close = yh_df[[\"Close\"]].rename(columns={\"Close\": tickers[0]})\n",
    "        vol = yh_df[[\"Volume\"]].rename(columns={\"Volume\": tickers[0]})\n",
    "\n",
    "    close.index.name = \"date\"\n",
    "    vol.index.name = \"date\"\n",
    "\n",
    "    us_close_long = close.reset_index().melt(id_vars=\"date\", var_name=\"ticker\", value_name=\"close\")\n",
    "    us_vol_long = vol.reset_index().melt(id_vars=\"date\", var_name=\"ticker\", value_name=\"volume\")\n",
    "    us_mkt = us_close_long.merge(us_vol_long, on=[\"date\",\"ticker\"], how=\"inner\").dropna(subset=[\"close\"])\n",
    "else:\n",
    "    us_mkt = pd.DataFrame(columns=[\"date\",\"ticker\",\"close\",\"volume\"])\n",
    "\n",
    "us_mkt.head(), us_mkt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_raw</th>\n",
       "      <th>PENUSD_buy</th>\n",
       "      <th>PENUSD_sell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03.Ene.22</td>\n",
       "      <td>3.98366666666667</td>\n",
       "      <td>3.98883333333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04.Ene.22</td>\n",
       "      <td>3.9595</td>\n",
       "      <td>3.964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05.Ene.22</td>\n",
       "      <td>3.952</td>\n",
       "      <td>3.95633333333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06.Ene.22</td>\n",
       "      <td>3.96716666666667</td>\n",
       "      <td>3.96966666666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07.Ene.22</td>\n",
       "      <td>3.94516666666667</td>\n",
       "      <td>3.94816666666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>12.Dic.25</td>\n",
       "      <td>3.36685714285714</td>\n",
       "      <td>3.36885714285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>15.Dic.25</td>\n",
       "      <td>3.36871428571429</td>\n",
       "      <td>3.3705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>16.Dic.25</td>\n",
       "      <td>3.36985714285714</td>\n",
       "      <td>3.37142857142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>17.Dic.25</td>\n",
       "      <td>3.36771428571429</td>\n",
       "      <td>3.36914285714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>18.Dic.25</td>\n",
       "      <td>3.36514285714286</td>\n",
       "      <td>3.36664285714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>988 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      date_raw        PENUSD_buy       PENUSD_sell\n",
       "0    03.Ene.22  3.98366666666667  3.98883333333333\n",
       "1    04.Ene.22            3.9595             3.964\n",
       "2    05.Ene.22             3.952  3.95633333333333\n",
       "3    06.Ene.22  3.96716666666667  3.96966666666667\n",
       "4    07.Ene.22  3.94516666666667  3.94816666666667\n",
       "..         ...               ...               ...\n",
       "983  12.Dic.25  3.36685714285714  3.36885714285714\n",
       "984  15.Dic.25  3.36871428571429            3.3705\n",
       "985  16.Dic.25  3.36985714285714  3.37142857142857\n",
       "986  17.Dic.25  3.36771428571429  3.36914285714286\n",
       "987  18.Dic.25  3.36514285714286  3.36664285714286\n",
       "\n",
       "[988 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- BCRP: daily exchange rate PEN/USD buy & sell (official API) ---\n",
    "# Codes:\n",
    "# - PD04637PD: USD/PEN (buy)\n",
    "# - PD04638PD: USD/PEN (sell)\n",
    "\n",
    "import requests\n",
    "\n",
    "bcrp_url = f\"https://estadisticas.bcrp.gob.pe/estadisticas/series/api/PD04637PD-PD04638PD/json/{START}/{END}/esp\"\n",
    "try:\n",
    "    r = requests.get(bcrp_url, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    bcrp_obj = r.json()\n",
    "except Exception as e:\n",
    "    bcrp_obj = {\"periods\": []}\n",
    "    print(\"BCRP request failed:\", type(e).__name__, str(e))\n",
    "\n",
    "periods = bcrp_obj.get(\"periods\", [])\n",
    "rows = []\n",
    "for p in periods:\n",
    "    name = p.get(\"name\")\n",
    "    vals = p.get(\"values\", [])\n",
    "    if isinstance(vals, str):\n",
    "        vals = [vals]\n",
    "    if name is None or not isinstance(vals, list) or len(vals) < 2:\n",
    "        continue\n",
    "    rows.append([name, vals[0], vals[1]])\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"date_raw\", \"PENUSD_buy\", \"PENUSD_sell\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.2 From NumPy array to Series\n",
    "\n",
    "Using `us_mkt`:\n",
    "\n",
    "1. Filter to `ticker == \"SPY\"`.\n",
    "2. Take `close` as a NumPy array.\n",
    "3. Create a Series indexed by `date` named `SPY_close_series`.\n",
    "4. Compute the mean, minimum, and maximum using Series methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 485.608584705253, Min: 341.18206787109375, Max: 687.1395263671875\n"
     ]
    }
   ],
   "source": [
    "# This line filters the market DataFrame to keep only observations where the ticker is 'SPY'.\n",
    "spy_df = us_mkt.loc[us_mkt[\"ticker\"].eq(\"SPY\")].copy()\n",
    "\n",
    "# This line converts the 'close' column from the filtered DataFrame into a NumPy array.\n",
    "spy_close_np = spy_df[\"close\"].to_numpy()\n",
    "\n",
    "# This line constructs a pandas Series using dates as the index and the NumPy array as values, naming it explicitly.\n",
    "SPY_close_series = pd.Series(spy_close_np, index=spy_df[\"date\"], name=\"SPY_close_series\")\n",
    "\n",
    "# This line computes the mean of the Series using pandas' Series method (which is NaN-aware).\n",
    "spy_mean = SPY_close_series.mean()\n",
    "\n",
    "# This line computes the minimum value of the Series using pandas' Series method.\n",
    "spy_min = SPY_close_series.min()\n",
    "\n",
    "# This line computes the maximum value of the Series using pandas' Series method.\n",
    "spy_max = SPY_close_series.max()\n",
    "\n",
    "# This line prints the summary statistics in a single, readable output.\n",
    "print(f\"Mean: {spy_mean}, Min: {spy_min}, Max: {spy_max}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.3 From Dictionary to Series\n",
    "\n",
    "Using `us_mkt`:\n",
    "\n",
    "1. Compute the **last available close** for each ticker in `tickers`.\n",
    "2. Store the result in a dictionary of the form `{ticker: last_close}`.\n",
    "3. Convert the dictionary to a Series and sort it in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SPY    669.421936\n",
       "QQQ    599.637390\n",
       "GLD    399.290009\n",
       "TLT     87.459633\n",
       "EEM     52.599998\n",
       "Name: last_close, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This line sorts the DataFrame by date to ensure that 'last' refers to the most recent observation per ticker.\n",
    "us_sorted = us_mkt.sort_values(\"date\")\n",
    "\n",
    "# This line extracts the last available close per ticker by grouping and taking the final close in each group.\n",
    "last_close_per_ticker = us_sorted.groupby(\"ticker\")[\"close\"].last()\n",
    "\n",
    "# This line converts the resulting Series into a dictionary of the form {ticker: last_close}.\n",
    "last_close_dict = last_close_per_ticker.to_dict()\n",
    "\n",
    "# This line converts the dictionary back into a pandas Series for convenient sorting and analysis.\n",
    "last_close_series = pd.Series(last_close_dict, name=\"last_close\")\n",
    "\n",
    "# This line sorts the Series in descending order, as requested.\n",
    "last_close_series_sorted = last_close_series.sort_values(ascending=False)\n",
    "\n",
    "# This line displays the final sorted Series.\n",
    "last_close_series_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.4 Series vs NumPy\n",
    "\n",
    "**Goal:** show why pandas alignment matters.\n",
    "\n",
    "1. Create two Series indexed by date:\n",
    "   - Mid-rate from `df`\n",
    "   - SPY close from `us_mkt`\n",
    "2. Combine them into a single DataFrame (pandas aligns on dates).\n",
    "3. Separately, build two NumPy arrays by truncating them to the same length.\n",
    "4. In Markdown, explain why alignment is safer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_6492\\2809656145.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_dates = pd.to_datetime(df[\"date_raw\"], errors=\"coerce\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PENUSD_mid</th>\n",
       "      <th>SPY_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-02-01</th>\n",
       "      <td>3.874500</td>\n",
       "      <td>428.454193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-02</th>\n",
       "      <td>3.854500</td>\n",
       "      <td>432.616272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-03</th>\n",
       "      <td>3.859667</td>\n",
       "      <td>422.447632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-04</th>\n",
       "      <td>3.865417</td>\n",
       "      <td>424.434052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-07</th>\n",
       "      <td>3.842167</td>\n",
       "      <td>423.071899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PENUSD_mid   SPY_close\n",
       "2022-02-01    3.874500  428.454193\n",
       "2022-02-02    3.854500  432.616272\n",
       "2022-02-03    3.859667  422.447632\n",
       "2022-02-04    3.865417  424.434052\n",
       "2022-02-07    3.842167  423.071899"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This line converts the raw BCRP date strings into pandas datetime to enable robust index alignment.\n",
    "df_dates = pd.to_datetime(df[\"date_raw\"], errors=\"coerce\")\n",
    "\n",
    "# This line converts the buy column to numeric, coercing any non-numeric entries into NaN.\n",
    "buy = pd.to_numeric(df[\"PENUSD_buy\"], errors=\"coerce\")\n",
    "\n",
    "# This line converts the sell column to numeric, coercing any non-numeric entries into NaN.\n",
    "sell = pd.to_numeric(df[\"PENUSD_sell\"], errors=\"coerce\")\n",
    "\n",
    "# This line computes the mid exchange rate as the arithmetic mean of buy and sell rates.\n",
    "mid = (buy + sell) / 2\n",
    "\n",
    "# This line constructs a mid-rate Series indexed by date, which is required for safe calendar-based alignment.\n",
    "mid_rate_series = pd.Series(mid.to_numpy(), index=df_dates, name=\"PENUSD_mid\")\n",
    "\n",
    "# This line removes missing dates (NaT) from the index to avoid invalid alignment keys.\n",
    "mid_rate_series = mid_rate_series.loc[mid_rate_series.index.notna()]\n",
    "\n",
    "# This line collapses duplicate dates by keeping the last observation per date, ensuring a unique index.\n",
    "mid_rate_series = mid_rate_series.groupby(level=0).last()\n",
    "\n",
    "# This line filters the US market dataset to keep only SPY observations.\n",
    "spy_df2 = us_mkt.loc[us_mkt[\"ticker\"].eq(\"SPY\")].copy()\n",
    "\n",
    "# This line constructs a SPY close Series indexed by date, enabling index-based alignment.\n",
    "spy_close_series = pd.Series(spy_df2[\"close\"].to_numpy(), index=spy_df2[\"date\"], name=\"SPY_close\")\n",
    "\n",
    "# This line removes missing dates (NaT) from the SPY index to avoid invalid alignment keys.\n",
    "spy_close_series = spy_close_series.loc[spy_close_series.index.notna()]\n",
    "\n",
    "# This line collapses duplicate SPY dates by keeping the last observation per date, ensuring a unique index.\n",
    "spy_close_series = spy_close_series.groupby(level=0).last()\n",
    "\n",
    "# This line concatenates both Series into a single DataFrame, aligning observations strictly by their date indices.\n",
    "aligned_df = pd.concat([mid_rate_series, spy_close_series], axis=1)\n",
    "\n",
    "# This line drops rows where at least one of the two aligned variables is missing.\n",
    "aligned_df_clean = aligned_df.dropna()\n",
    "\n",
    "# This line extracts the aligned mid-rate values as a NumPy array after ensuring correct calendar alignment.\n",
    "mid_np_aligned = aligned_df_clean[\"PENUSD_mid\"].to_numpy()\n",
    "\n",
    "# This line extracts the aligned SPY close values as a NumPy array after ensuring correct calendar alignment.\n",
    "spy_np_aligned = aligned_df_clean[\"SPY_close\"].to_numpy()\n",
    "\n",
    "# This line displays the first few aligned observations for verification.\n",
    "aligned_df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why pandas alignment is safer than NumPy truncation\n",
    "\n",
    "Pandas alignment is safer because it matches observations based on their index values, in this case calendar dates, rather than relying on positional correspondence. When two Series are combined using their date indices, pandas ensures that each observation refers to the same point in time before any comparison or transformation is performed.\n",
    "\n",
    "By contrast, truncating NumPy arrays to a common length only guarantees that both arrays have the same shape, but it does not ensure that element *i* in one array corresponds to the same date as element *i* in the other. This positional matching can silently introduce temporal mismatches, particularly when datasets contain missing dates, duplicated observations, or different sampling frequencies.\n",
    "\n",
    "Therefore, index-based alignment in pandas provides a more robust and conceptually correct approach for financial and time-series analysis, as it preserves the economic meaning of each observation and prevents misleading statistical results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.6 Dealing with Nulls\n",
    "\n",
    "Using `us_mkt`:\n",
    "\n",
    "1. Copy `us_mkt` to `us_mkt_nan`.\n",
    "2. Set 1% of `close` values to NaN (fixed random seed).\n",
    "3. Create:\n",
    "   - `us_drop`: drop NaN values\n",
    "   - `us_fill`: fill NaNs with ticker-specific median close\n",
    "4. Compare dataset shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.7 Duplicates\n",
    "\n",
    "1. Create `dup_df` by stacking the last 5 rows of `us_mkt` twice.\n",
    "2. Detect duplicates using `.duplicated()`.\n",
    "3. Remove them using `.drop_duplicates()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.8 Groupby\n",
    "\n",
    "Using `us_mkt`:\n",
    "\n",
    "1. Group by `ticker` and compute:\n",
    "   - mean close\n",
    "   - median close\n",
    "   - max volume\n",
    "2. Rename columns clearly.\n",
    "3. Sort by mean close in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.9 Reshape\n",
    "\n",
    "1. Create a 1-row wide DataFrame with last closes per ticker.\n",
    "2. Convert it to long format using `melt()` into columns: `ticker`, `last_close`.\n",
    "3. Pivot `us_mkt` into a wide table with:\n",
    "   - index = `date`\n",
    "   - columns = `ticker`\n",
    "   - values = `close`\n",
    "   (keep the first 50 dates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
