{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27bcf19e",
   "metadata": {},
   "source": [
    "## Lecture 4 — Data (BCRP + Yahoo) + Plots + Stats + VaR \n",
    "\n",
    "Reproduce the key parts of the lecture notebook using:\n",
    "\n",
    "- **Peru (BCRP API)**: `PD04637PD`, `PD04639PD`, `PD04704XD`, `PD04701XD`  \n",
    "  *(FX + commodities exactly as in the notebook)*\n",
    "- **USA (yfinance)**: `SPY`, `TLT`, `GLD`\n",
    "\n",
    "**Deliverables**\n",
    "- Multiple **plots** (including **one with annotations**)  \n",
    "- A **summary statistics table**  \n",
    "- **Historical 95% VaR** for a **60/40 portfolio** (SPY/TLT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5ffc443-9b2d-4997-b9f5-06ea22306ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "282c20bc-a48e-4a54-a2e4-d5991d63612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "import re\n",
    "from io import StringIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Configuration\n",
    "\n",
    "\n",
    "CACHE_DIR = Path(\".cache\")\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Cache utilities (parquet -> csv fallback)\n",
    "\n",
    "def _hash_key(*parts: object) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    for p in parts:\n",
    "        h.update(str(p).encode(\"utf-8\"))\n",
    "        h.update(b\"|\")\n",
    "    return h.hexdigest()[:24]\n",
    "\n",
    "def _cache_paths(prefix: str, key: str) -> tuple[Path, Path]:\n",
    "    p_parquet = CACHE_DIR / f\"{prefix}_{key}.parquet\"\n",
    "    p_csv = CACHE_DIR / f\"{prefix}_{key}.csv\"\n",
    "    return p_parquet, p_csv\n",
    "\n",
    "def _read_cache_df(prefix: str, key: str) -> pd.DataFrame | None:\n",
    "    p_parquet, p_csv = _cache_paths(prefix, key)\n",
    "    if p_parquet.exists():\n",
    "        try:\n",
    "            return pd.read_parquet(p_parquet)\n",
    "        except Exception:\n",
    "            pass\n",
    "    if p_csv.exists():\n",
    "        try:\n",
    "            return pd.read_csv(p_csv)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "def _write_cache_df(df: pd.DataFrame, prefix: str, key: str) -> None:\n",
    "    p_parquet, p_csv = _cache_paths(prefix, key)\n",
    "    try:\n",
    "        df.to_parquet(p_parquet, index=False)\n",
    "        return\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        df.to_csv(p_csv, index=False)\n",
    "    except Exception:\n",
    "        # If caching fails, ignore silently (no exceptions)\n",
    "        return\n",
    "\n",
    "# HTTP helpers\n",
    "\n",
    "def http_get_text(url: str, timeout: int = 30, headers: dict | None = None) -> str:\n",
    "    \"\"\"\n",
    "    Returns response text. Raises inside, but callers wrap in try/except (no exceptions to user).\n",
    "    \"\"\"\n",
    "    import requests\n",
    "\n",
    "    h = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (compatible; FinanceCourse/1.0)\",\n",
    "        \"Accept\": \"*/*\",\n",
    "    }\n",
    "    if headers:\n",
    "        h.update(headers)\n",
    "\n",
    "    r = requests.get(url, timeout=timeout, headers=h)\n",
    "    r.raise_for_status()\n",
    "    return r.text\n",
    "# Numeric + returns helpers\n",
    "def parse_number(x) -> float:\n",
    "    \"\"\"\n",
    "    Robust number parser:\n",
    "      - '3,367' -> 3.367 (comma decimal)\n",
    "      - '1,234.56' -> 1234.56 (comma thousands)\n",
    "    \"\"\"\n",
    "    if x is None:\n",
    "        return np.nan\n",
    "    s = str(x).strip()\n",
    "    if s == \"\" or s.lower() in {\"nan\", \"none\"}:\n",
    "        return np.nan\n",
    "\n",
    "    if \",\" in s and \".\" in s:\n",
    "        s = s.replace(\",\", \"\")\n",
    "    elif \",\" in s and \".\" not in s:\n",
    "        s = s.replace(\",\", \".\")\n",
    "\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def pct_change(s: pd.Series) -> pd.Series:\n",
    "    x = pd.to_numeric(s, errors=\"coerce\")\n",
    "    return x.pct_change(fill_method=None).replace([np.inf, -np.inf], np.nan)\n",
    "# BCRP parsing\n",
    "\n",
    "_SP2EN = {\n",
    "    \"Ene\": \"Jan\", \"Feb\": \"Feb\", \"Mar\": \"Mar\", \"Abr\": \"Apr\", \"May\": \"May\", \"Jun\": \"Jun\",\n",
    "    \"Jul\": \"Jul\", \"Ago\": \"Aug\", \"Set\": \"Sep\", \"Sep\": \"Sep\", \"Oct\": \"Oct\", \"Nov\": \"Nov\", \"Dic\": \"Dec\",\n",
    "}\n",
    "\n",
    "def _clean_bcrp_payload(txt: str) -> str:\n",
    "    \"\"\"\n",
    "    BCRP sometimes returns \"CSV\" wrapped as HTML with <br> line breaks.\n",
    "    Normalize to plain text with real newlines.\n",
    "    \"\"\"\n",
    "    x = txt.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    x = x.replace(\"<br/>\", \"\\n\").replace(\"<br />\", \"\\n\").replace(\"<br>\", \"\\n\")\n",
    "    x = re.sub(r\"</?pre[^>]*>\", \"\", x, flags=re.IGNORECASE)\n",
    "    return x.strip()\n",
    "\n",
    "def _detect_sep(header_line: str) -> str:\n",
    "    return \";\" if header_line.count(\";\") > header_line.count(\",\") else \",\"\n",
    "\n",
    "def _parse_bcrp_date(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Parses common BCRP date formats:\n",
    "      - Daily: 2022-01-03, 03Jan22, 03Ene22\n",
    "      - Monthly: Jan22, Ene22, 2022-1, 2022-01\n",
    "      - Yearly: 2022\n",
    "    \"\"\"\n",
    "    x = s.astype(str).str.strip()\n",
    "    x = x.str.replace(\".\", \"\", regex=False)\n",
    "\n",
    "    y = x\n",
    "    for k, v in _SP2EN.items():\n",
    "        y = y.str.replace(k, v, regex=False)\n",
    "\n",
    "    dt = pd.to_datetime(y, format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "\n",
    "    m = dt.isna()\n",
    "    if m.any():\n",
    "        dt.loc[m] = pd.to_datetime(y[m], format=\"%d%b%y\", errors=\"coerce\")\n",
    "\n",
    "    m = dt.isna()\n",
    "    if m.any():\n",
    "        dt.loc[m] = pd.to_datetime(y[m], format=\"%b%y\", errors=\"coerce\")\n",
    "\n",
    "    m = dt.isna()\n",
    "    if m.any():\n",
    "        dt.loc[m] = pd.to_datetime(y[m], format=\"%Y-%m\", errors=\"coerce\")\n",
    "\n",
    "    m = dt.isna()\n",
    "    if m.any():\n",
    "        dt.loc[m] = pd.to_datetime(y[m], format=\"%Y\", errors=\"coerce\")\n",
    "\n",
    "    m = dt.isna()\n",
    "    if m.any():\n",
    "        dt.loc[m] = pd.to_datetime(y[m], errors=\"coerce\")\n",
    "\n",
    "    return dt\n",
    "\n",
    "\n",
    "def bcrp_series_csv(\n",
    "    series_codes: list[str],\n",
    "    start: str,\n",
    "    end: str,\n",
    "    lang: str = \"ing\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    BCRPData API (CSV):\n",
    "      https://estadisticas.bcrp.gob.pe/estadisticas/series/api/[codes]/csv/[start]/[end]/[lang]\n",
    "\n",
    "    Returns LONG DataFrame:\n",
    "      date, series_name, value\n",
    "\n",
    "    If the endpoint fails, prints a short message and returns an empty DataFrame (no exceptions).\n",
    "    \"\"\"\n",
    "    codes = \"-\".join(series_codes)\n",
    "    url = f\"https://estadisticas.bcrp.gob.pe/estadisticas/series/api/{codes}/csv/{start}/{end}/{lang}\"\n",
    "\n",
    "    key = _hash_key(\"bcrp\", url)\n",
    "    cached = _read_cache_df(\"bcrp\", key)\n",
    "    if cached is not None and cached.shape[0] > 0:\n",
    "        cached[\"date\"] = pd.to_datetime(cached[\"date\"], errors=\"coerce\")\n",
    "        return cached\n",
    "\n",
    "    try:\n",
    "        txt = http_get_text(url, timeout=30)\n",
    "        txt = _clean_bcrp_payload(txt)\n",
    "\n",
    "        lines = [ln for ln in txt.split(\"\\n\") if ln.strip() != \"\"]\n",
    "        if len(lines) < 2:\n",
    "            print(\"[BCRP] Endpoint returned no usable rows. Continuing...\")\n",
    "            return pd.DataFrame(columns=[\"date\", \"series_name\", \"value\"])\n",
    "\n",
    "        sep = _detect_sep(lines[0])\n",
    "        df = pd.read_csv(StringIO(\"\\n\".join(lines)), sep=sep)\n",
    "\n",
    "        if df.shape[0] == 0 or df.shape[1] < 2:\n",
    "            print(\"[BCRP] Returned an empty table. Continuing...\")\n",
    "            return pd.DataFrame(columns=[\"date\", \"series_name\", \"value\"])\n",
    "\n",
    "        date_col = df.columns[0]\n",
    "        value_cols = list(df.columns[1:])\n",
    "\n",
    "        out = df.melt(\n",
    "            id_vars=[date_col],\n",
    "            value_vars=value_cols,\n",
    "            var_name=\"series_name\",\n",
    "            value_name=\"value_raw\",\n",
    "        ).rename(columns={date_col: \"date\"})\n",
    "\n",
    "        out[\"date\"] = _parse_bcrp_date(out[\"date\"])\n",
    "        out[\"value\"] = out[\"value_raw\"].map(parse_number)\n",
    "\n",
    "        out = out.drop(columns=[\"value_raw\"])\n",
    "        out = out.dropna(subset=[\"date\"]).sort_values([\"series_name\", \"date\"]).reset_index(drop=True)\n",
    "\n",
    "        _write_cache_df(out, \"bcrp\", key)\n",
    "        return out\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[BCRP] Endpoint unavailable ({type(e).__name__}). Continuing...\")\n",
    "        return pd.DataFrame(columns=[\"date\", \"series_name\", \"value\"])\n",
    "# Yahoo Finance (yfinance)\n",
    "\n",
    "def yfinance_download(tickers: list[str], start: str, end: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Yahoo Finance via yfinance.\n",
    "    Returns LONG DataFrame:\n",
    "      date, ticker, close, volume, ret\n",
    "\n",
    "    If the endpoint fails, prints a short message and returns an empty DataFrame (no exceptions).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import yfinance as yf\n",
    "    except Exception:\n",
    "        print(\"[yfinance] yfinance not installed/importable. Continuing...\")\n",
    "        return pd.DataFrame(columns=[\"date\", \"ticker\", \"close\", \"volume\", \"ret\"])\n",
    "\n",
    "    key = _hash_key(\"yfinance\", \" \".join(tickers), start, end)\n",
    "    cached = _read_cache_df(\"yf\", key)\n",
    "    if cached is not None and cached.shape[0] > 0:\n",
    "        cached[\"date\"] = pd.to_datetime(cached[\"date\"], errors=\"coerce\")\n",
    "        return cached\n",
    "\n",
    "    try:\n",
    "        data = yf.download(tickers=tickers, start=start, end=end, auto_adjust=False, progress=False)\n",
    "        if data is None or data.shape[0] == 0:\n",
    "            print(\"[yfinance] Returned no rows. Continuing...\")\n",
    "            return pd.DataFrame(columns=[\"date\", \"ticker\", \"close\", \"volume\", \"ret\"])\n",
    "\n",
    "        frames = []\n",
    "        if isinstance(data.columns, pd.MultiIndex):\n",
    "            for t in tickers:\n",
    "                if t not in data.columns.get_level_values(1):\n",
    "                    continue\n",
    "                sub = data.xs(t, axis=1, level=1).copy()\n",
    "                sub = sub.reset_index().rename(columns={\"Date\": \"date\", \"Datetime\": \"date\"})\n",
    "                sub[\"ticker\"] = t\n",
    "                sub = sub.rename(columns={\"Close\": \"close\", \"Volume\": \"volume\"})\n",
    "                frames.append(sub[[\"date\", \"ticker\", \"close\", \"volume\"]])\n",
    "            out = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()\n",
    "        else:\n",
    "            out = data.reset_index().rename(columns={\"Date\": \"date\", \"Datetime\": \"date\"})\n",
    "            out[\"ticker\"] = tickers[0]\n",
    "            out = out.rename(columns={\"Close\": \"close\", \"Volume\": \"volume\"})\n",
    "            out = out[[\"date\", \"ticker\", \"close\", \"volume\"]]\n",
    "\n",
    "        out[\"date\"] = pd.to_datetime(out[\"date\"], errors=\"coerce\")\n",
    "        out[\"close\"] = pd.to_numeric(out[\"close\"], errors=\"coerce\")\n",
    "        out[\"volume\"] = pd.to_numeric(out[\"volume\"], errors=\"coerce\")\n",
    "\n",
    "        out = out.dropna(subset=[\"date\", \"close\"]).sort_values([\"ticker\", \"date\"]).reset_index(drop=True)\n",
    "        out[\"ret\"] = out.groupby(\"ticker\")[\"close\"].apply(pct_change).reset_index(level=0, drop=True)\n",
    "\n",
    "        _write_cache_df(out, \"yf\", key)\n",
    "        return out\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[yfinance] Endpoint unavailable ({type(e).__name__}). Continuing...\")\n",
    "        return pd.DataFrame(columns=[\"date\", \"ticker\", \"close\", \"volume\", \"ret\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2296aa0d",
   "metadata": {},
   "source": [
    "1. Build (and display) the **BCRPData API URL** that requests the 4 series used in the notebook.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e57a494",
   "metadata": {},
   "source": [
    "2. Download those series and build a **tidy** table: `date`, `series`, `value`.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e8f662",
   "metadata": {},
   "source": [
    "3. Clean to **wide format** with columns: `fx_interbank`, `fx_sbs`, `gold`, `copper` (as in the notebook).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35e234f",
   "metadata": {},
   "source": [
    "4. Download `SPY`, `TLT`, `GLD` from yfinance and build: `date`, `ticker`, `close`.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7b653b",
   "metadata": {},
   "source": [
    "5. Compute **daily returns** by ticker (`ret`) and validate there are **no inf values**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f73213f",
   "metadata": {},
   "source": [
    "6. *(Quantities)* Compare FX levels in Peru: produce a **plot** and a short comment.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fab720c",
   "metadata": {},
   "source": [
    "7. *(Proportions)* Compute the **share of positive-return days** by ticker (USA).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72421adf",
   "metadata": {},
   "source": [
    "8. Plot that share as a **bar chart** and add **labels above each bar** (`annotate`).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3e1b3c",
   "metadata": {},
   "source": [
    "9. *(Distributions)* Compare the distribution of **Peru Gold** vs **GLD** (histogram).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2733a626",
   "metadata": {},
   "source": [
    "10. Add an **ECDF** (if used in the notebook) and comment on what changes vs the histogram.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0045218",
   "metadata": {},
   "source": [
    "11. *(Relationships)* Build `FX_change` and relate it to `SPY_ret` (scatter plot).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebb7187",
   "metadata": {},
   "source": [
    "12. Compute the **correlation** between `FX_change` and `SPY_ret` and explain the sign.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e70d25",
   "metadata": {},
   "source": [
    "13. Estimate a simple regression `FX_change ~ SPY_ret` and interpret the coefficient.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df056eeb",
   "metadata": {},
   "source": [
    "14. *(Pandas)* Do a selection exercise: `.iloc` (position-based) vs conditional filtering.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d668cd3",
   "metadata": {},
   "source": [
    "15. Create missing data on purpose in one series and apply imputation (as in the notebook).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cbf0d0",
   "metadata": {},
   "source": [
    "16. Standardize a variable (z-score) and plot **before vs after**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d427b70a",
   "metadata": {},
   "source": [
    "17. Find the day with the largest `|SPY_ret|` and **annotate it** in the returns plot (like the exercise).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd02725",
   "metadata": {},
   "source": [
    "18. Save one figure into `/figures` using `savefig` and verify the file exists.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8434335",
   "metadata": {},
   "source": [
    "19. Build a **summary stats table** for returns (mean, sd, p5, p95, etc.).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1bdccc",
   "metadata": {},
   "source": [
    "20. Compute **historical 95% VaR** for a **60/40 portfolio (SPY/TLT)** and explain what it means.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fe7d67-d6c0-4a5e-ae09-69b368424a11",
   "metadata": {},
   "source": [
    "## 1) Load real financial data\n",
    "\n",
    "If an endpoint is temporarily unavailable, this notebook prints a short message and continues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c658d69-b98b-420c-8903-1bf299a08052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru rows: 4136 | USA rows: 2982\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>copper_london</th>\n",
       "      <th>gold_london</th>\n",
       "      <th>fx_interbank_buy</th>\n",
       "      <th>fx_sbs_buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>439.621725</td>\n",
       "      <td>1820.10</td>\n",
       "      <td>3.983667</td>\n",
       "      <td>3.987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>438.170229</td>\n",
       "      <td>1811.40</td>\n",
       "      <td>3.959500</td>\n",
       "      <td>3.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>443.522619</td>\n",
       "      <td>1826.25</td>\n",
       "      <td>3.952000</td>\n",
       "      <td>3.953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>433.861102</td>\n",
       "      <td>1789.35</td>\n",
       "      <td>3.967167</td>\n",
       "      <td>3.967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>436.129064</td>\n",
       "      <td>1792.60</td>\n",
       "      <td>3.945167</td>\n",
       "      <td>3.948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  copper_london  gold_london  fx_interbank_buy  fx_sbs_buy\n",
       "0 2022-01-03     439.621725      1820.10          3.983667       3.987\n",
       "1 2022-01-04     438.170229      1811.40          3.959500       3.963\n",
       "2 2022-01-05     443.522619      1826.25          3.952000       3.953\n",
       "3 2022-01-06     433.861102      1789.35          3.967167       3.967\n",
       "4 2022-01-07     436.129064      1792.60          3.945167       3.948"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_D = \"2022-01-01\"\n",
    "END_D   = \"2025-12-18\"\n",
    "\n",
    "peru = bcrp_series_csv(\n",
    "    series_codes=[\"PD04637PD\", \"PD04639PD\", \"PD04704XD\", \"PD04701XD\"],\n",
    "    start=START_D,\n",
    "    end=END_D,\n",
    "    lang=\"ing\"\n",
    ")\n",
    "\n",
    "usa = yfinance_download([\"SPY\", \"TLT\", \"GLD\"], start=START_D, end=END_D)\n",
    "\n",
    "print(\"Peru rows:\", peru.shape[0], \"| USA rows:\", usa.shape[0])\n",
    "\n",
    "# show in English (wide + renamed)\n",
    "peru_wide = (\n",
    "    peru.pivot_table(index=\"date\", columns=\"series_name\", values=\"value\", aggfunc=\"last\")\n",
    "        .reset_index()\n",
    "        .sort_values(\"date\")\n",
    ")\n",
    "peru_wide.columns.name = None\n",
    "\n",
    "rename_map = {}\n",
    "for c in peru_wide.columns:\n",
    "    cl = str(c).lower()\n",
    "    if \"interbanc\" in cl and (\"tipo de cambio\" in cl or \"tc\" in cl or \"exchange\" in cl):\n",
    "        rename_map[c] = \"fx_interbank_buy\"\n",
    "    elif \"sbs\" in cl and (\"tipo de cambio\" in cl or \"tc\" in cl or \"exchange\" in cl):\n",
    "        rename_map[c] = \"fx_sbs_buy\"\n",
    "    elif \"oro\" in cl or \"gold\" in cl:\n",
    "        rename_map[c] = \"gold_london\"\n",
    "    elif \"cobre\" in cl or \"copper\" in cl:\n",
    "        rename_map[c] = \"copper_london\"\n",
    "\n",
    "peru_wide = peru_wide.rename(columns=rename_map)\n",
    "peru_wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed1c353-671c-43c4-9d7d-f458132a66b5",
   "metadata": {},
   "source": [
    "### 1.1) Quantities\n",
    "\n",
    "#### Exercise 1.1 — FX level comparison (Peru)\n",
    "\n",
    "**Tasks**\n",
    "1. Filter `peru` to the two FX series (Interbank buy and SBS buy).\n",
    "2. Pivot to wide format (`date` as index).\n",
    "3. Plot both FX levels in the same line chart.\n",
    "4. Create `spread = sbs - interbank` and plot it in a separate figure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728afe57-20fb-44bb-b640-d3cb0b04e57c",
   "metadata": {},
   "source": [
    "### 1.2) Proportions\n",
    "\n",
    "#### Exercise 1.2 — Share of positive-return days (USA)\n",
    "\n",
    "Define a positive day as `ret > 0`.\n",
    "\n",
    "**Tasks**\n",
    "1. For each ticker in `usa`, compute the share of days with `ret > 0`.\n",
    "2. Plot a bar chart of these shares.\n",
    "3. Add labels (percent format) and a title."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf7ba68-b163-402e-926e-0e779f5b16c0",
   "metadata": {},
   "source": [
    "### 1.3) Distributions\n",
    "\n",
    "#### Exercise 1.3 — Return distributions: Peru Gold vs US Gold ETF\n",
    "\n",
    "**Goal:** compare distributions of a **Peru gold reference price** series vs the **US gold ETF (GLD)**.\n",
    "\n",
    "**Tasks**\n",
    "1. From `peru`, build a daily gold series and compute returns.\n",
    "2. From `usa`, filter to GLD returns.\n",
    "3. Plot two histograms (separate figures) with the same binning.\n",
    "4. Optional: overlay KDE for each distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c22127-8e3d-4051-b031-718211be7925",
   "metadata": {},
   "source": [
    "### 1.4) Relationships\n",
    "\n",
    "#### Exercise 1.4 — FX changes vs market returns (Peru + USA)\n",
    "\n",
    "Use:\n",
    "- Peru interbank FX (daily % change)\n",
    "- SPY returns (broad US market benchmark)\n",
    "\n",
    "**Tasks**\n",
    "1. Build interbank FX daily returns from the Peru FX series.\n",
    "2. Build SPY daily returns from `usa`.\n",
    "3. Merge on date.\n",
    "4. Scatter plot (x = SPY ret, y = FX ret).\n",
    "5. Compute correlation and write 2–3 sentences interpreting the sign/magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec12f73-8852-4ed1-a55b-cb96a33b11b7",
   "metadata": {},
   "source": [
    "### 1.5) References \n",
    "\n",
    "- BCRP Statistical Series (Daily): exchange rates and commodities series catalog.\n",
    "- BCRPData API (CSV endpoint) for downloading series.\n",
    "- yfinance: Python wrapper that fetches historical market data from Yahoo Finance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7f3609-3cd7-4e1b-9015-a4ce1f04c7da",
   "metadata": {},
   "source": [
    "## 2) Online Data Sources \n",
    "\n",
    "### Exercise 2.1 — Inspect the BCRPData API URL (requests)\n",
    "You are already downloading from BCRPData. Now you will **inspect** what is being requested.\n",
    "\n",
    "**Tasks**\n",
    "1. Recreate the API URL string used to download the Peru series.\n",
    "2. Print it.\n",
    "3. Download the CSV text using `http_get_text` and display the first 10 lines.\n",
    "4. Explain (in a markdown cell) what each part of the URL means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3edd0f87-2781-4a01-8885-a7993b2e779d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCRPData URL (multi-series):\n",
      "https://estadisticas.bcrp.gob.pe/estadisticas/series/api/PD04637PD-PD04639PD-PD04704XD-PD04701XD/csv/2022-01-01/2025-12-18/ing\n",
      "\n",
      "First 10 lines of the response (server (multi-series)):\n",
      "01: D&iacute;a/Mes/A&ntilde;o,\"Tipo de cambio - TC Interbancario (S/ por US$) - Compra\",\"Tipo de cambio - TC Sistema bancario SBS (S/ por US$) - Compra\",\"Cotizaciones internacionales - Cobre (Londres, cUS$ por libras)\",\"Cotizaciones internacionales - Oro (Londres, US$ por onzas troy)\"\n",
      "02: \"03.Jan.22\",\"3.98366666666667\",\"3.987\",\"439.621724973844\",\"1820.1\"\n",
      "03: \"04.Jan.22\",\"3.9595\",\"3.963\",\"438.170229389944\",\"1811.4\"\n",
      "04: \"05.Jan.22\",\"3.952\",\"3.953\",\"443.522619355577\",\"1826.25\"\n",
      "05: \"06.Jan.22\",\"3.96716666666667\",\"3.967\",\"433.86110187524\",\"1789.35\"\n",
      "06: \"07.Jan.22\",\"3.94516666666667\",\"3.948\",\"436.129063725084\",\"1792.6\"\n",
      "07: \"10.Jan.22\",\"3.92766666666667\",\"3.925\",\"438.397025574929\",\"1794.2\"\n",
      "08: \"11.Jan.22\",\"3.91633333333333\",\"3.919\",\"438.260947863938\",\"1806.8\"\n",
      "09: \"12.Jan.22\",\"3.89233333333333\",\"3.897\",\"451.097611934057\",\"1821.4\"\n",
      "10: \"13.Jan.22\",\"3.89483333333333\",\"3.895\",\"452.322311332973\",\"1820.35\"\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import requests\n",
    "\n",
    "def fetch_text_with_session(url: str, timeout: int = 30, tries: int = 3) -> str:\n",
    "    \"\"\"Fetch raw text using a requests.Session (cookies) + browser-like headers.\"\"\"\n",
    "    headers = {\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "            \"Chrome/120.0.0.0 Safari/537.36\"\n",
    "        ),\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9,es;q=0.8\",\n",
    "        \"Referer\": \"https://estadisticas.bcrp.gob.pe/\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Cache-Control\": \"no-cache\",\n",
    "        \"Pragma\": \"no-cache\",\n",
    "    }\n",
    "\n",
    "    s = requests.Session()\n",
    "\n",
    "    # Warm-up request to get cookies (can help with WAF/403)\n",
    "    try:\n",
    "        s.get(\"https://estadisticas.bcrp.gob.pe/\", headers=headers, timeout=timeout)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    last = None\n",
    "    for k in range(tries):\n",
    "        try:\n",
    "            r = s.get(url, headers=headers, timeout=timeout)\n",
    "            if r.status_code == 403:\n",
    "                last = requests.HTTPError(f\"403 Forbidden for url: {url}\")\n",
    "                time.sleep(1.5 * (k + 1))\n",
    "                continue\n",
    "            r.raise_for_status()\n",
    "            return r.text\n",
    "        except Exception as e:\n",
    "            last = e\n",
    "            time.sleep(1.5 * (k + 1))\n",
    "\n",
    "    raise last\n",
    "\n",
    "\n",
    "SERIES = [\"PD04637PD\", \"PD04639PD\", \"PD04704XD\", \"PD04701XD\"]\n",
    "\n",
    "START_D = \"2022-01-01\"\n",
    "END_D   = \"2025-12-18\"\n",
    "LANG    = \"ing\"\n",
    "\n",
    "# 1) Recreate the API URL string used to download the Peru series\n",
    "codes = \"-\".join(SERIES)\n",
    "url_multi = f\"https://estadisticas.bcrp.gob.pe/estadisticas/series/api/{codes}/csv/{START_D}/{END_D}/{LANG}\"\n",
    "\n",
    "print(\"BCRPData URL (multi-series):\")\n",
    "print(url_multi)\n",
    "\n",
    "# 2-3) Try to download raw CSV text and show first 10 lines\n",
    "txt = None\n",
    "raw_source = None\n",
    "\n",
    "try:\n",
    "    txt = fetch_text_with_session(url_multi, timeout=30, tries=3)\n",
    "    raw_source = \"server (multi-series)\"\n",
    "except Exception as e:\n",
    "    print(f\"[BCRP] Multi-series request failed: {type(e).__name__}: {e}\")\n",
    "\n",
    "# Fallback: try only ONE series (often allowed even if multi is blocked)\n",
    "if txt is None:\n",
    "    one = SERIES[0]\n",
    "    url_one = f\"https://estadisticas.bcrp.gob.pe/estadisticas/series/api/{one}/csv/{START_D}/{END_D}/{LANG}\"\n",
    "    print(\"\\nBCRPData URL (single-series fallback):\")\n",
    "    print(url_one)\n",
    "    try:\n",
    "        txt = fetch_text_with_session(url_one, timeout=30, tries=3)\n",
    "        raw_source = f\"server (single-series: {one})\"\n",
    "    except Exception as e:\n",
    "        print(f\"[BCRP] Single-series request failed: {type(e).__name__}: {e}\")\n",
    "\n",
    "if txt is not None:\n",
    "    # Replace <br> HTML tags with newline characters (some responses use HTML breaks)\n",
    "    txt_clean = (txt.replace(\"<br />\", \"\\n\").replace(\"<br/>\", \"\\n\").replace(\"<br>\", \"\\n\"))\n",
    "\n",
    "    lines = txt_clean.splitlines()\n",
    "    print(f\"\\nFirst 10 lines of the response ({raw_source}):\")\n",
    "    for i, line in enumerate(lines[:10], start=1):\n",
    "        print(f\"{i:02d}: {line}\")\n",
    "\n",
    "else:\n",
    "    # Last-resort fallback: reconstruct \"CSV-like\" lines from your cached dataframes\n",
    "    # NOTE: this is NOT the raw server response; it's reconstructed from local data.\n",
    "    print(\"\\n[BCRP] Could not fetch raw text due to 403. Reconstructing lines from local data (NOT raw server response).\")\n",
    "\n",
    "    # Try to use peru_w if it exists; else use peru if it exists.\n",
    "    if \"peru_w\" in globals() and hasattr(peru_w, \"head\"):\n",
    "        preview = peru_w.head(10).to_csv(index=False)\n",
    "        rec_lines = preview.splitlines()[:10]\n",
    "        print(\"\\nFirst 10 lines (reconstructed from peru_w):\")\n",
    "        for i, line in enumerate(rec_lines, start=1):\n",
    "            print(f\"{i:02d}: {line}\")\n",
    "    elif \"peru\" in globals() and hasattr(peru, \"head\"):\n",
    "        preview = peru.head(10).to_csv(index=False)\n",
    "        rec_lines = preview.splitlines()[:10]\n",
    "        print(\"\\nFirst 10 lines (reconstructed from peru):\")\n",
    "        for i, line in enumerate(rec_lines, start=1):\n",
    "            print(f\"{i:02d}: {line}\")\n",
    "    else:\n",
    "        print(\"No local dataframes found (peru/peru_w). Run the download cells first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ca0caf-1d8a-4161-b886-100035559173",
   "metadata": {},
   "source": [
    "### Exercise 2.2 — Build a clean wide table (Peru finance data)\n",
    "Turn long BCRP data into a clean table.\n",
    "\n",
    "**Tasks**\n",
    "1. Use `peru_w` (already wide).\n",
    "2. Rename columns to short names:\n",
    "   - `fx_interbank`, `fx_sbs`, `gold`, `copper`\n",
    "   (Hint: inspect column names first.)\n",
    "3. Create daily percentage changes for FX and commodities.\n",
    "4. Drop rows where all four returns are missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31434e36-23b4-447d-ab7c-0251c52d9e7f",
   "metadata": {},
   "source": [
    "## 3) Matplotlib: Constructing the Plot \n",
    "\n",
    "### Exercise 3.1 \n",
    "Create a single figure with 2 subplots:\n",
    "- Top: Peru FX spread (SBS - interbank)\n",
    "- Bottom: USA SPY close price\n",
    "\n",
    "**Tasks**\n",
    "1. Build the Peru FX spread series from `peru_w`.\n",
    "2. Build SPY close series from `usa_w`.\n",
    "3. Use `plt.subplots(nrows=2, ncols=1, sharex=True)`.\n",
    "4. Add titles, axis labels, and use `fig.tight_layout()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9a0b50-7d16-4a91-a97e-a5cdf6bc55ea",
   "metadata": {},
   "source": [
    "### Exercise 3.2 — Annotations (mark a key event on a series)\n",
    "Annotate the largest absolute daily SPY return.\n",
    "\n",
    "**Tasks**\n",
    "1. Find the date with the largest `abs(ret)` for SPY.\n",
    "2. Plot SPY returns over time.\n",
    "3. Add an annotation at the extreme point (arrow + text)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687abacd-1793-4358-b025-b98ad0e6bb28",
   "metadata": {},
   "source": [
    "### Exercise 3.3 — Saving the figure\n",
    "Save one of your figures to disk.\n",
    "\n",
    "**Tasks**\n",
    "1. Create a folder `figures/` if it does not exist.\n",
    "2. Save the subplot figure as `figures/lecture4II_fx_spy.png` with dpi=150.\n",
    "3. Confirm the file exists."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb913ac-c8ca-4474-91a1-5113757880da",
   "metadata": {},
   "source": [
    "## 4) Statistics \n",
    "### Exercise 4.1 — Summary statistics table (returns)\n",
    "Build a clean table of return moments.\n",
    "\n",
    "**Tasks**\n",
    "1. Create a wide daily returns table for SPY, TLT, GLD.\n",
    "2. Compute: mean, std, skewness, kurtosis.\n",
    "3. Present results as a DataFrame with tickers as rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1ac8d2-39c0-45d9-ae2c-4e2c8c84fd82",
   "metadata": {},
   "source": [
    "### Exercise 4.2 — \n",
    "Run a simple regression of GLD returns on SPY returns:\n",
    "\n",
    "\\[\n",
    "GLD_t = \\alpha + \\beta\\,SPY_t + \\varepsilon_t\n",
    "\\]\n",
    "\n",
    "**Tasks**\n",
    "1. Build aligned return vectors (drop missing).\n",
    "2. Compute \\alpha and \\beta using the closed-form OLS formulas.\n",
    "3. Plot the scatter and fitted line.\n",
    "4. Interpret \\beta in 2–3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c745fb54-29c8-46c6-a187-0f6b9a309bf9",
   "metadata": {},
   "source": [
    "## 5) Risk and Uncertainty \n",
    "\n",
    "### Exercise 5.1 — Historical VaR (95%) for a 60/40 portfolio\n",
    "Portfolio:\n",
    "- 60% SPY\n",
    "- 40% TLT\n",
    "\n",
    "**Tasks**\n",
    "1. Create a wide returns table for SPY and TLT.\n",
    "2. Compute portfolio daily returns.\n",
    "3. Compute 1-day 95% Historical VaR (the 5th percentile of returns).\n",
    "4. Compute 1-day 95% CVaR (average return below the 5th percentile)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee096ef3-0949-4d60-a468-ca484e24e4cb",
   "metadata": {},
   "source": [
    "## 6) References\n",
    "\n",
    "- BCRPData API (CSV endpoint): BCRP statistical series API for downloading time series\n",
    "- BCRP series catalog: codes for FX (interbank/SBS) and commodity reference prices\n",
    "- yfinance: Python wrapper to access historical market data from Yahoo Finance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
