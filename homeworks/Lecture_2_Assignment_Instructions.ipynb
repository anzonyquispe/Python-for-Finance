{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e9ae99c",
   "metadata": {},
   "source": [
    "# Lecture 2 — Homework (Instructions Only)\n",
    "\n",
    "**Goal:** Practice Python containers (lists, dicts, NumPy arrays) and core pandas workflows (Series, DataFrames, filtering, missing values, duplicates, groupby, reshape, merge) using **real financial data** from Peru and the US.\n",
    "\n",
    "**Rules**\n",
    "- Submit a single `.ipynb` that runs top-to-bottom with **Run All**.\n",
    "- Use **real data** via the loaders you built in the Lecture 2 practice notebook (BCRP API + Yahoo Finance).\n",
    "- Do **not** include plots in this homework.\n",
    "\n",
    "---\n",
    "\n",
    "## Part 1 — Series (containers → Series)\n",
    "\n",
    "### Task 1.1 — From list to Series (Peru FX)\n",
    "1. Fetch Peru FX buy and sell (PEN/USD) from BCRP for a recent 2–5 year window.\n",
    "2. Compute the mid-rate: `mid = (buy + sell) / 2`.\n",
    "3. Take the **last 20 values** of `mid` as a Python list.\n",
    "4. Build a `pd.Series` from that list and name it `PENUSD_mid_last20`.\n",
    "5. Report (in markdown): number of observations, mean, min, max.\n",
    "\n",
    "### Task 1.2 — From NumPy array to Series (US market)\n",
    "1. Download daily data for `GLD` from Yahoo Finance for a recent 3–7 year window.\n",
    "2. Extract the `close` column as a NumPy array.\n",
    "3. Build a `pd.Series` indexed by the corresponding dates.\n",
    "4. Report (in markdown): mean, min, max, and the date range.\n",
    "\n",
    "### Task 1.3 — From dict to Series (last available close)\n",
    "1. Choose **three** Yahoo Finance tickers (example: `SPY`, `QQQ`, `IWM`).\n",
    "2. For each ticker, compute the **last available close** in your sample.\n",
    "3. Store them in a dict `{ticker: last_close}`.\n",
    "4. Convert to a `pd.Series`, sort descending, and report the top ticker.\n",
    "\n",
    "### Task 1.4 — Why alignment matters (short explanation)\n",
    "Write a short markdown explanation (5–8 lines) comparing:\n",
    "- a pandas merge/concat that aligns on dates (safe), versus\n",
    "- truncating two NumPy arrays to the same length (unsafe).\n",
    "\n",
    "Use your own examples from Tasks 1.1 and 1.2.\n",
    "\n",
    "---\n",
    "\n",
    "## Part 2 — DataFrames (core operations)\n",
    "\n",
    "### Task 2.1 — Ticker metadata table\n",
    "Create a DataFrame with:\n",
    "- `ticker`\n",
    "- `last_close`\n",
    "- `market` (set to `\"US\"` for all rows)\n",
    "\n",
    "Use the same tickers you picked in Task 1.3.\n",
    "\n",
    "### Task 2.2 — Filtering (percentiles within each ticker)\n",
    "Using your US market dataset with at least 2 tickers:\n",
    "1. For each ticker, compute the **95th percentile** of `close`.\n",
    "2. Keep only rows where `close` is strictly above the ticker’s 95th percentile.\n",
    "3. Report: how many rows remain per ticker (a small table is enough).\n",
    "\n",
    "### Task 2.3 — Missing values (controlled experiment)\n",
    "1. Make a copy of your US market DataFrame.\n",
    "2. With a fixed random seed, set **1% of `volume`** to missing (`NaN`).\n",
    "3. Create two cleaned versions:\n",
    "   - dropped rows with missing `volume`\n",
    "   - filled missing `volume` using the **ticker-specific median**\n",
    "4. Compare shapes and report (in markdown): which method keeps more information and why.\n",
    "\n",
    "### Task 2.4 — Duplicates\n",
    "1. Create a new DataFrame by stacking the last 5 rows twice.\n",
    "2. Detect duplicates with `.duplicated()`.\n",
    "3. Remove duplicates with `.drop_duplicates()`.\n",
    "4. Verify row counts before/after.\n",
    "\n",
    "### Task 2.5 — Groupby summary\n",
    "Compute a table grouped by `ticker` with:\n",
    "- `mean_close`\n",
    "- `std_close`\n",
    "- `max_volume`\n",
    "\n",
    "Sort by `mean_close` descending and write 3 bullet points interpreting the table.\n",
    "\n",
    "### Task 2.6 — Reshape (long ↔ wide)\n",
    "1. Create a wide pivot table of `close` with:\n",
    "   - index = `date`\n",
    "   - columns = `ticker`\n",
    "   - values = `close`\n",
    "2. Keep only the first 30 dates.\n",
    "3. Melt the wide table back to long format with columns `date`, `ticker`, `close`.\n",
    "\n",
    "---\n",
    "\n",
    "## Part 3 — Merge (Peru macro + US market)\n",
    "\n",
    "### Task 3.1 — Monthly merge (policy rate vs commodity ETF)\n",
    "1. Fetch BCRP **policy rate** for a multi-year window (daily series is fine).\n",
    "2. Convert both datasets to **monthly frequency** using:\n",
    "   - `year` and `month` extracted from dates\n",
    "   - monthly mean aggregation\n",
    "3. Build a monthly average close for **GLD**.\n",
    "4. Merge policy rate monthly with GLD monthly on `(year, month)`.\n",
    "5. Save your final table to:\n",
    "   - `outputs/lecture2_hw_policy_gld_monthly.csv`\n",
    "\n",
    "In markdown: explain (3–6 lines) what each column represents and what a student could explore next (no plots required).\n",
    "\n",
    "---\n",
    "\n",
    "## Deliverables checklist\n",
    "- All tasks completed with short markdown notes.\n",
    "- Notebook runs with **Run All**.\n",
    "- CSV saved to `outputs/lecture2_hw_policy_gld_monthly.csv`.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
